{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-06T14:50:46.570288Z","iopub.execute_input":"2022-12-06T14:50:46.570803Z","iopub.status.idle":"2022-12-06T14:50:47.124074Z","shell.execute_reply.started":"2022-12-06T14:50:46.570720Z","shell.execute_reply":"2022-12-06T14:50:47.123054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/vispol/dhaka-streets-coco/README.roboflow.txt\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-22_jpg.rf.f54947d6c80fc8d47182fd9788a4ac57.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-50_jpg.rf.49394d9e860ba922cb9ae283f37b2208.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-44_jpg.rf.eff7fb91a83ff2bd1e933a9614573601.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-33_jpg.rf.54968ab5e6443f93bb889a697c97e0d0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-108_jpg.rf.24070a9a0e7e5d2e6402e96941219074.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-223_jpg.rf.093229e3906161a44a8718bc1be59c8b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-187_jpg.rf.73011466db457a9f611199b78d32bcfa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-79_jpg.rf.346c0495a95fb9a994b62b758d50542d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-20_jpg.rf.dc3657d5adf95206f24754a2f5908dad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-28_jpg.rf.c194ee7d5dbc94dfdb2db11d6c35d6d6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-34_jpg.rf.b44f1e1f13dd75899f14869c6d9e1819.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-117_jpg.rf.605dbbcd9988ef680cad186961ea4751.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-203_jpg.rf.3f3dd4596204456217daf9ad0f3fddb5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-106_jpg.rf.554a04254a894694ff892efe733dbd28.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-163_jpg.rf.90ee4ccaf102a90d0816c356d843c5ec.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-97_jpg.rf.0934ebf7ceaf9ab46df548ba481cad88.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-71_jpg.rf.766cb5f0dce7af6cb5709a2c14390426.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-32_jpg.rf.20287f768ff726322a7c85ae5557e3e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-45_jpg.rf.b15ef7f803d99fdd929850219f42c8ac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-70_jpg.rf.012dff4128c8decabf516201355e4823.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-4_jpg.rf.3e40218655d6fc9ff4e1da2b2616ebb2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-122_jpg.rf.307efd7af2f17059e542463c2098a75a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-102_jpg.rf.ebab9d11305782517b011c08c258fd1b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-177_jpg.rf.c38e2ad8e5f47f2bd45a38b3be050e97.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-112_jpg.rf.dc249a056ad12b133b06fd1725bda8de.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-138_jpg.rf.079bde942c866637996908496ce560a6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-119_jpg.rf.86c9f1bb31e0f0f41c17345308406194.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-131_jpg.rf.9e01d039806daad87a95369c324aa07e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-83_jpg.rf.6bb864159b3f14c14166a31afe356c21.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-81_jpg.rf.6874f6f309f02f402335ead79821bca1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-19_jpg.rf.e4506a1da7783db170b58b08c592d786.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-152_jpg.rf.ad4bf659ed63ab5d80bdd329606308f6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-2_jpg.rf.0ee9e68bfd815edf77b26eab2e615b04.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-229_jpg.rf.3350b2ab9bf7a504e842352d4a1b621b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-135_jpg.rf.4a3f9cbe3d9cdc6719768421d9d3f9f7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-50_jpg.rf.dde50472f1dd1e93acf7a63fb1fe8332.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-29_jpg.rf.c5fd7a1acc5f9ee90b5f6b54974ae210.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-21_jpg.rf.0eadaabc1f27ee52b833f8d41dda25c5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-79_jpg.rf.99903dc8bd3b934cb1e5c663dac9408a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-51_jpg.rf.ad955e7351ae1b26fd63d3480ac129a7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-93_jpg.rf.aa172741700fd8857ef7cf842becd520.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-82_jpg.rf.f1c756e8246819e0da39356e7d2b4e6a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-111_jpg.rf.55bffeea3fa6e1090129f783e7c1a933.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-183_jpg.rf.a04f62edb0162aa80785837839aad877.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-116_jpg.rf.250f1e86bc7c4ac8cfe1c2fac6ed4c27.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-111_jpg.rf.2eb3aa6b6bc58d4b94120aa3e70a317e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-100_jpg.rf.b8285a72a0c7db269ad49637968690e8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-16_jpg.rf.d95239991a32198bd1bf28d7a0ae7620.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-173_jpg.rf.132e35cdbea1519610055c89389f2236.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-254_jpg.rf.0788a324a18694c35f9a1707c9f3f2fd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-50_jpg.rf.388bc77177f845de36ecb83b7450ddc2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-2_jpg.rf.2df45bbea90ae46a6ced2fc15796651b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-127_jpg.rf.c705ced8a7546b570cdd22785b13293a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-140_jpg.rf.fc457d4f121d4342c0a77feefce0c6d0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-180_jpg.rf.762f8cb99143e7b822cd2123704b35f7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-132_jpg.rf.5f5cf26a255e165fc2e57b9a18499394.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks2-5_jpg.rf.9226194446a320eaf4bb54d3e2ebb100.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-11_jpg.rf.530b1d003be8c53f9c7d8ee497c58244.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-6_jpg.rf.690d5168efa5144bef5e94b3f3673a96.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-33_jpg.rf.61cec67a090f3b1a232a26d317ad6bdf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-210_jpg.rf.47456e63ab03720e2ad851b2f5856ae7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-143_jpg.rf.354f509bfcd36fc0b99f5980f2b8a3ad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-227_jpg.rf.70bb20c9461609f992aaee3cf39c66fb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-191_jpg.rf.c7eaf2fbdeda2996e95191fd2c1cc18d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-170_jpg.rf.822b844a4da2892fadae0a59d3145c43.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-88_jpg.rf.bf0f3d584235ee648c175593bb49724a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-23_jpg.rf.abe5e36fbd71f86c807ab9bb022e6841.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-147_jpg.rf.89d0ede33bf5721a7c6fd3513694b429.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-18_jpg.rf.c38c8b0eb5af7e8ced06e8cd655ddda2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-181_jpg.rf.65d7b1578980d09328cae5714362c34b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-55_jpg.rf.d02cf1cc2f5b806c64a71d9b59449d1b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-24_jpg.rf.6551fc044a500c93470b428824ce3bd3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-91_jpg.rf.b9d6c0f07a85f24dcd79e86b287405a0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-265_jpg.rf.b9495897cc9cc1e13a1f1db899a9ddab.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-132_jpg.rf.fdfe4ab4b265389154bcbec32643a2f4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-150_jpg.rf.7614d6e537f5884cccd0db11f19a5b70.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-5_jpg.rf.ce74c0984847438c7f4b424cda143ab6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-65_jpg.rf.366b9eaa0a98e76626c434b0c4570b2a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-26_jpg.rf.7d216dffa66a9cf859ad67f1f9b08445.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-171_jpg.rf.8b68e6987d7f5ad48c821ca62c3b389b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-106_jpg.rf.9c9febfbf74265c831ff4ee7ee3a2c3a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-133_jpg.rf.b3e93d0c329013629b2b133894630606.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-28_jpg.rf.015718e9410ec72265aacec8f6357974.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-170_jpg.rf.57f63a742c0f0f40b89769b5fca6cbee.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-256_jpg.rf.2580a3bd925b368483185b0aff019a90.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-169_jpg.rf.071c193cc0c853636c31f57852b87cbd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-91_jpg.rf.3829f8e335e5b02728110f5a0536448d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-224_jpg.rf.18379caff5c77258cfea73809621ee9d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-36_jpg.rf.2db9aaddb900b1d483f81edf1619344f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-146_jpg.rf.4ab892b314c67600c3ec83bf5b0c4f8c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-131_jpg.rf.e244be1d2f2f5c4059df35213478200e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-102_jpg.rf.b4d9ac61295239672805e56c80e4cb2a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-72_jpg.rf.d95cbddb9b9f2c4ff21d5b2fca51938c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-47_jpg.rf.0e7a6af453a24d9631af21b8988d173b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-91_jpg.rf.afa8684f366a423f02f497c3d7a8b6ad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-170_jpg.rf.0bdaf9a30f2540c79a9f910218af6b79.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-50_jpg.rf.945fb338b321986cbf91f0b242cb536d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-94_jpg.rf.c8dd65665383bd31af3db656b0095553.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-27_jpg.rf.0d371119719fcfdafe565c55547f4b19.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-36_jpg.rf.a04592b06cc6d6340046628a109a6029.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-29_jpg.rf.5e7c543c7b98775bd74e121f41a305a0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-58_jpg.rf.88c32aa164bf903f05981dfe2c00959a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-55_jpg.rf.e9b18d174c3aec760a9982902a77f4ea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-101_jpg.rf.2fe9b1fbb6caf6c97503c5f4868871bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-93_jpg.rf.0d6c0fb32308dde3fae0e0abeff71231.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-176_jpg.rf.5013723dd3c16af6f31693d2eb4fd57c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-84_jpg.rf.142ca51eb781aad4a771e9c6631e2557.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-134_jpg.rf.0103299f1bedecb2d300111940f734c3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-130_jpg.rf.e3a148be9af3926801ea367c5814d416.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-118_jpg.rf.4542d7dc08843492939d7aef2341bd3d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-87_jpg.rf.d6adc4a708a7c5ebf0392cb4aea9dc93.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-219_jpg.rf.1ac3a738ff83af437f7f89467ba4db2c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-155_jpg.rf.39380ffd6ed9c53e1dc783b64a280775.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-129_jpg.rf.5c5d768b0e869949e25d6eb251441b0f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-157_jpg.rf.0960da7e96347bfb6718badc335dd322.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks2-10_jpg.rf.c36ffd9886561c9a14062a35bab7cc16.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-175_jpg.rf.37ed3e78344b6baaf7a8abd9547e0219.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-204_jpg.rf.e93148efa767127ebb026031906c3643.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-125_jpg.rf.55bff45b59b8e817cb8e7e4fc419501b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-255_jpg.rf.793a2fd7338ab149bf2306df9cc1f88e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-94_jpg.rf.104ce47e1b2ad1cf6db78a83a8e96a34.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-3_jpg.rf.7245c97274d2fe44c017307abd0b6422.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-100_jpg.rf.a5f1383a246fb697bbe0f1f2bc64c3d7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-45_jpg.rf.efb0391941faafbf39a18ca0d62531da.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-79_jpg.rf.97ca9a092eb61bc7de466cbe59799ac5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-159_jpg.rf.73343c1156b1b1c025901105fdf311ee.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-42_jpg.rf.59ec73fd423d4c629fd271fa85c3424a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-103_jpg.rf.b3b9e6cbfe807fe5dbafbb55ebfccfcd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-48_jpg.rf.71f836f971ac954725eb7c2a5df26015.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-228_jpg.rf.e7461ad1d91d04c63cbd0c0254d60223.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-180_jpg.rf.8e1a1a717e6745065c8eb785d6908e17.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-52_jpg.rf.fe6a803901c3a7762655a9a83cd3a541.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-159_jpg.rf.4f9cfd054ced0ad396b2ea6949175b4d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-6_jpg.rf.807c4fac91c9fc9b35bbc1ebabb06f42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-100_jpg.rf.5fd1d7114acb27ffe4a99663fc8253d0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-12_jpg.rf.8074489af44e0cd86f0f0e79674b38a9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-189_jpg.rf.30cd3aa0c43c275311c5a0402fef9117.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-139_jpg.rf.4bf64743870784ebfe46c5b0944c40df.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-277_jpg.rf.0ec94c1205829dd9e548dfe44e9a3df3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-107_jpg.rf.83924abeb256ea6108f29e248097df79.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-125_jpg.rf.719ab435097ac4af3642a2fa11e58d57.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-90_jpg.rf.913b37ed4483429d980eaa8267354862.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-41_jpg.rf.c9109da00a118c7925bc688b7a7eb30e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-144_jpg.rf.d8424204a621e914c11b430b8b198f7f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-111_jpg.rf.f157f7479e30a6731646f7ba9ab9a020.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-18_jpg.rf.06eae2238f9ef1b62fa57259423ce34f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-27_jpg.rf.1a7e573ee397ca9415d7ebca32e52a44.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-13_jpg.rf.e983fa1cdf450a47f6fe2690248955be.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-88_jpg.rf.96270cc3e918b4c6a460ffd36e0c76a6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-168_jpg.rf.0cdcf0db53c85695c02d6b213fc4b57d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-178_jpg.rf.97ec22bd2de836141b7606e3118aedc6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-188_jpg.rf.39d57b2cdabf95322d4365509b9a59ad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-167_jpg.rf.27720964d847fc91dc39f21337c307a4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-20_jpg.rf.2fd12a8e341968712fc4b2cb9071c3e6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-174_jpg.rf.76fe9341dbc179d80b118de3b6d924b6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-95_jpg.rf.7201ad20dc35d0895887ccf407c107ea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-193_jpg.rf.05e97db1f8d7f3f7bc5f2b798f558b9c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-54_jpg.rf.67d97a8add602b5f5b6f34b23a688fca.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-70_jpg.rf.99f7b5b265029e02d191dd6dddb0ba1e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-234_jpg.rf.b3d05c94662c81f8554da0f9d07103c3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-65_jpg.rf.394029210176e67a262a16080504bf7d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-31_jpg.rf.b1b9675b84cfc50f20f7d85ab883ea6e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-125_jpg.rf.14e5a2e37567eae12cee26fa4b05306c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-121_jpg.rf.9543d0897d4cdd04ca23355075b00db9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-103_jpg.rf.ce9fea130eae498f30e786bd945d7c8b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-131_jpg.rf.c0de5b1848f0af7d2cd9ab5162df2ffc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-16_jpg.rf.0741b343d1bd204afeacdba8ec76e1f6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-221_jpg.rf.89e90e8702136eac9946134f8066287d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-222_jpg.rf.caf83eeedd19d231df09f7e95452d700.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-249_jpg.rf.356b29fecc64d3584e33655d116159b7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-56_jpg.rf.cb2ae49ef710999acdac759cb822bb55.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-118_jpg.rf.5f0c7ae36fec930404b78aa3e4791349.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-103_jpg.rf.9db614ed98047d64a2367c800cf30494.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-134_jpg.rf.5db3e031facbaef22f7b356071524e8a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-111_jpg.rf.1804cc3a47e76143a437ce4c07c48a96.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-36_jpg.rf.bbc5bdcd4ccf67127ce7ad9e26114aa3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-115_jpg.rf.0c2c5b8ff8f5521ca6369fe094276f14.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-184_jpg.rf.e2d54061e8b7119059b3feed4f540b57.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-148_jpg.rf.a518085545151440b6e14b76b7b6f360.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-98_jpg.rf.a846ca61981fc741d09d1ef7dec6f4b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-55_jpg.rf.50b973c67c3e3670dac60c289a3c7742.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-156_jpg.rf.9a5aa5db17cb9eb5fa9c82f3a1effd1d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-0_jpg.rf.137f5153f965991152a0d902cc1f8b1a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-189_jpg.rf.4e77f87df09680741e5ee4c10bc92584.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-8_jpg.rf.2b0ab7bbbe2f624f66e36809da30fcf4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-3_jpg.rf.704f4211089309f840b581658f9929c7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-204_jpg.rf.5dcd6d908d264f9a7dd7450e1c2b656f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-104_jpg.rf.a61c6b2262fde1f3fcdd44da87bdf6aa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-32_jpg.rf.992f7ea0a16362d33adc0d196d885563.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-142_jpg.rf.549153478b3c60c3d6f703e47f8d3625.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-248_jpg.rf.40d275fae8382ad7f6bafd3d556f916d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-113_jpg.rf.3c79e6d3ffd906d5233c139b6ce96b98.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-103_jpg.rf.a8467affda46adb6b53f7c8cac9c99d2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-168_jpg.rf.4e9249b86d97ac36b775dfb5b921823e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-279_jpg.rf.e1ccb5236d5657a8bb28c3d8f66d4ceb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-7_jpg.rf.e2cc41faa412ed661f625f801213f51a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-95_jpg.rf.49df18aec714591dcea8349719ffbd42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-172_jpg.rf.97fb4381bb6b53be02f8054fae8fb405.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-130_jpg.rf.728dbb841aa6ab19444f8f0332ab37c4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-38_jpg.rf.3cc917ae0cd0266515a79122121b2b5c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-179_jpg.rf.096e05e5fb3c523b22d965d797884b85.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-122_jpg.rf.4fd14b636f07bfef9d5f840f398237c4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-31_jpg.rf.f33143a95a493aa4de8b33af580b9978.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-166_jpg.rf.608f646cb1e6bb8bc1081bb4505ccff6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-38_jpg.rf.3c5bb87eec302bd30ae25f6370b7a35a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-108_jpg.rf.e2475e909666a88fef78a288c6781f85.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-111_jpg.rf.3d3a0a69f1253ab00170f76ab9cbecf3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-132_jpg.rf.5391f219e790f8c6b6ff90581349188e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-49_jpg.rf.55d61dd004de3f62760ce86d636e79a0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-144_jpg.rf.6d5eb37fda64b223f99111bbb36d6669.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-25_jpg.rf.c9b7fdfd2a65919f01fa9699c33344af.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-179_jpg.rf.fb48588215c23f5f1da95f40f4d56138.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-122_jpg.rf.02d2317f781d24d766f05e20e2523f44.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-46_jpg.rf.c5ab1526192029025cfc66612fc36d43.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-229_jpg.rf.bc3ec548426389f227ec346d5e2f49bb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-176_jpg.rf.41359cb596b89b8bfbe49ab66d5b2a45.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-66_jpg.rf.c8ba4b760a5dec6324defa9222e62e6c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-64_jpg.rf.8398581a9fd7394bbcf28bc1bbe78c55.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-172_jpg.rf.125578b3f85a7717ada716303ee9adfd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-107_jpg.rf.63a2ddbdad8eb56b4914b5f8b93e7001.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-218_jpg.rf.ea842fe8256a24cc31b7ac90283c0534.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-7_jpg.rf.7d9ea75b18a8a124d9e4c5b8c0d455cd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-23_jpg.rf.344a96ecdf1953b41d75f0970361cc18.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-181_jpg.rf.81b204d273d1c61577a2ed1883410f30.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-145_jpg.rf.b66bac78c3ace7ff0581b627c523e978.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-75_jpg.rf.4fffd73d9d76c42db1b9a52f5181cdd9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-205_jpg.rf.d979548bcf99cde1b4fd738528693636.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-59_jpg.rf.d47eb7652eec72d68c970f33ba0c44ca.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-60_jpg.rf.83f2e63a1832a68e993d69b83c160daa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-19_jpg.rf.e24abce72e063aaa7013a5c31ece48ae.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-86_jpg.rf.f02694cd39c9670633568cf0f36413fd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-153_jpg.rf.b97168d6e427bbb6b8700fd4c1b57820.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-17_jpg.rf.e278665a3ef20d6da20075586748813c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-95_jpg.rf.f708fa43e9c73826f0bf8c59b9d2fcb9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-138_jpg.rf.3c30e252ba261749784d56da90f2b333.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-190_jpg.rf.f7bc726fde0a660e25303dcfb8c0e300.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-46_jpg.rf.c331f1da0eaca0f64e4191b3c88d8227.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-247_jpg.rf.e74118f9610b5e7481577c83bd143114.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard2-33_jpg.rf.d081527913d82392ed2c5b0a6e2a7688.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-173_jpg.rf.8b145e8e080f8f84622e3d3eb836168b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-117_jpg.rf.43c0d354cc8ad610f08e31c636c3804e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-110_jpg.rf.94b094fa4979226f0c15744f1b70f377.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-172_jpg.rf.f3abbf7b0d78ae45f80f47239e4f9419.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-140_jpg.rf.9d571d3641721cb14058daa9d578b181.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-17_jpg.rf.ab3b5de295e5ef70a48d636df3ef0615.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-16_jpg.rf.a0c4fbaf4b0e36aa4307966c7aca487b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-121_jpg.rf.5cbdf22ff6898e7d09aa0f4da027d982.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-24_jpg.rf.69f4118b1ddaff8269173295e44daf3f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-127_jpg.rf.5caa8037608bdf81d9284c3ed4dde7b7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-66_jpg.rf.71ed2721a7274939fde118bdc4fd91d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-161_jpg.rf.1e4eed513d2d2f08d0f685529ec0e69e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-226_jpg.rf.d21673742692b4208463180b122622bf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-44_jpg.rf.7db2004ae03eba61c5a9bc89fc4e4abe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-74_jpg.rf.d0f635695fc94598234aca29f8465f88.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-113_jpg.rf.c2a296b97eab7b3025b81eb43c0195fb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-75_jpg.rf.de780a3e00869294dde1155b7bcb0d1a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-197_jpg.rf.fccdc12e0e11eb3cd1c548ffb88698f8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-146_jpg.rf.1b878ff0d758ba87aacfdd972ef0313e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-83_jpg.rf.983978505cb10d2dff6991e4e09cd008.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-144_jpg.rf.2eaaf607902e136a59e7672964b9ef13.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-147_jpg.rf.d3dc1898ed03ed437a5fbbf289309421.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-158_jpg.rf.bb34ecd7734e267b00762bcdf812f247.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-30_jpg.rf.c986c1853ffc7079b4d99787ef83fd00.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/bricks-37_jpg.rf.174182156b34bc672b19fc8ade3712d2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-80_jpg.rf.6928efcd712ea2d87170537c73354766.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters-81_jpg.rf.30eede73b050d5b47db0ce6e707b4e5f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-101_jpg.rf.cfa4ef693f2b4eab1551585a3af4127f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-15_jpg.rf.214d34671eae8a8850b4ca47fa55d4fa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-159_jpg.rf.0ba9a3aec2f5e38719ed620b6ad0df84.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-136_jpg.rf.1418e9381dffffcb310fa530105e0ec2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/wires-79_jpg.rf.6b9ae23b97f92fa222d7ce615b822243.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-3_jpg.rf.4de3f5dc5242ae9199254954a4e1fe61.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-162_jpg.rf.8c9c167f230be5cdb9ab256b90368718.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/streetLitters2-119_jpg.rf.0f604e8eed6e0bc5e1cc78df9e67c602.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-118_jpg.rf.18a10fbf4c343f2b27da380edf9deed4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/towers-73_jpg.rf.b989372e489ef98b8f906e3a53db6c17.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-209_jpg.rf.1f7b5ac928ef28b4c3711b7b6818a3d4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/constructionMat-63_jpg.rf.4f6b44630c0db097fffadfcb8968d1c8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/valid/billboard-132_jpg.rf.c498029a73a132e8b9f64a73f27a1094.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-166_jpg.rf.f303cf11a038509ce214b178699ab7ff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-11_jpg.rf.49f8d59f4b4ff82e4665c62cc9b27132.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-109_jpg.rf.bddf692e9ac8c4bab3303bc94c413873.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-136_jpg.rf.36cea2cd9d2ca556aad0542dc1194aa5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-127_jpg.rf.6af01291917dd50723d25f08ed2aee5f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-47_jpg.rf.02808f4344303abbb8a0ec8a21c7871f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-288_jpg.rf.7f00cca5ca92225860c683f8d39d102d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-59_jpg.rf.36bb7dac7a7f233d298895715a10a566.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-14_jpg.rf.0e800311e82ea75ff3d1c0a6cd981d65.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-167_jpg.rf.7efc5774bbe3badf34467f0059795a87.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-31_jpg.rf.e744e773dbc23de0015089a001298407.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-3_jpg.rf.1621776119062a89042073d64697e0ff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-39_jpg.rf.ba1f41acdf299c1f66e64f3a67a757e2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-8_jpg.rf.8b5bac8d69dd76d1c49fc81549b38aa0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-41_jpg.rf.2f96f4c963d67bbf97b1e65a8e6350fc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-127_jpg.rf.30f777b4e0a64b3169c44cc2f3cec3b2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-161_jpg.rf.367e4ddc9b9b2b351571a4ca7ad91d53.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-140_jpg.rf.eb4fdd6e23e36cd2d71e80e7872cb23b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-250_jpg.rf.1358872695bcc0a2b5d569d9eea8544e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-102_jpg.rf.b52b54556568b650835dab11aa962173.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-159_jpg.rf.78c9bf3e0ffa4250a93189d153c0f6bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-185_jpg.rf.668e1f1134f421c6c4bfa41e664d2e42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-151_jpg.rf.2b0837a1115230547b7aeeda0b5ca8df.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-51_jpg.rf.67e2671b6df42d7fa33f8c42d3653ded.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-35_jpg.rf.ba194bbcf8c278764f94bd3e72b0c4df.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-63_jpg.rf.04194b34c1db6627c85c97838e00fc42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-4_jpg.rf.45cbaa6297e155d4310d341727250edd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-200_jpg.rf.0091f429b7e095410054c79a32f2519e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-11_jpg.rf.22b4654f9116e28e46937575c2b44215.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-69_jpg.rf.45467aa71043eaff0e657471d6f0ece6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-39_jpg.rf.5c65ff81da087bed6b128ab72430d004.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-159_jpg.rf.906086ba65322b6b4b016386eb446623.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-198_jpg.rf.c6319e5321baa63d81292741ca998fd7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-259_jpg.rf.eec4e4213918aa38d9e0fd248a4ea179.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-72_jpg.rf.a22dc2859d669be10074ab495e6ca905.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-43_jpg.rf.38567b2f9346fa3d656bb986512ec31d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-175_jpg.rf.7de81b80f783f9345183c3b426c3def7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-187_jpg.rf.26502ea7748a88bbb6a70aa4618aa49c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-9_jpg.rf.2d21e1102f6b80edacbca709ca273e7c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-82_jpg.rf.0d04c5b727d85a6d0253779aaa401e78.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-281_jpg.rf.eae857bf3caca9bc7c1fdd904656f431.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-92_jpg.rf.019206f547fed68a8a1705d71cd34d36.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-165_jpg.rf.c74ab872e369fb6a1bc952d9a129bfc5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-145_jpg.rf.5cf102d0c5d04787833ca3f109cda193.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-81_jpg.rf.0b4b2161ddba93fbfb9f9d408ce13d45.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-167_jpg.rf.c2f17c52c2f758e406a5692aeb7865e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-149_jpg.rf.2f216353028a4c5dab3e730a4f03161c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-225_jpg.rf.18de150bf5a2a6ad011326c791ace908.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-54_jpg.rf.dbbbdcb534647a046ae8553d1ccd0c50.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-99_jpg.rf.d06613b5984b787325c0cda84a24d561.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-16_jpg.rf.ab6099eb908e1d4393504e7ff77823ee.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-59_jpg.rf.6464908632311dc47b3f77b0f7225694.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-46_jpg.rf.97295a8092a44f1100c8b8763bf16973.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-124_jpg.rf.3ef5f4cea08972bd75aa6988a1a1643b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-18_jpg.rf.cd4d2066ec6ea740c4718b3ee7ab11ae.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-6_jpg.rf.a2b3f7d99c10322d8b5319b32757ed1e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-36_jpg.rf.c568e1f375297317586f42a4a49b2d6e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-99_jpg.rf.b004ccad5b9ecd903c882846b77ef736.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-61_jpg.rf.522af0a9a3014938472f9d08066de404.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-11_jpg.rf.d8bc43e022b1bd8c2ede2663fd965099.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-73_jpg.rf.23cc23bfc3edbc58f31fb98efb80d8a7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-198_jpg.rf.ece825ef6d409d69308ce2b6dd8436d8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-15_jpg.rf.05b78a2ade570714d6cacd06a178965a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-199_jpg.rf.d490dcadfebee327b93ee263426b3c35.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-4_jpg.rf.a2f0451d092e6106cb992273207b043c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-59_jpg.rf.a0f6e2c40ce1046f56e4bb8eecd8e730.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-19_jpg.rf.6f88e94386fae0c806d52e94803b1434.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-73_jpg.rf.6fffb3383ee25d970be9701d65b488d1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-9_jpg.rf.5a958146a575d8b08bf29699757a85d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-5_jpg.rf.15f22c5fa423a4194f1fe79cfb2e3a37.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-55_jpg.rf.421fb0c92fdd2684d8d6930c088e7d65.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-101_jpg.rf.5a62b59fd2e178a4b703073a50605a80.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-285_jpg.rf.0fd39e3cd89ca20e67ed5d361e892edf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-95_jpg.rf.65a009b316e6d146131caa1af8f6a5b2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-164_jpg.rf.b738f48a9f1007b0e7098869c449f228.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-258_jpg.rf.f7db9aa89e75e595e30121a7b5ca43ef.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-157_jpg.rf.cef6523ec2a45bba86e1a54026f82053.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-154_jpg.rf.a124bba1fcdb1a0a8dbf28dce9291d37.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-178_jpg.rf.33180d9d9dc9bf42ecb83177e9f50067.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-54_jpg.rf.a3fdac51d296c57b20461bbb0a829187.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-233_jpg.rf.e88d38e2cc2f5d9a40b6ce77dcd88d9c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-164_jpg.rf.495a4fcbec95eabdadd5964835f1a0fc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-107_jpg.rf.76baf54b94fd90456ddaf8e6c9f117c9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-48_jpg.rf.df869245248312a04e9cb9022efc06d0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-238_jpg.rf.532d7572f86c0205b615f6a7aba47c36.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-147_jpg.rf.e40e903b9b2182b8549c47f5b20af100.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-89_jpg.rf.d55f504ae492ed963427170dc1d3016f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-20_jpg.rf.dc673c284915d437bd189f578153f37e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-166_jpg.rf.93f5f393dab21727d4589300c75bfcb8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-114_jpg.rf.05cd120a8046ba0de18d3fcba0eaafe2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-57_jpg.rf.fec14e746b635a6b57d495da3f9c5324.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-148_jpg.rf.9fd1ec1506328340ae566afed9801464.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-214_jpg.rf.9b516a6d6b63d88fa6b6cc8b694156af.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-136_jpg.rf.28612e83355ac33951608249a1c5517a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-10_jpg.rf.af64a6346a31d4802880dcc2de894e42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-35_jpg.rf.54b048e99896cdbf572554a70c71720c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-154_jpg.rf.f9eee3bb1cfb4649acf2a71e8d4268a1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-109_jpg.rf.2d7b306d112e41c29fadd4c94a8bcd5c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-141_jpg.rf.f4b31fe91187debc475bee7241a9854d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-56_jpg.rf.3ee6b9f8ea5ab7d369f4a6f55b2e3e8b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-186_jpg.rf.f17a3f4fa258071369ab947c25be5187.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-201_jpg.rf.32dd9dc2d690c45820c2161346f794bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-41_jpg.rf.f3aaefb0bcafa4a5ae26d54829d4b034.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-135_jpg.rf.7a20a68f0cd69d4a2433a26e0e911db8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-0_jpg.rf.043ef88d61debce067569c63ac282916.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-7_jpg.rf.30f97c24bc40c1fc9635fe29697c7b7d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-89_jpg.rf.a0e52363c9304843520d2f48cc619ebd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-3_jpg.rf.f4fec8288af0c3614e4a77764af13a60.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-106_jpg.rf.e76b5f88483c141eddb2f398ef57f631.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-160_jpg.rf.042182e73433b6da291bd51fac2c1d36.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-18_jpg.rf.7c0d8b6b13ee946a4b54249b25ffbc32.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-36_jpg.rf.1684b35602fac58d4d0031e49e0a0f13.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-137_jpg.rf.8f9f407bc0d158e8ca57d2fd94488f81.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-126_jpg.rf.d8f494da768ef1d2ea485dd8fefdba97.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-65_jpg.rf.fc51186f5ab8c23ca55ec59b2d961a99.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-68_jpg.rf.e8de98cf5b549b11f0225334bc3f2992.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-68_jpg.rf.fa8bdd8ae83a50c0c4781cd4ae9fc60b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-86_jpg.rf.1c7b472ae8dd84f7ea0bfe007ca12496.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-156_jpg.rf.01f116c28eec9ac7b0f8af65a85a5271.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-284_jpg.rf.9041c37264e734309d696e7598e2871a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-13_jpg.rf.fe81dac46be1ad66e4e47e5b63297aed.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-27_jpg.rf.2dbb7780c4e0c718d12eb40e67565fb2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-19_jpg.rf.fc289ff0aa37cfc7b144fc2399d34da4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-22_jpg.rf.f304a1216ab13ba8c763a8fdbf409984.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-58_jpg.rf.e345b6c9782a07dafa72f574f73b8d56.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-108_jpg.rf.3d11c40695dbff42ea0fdb9bf33875c1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-124_jpg.rf.a6bd4162a1d75948c0dd590d80c6f658.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-185_jpg.rf.bb8dec5024eb038a1ba52ae6ed83b21e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-78_jpg.rf.96cdf441b824d4e3eb6854329ac6d7a4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-17_jpg.rf.c78ea3e288538e37703776aefb3cf865.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-106_jpg.rf.58c756d1b8fa34b2a4715b0a081b14d0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-221_jpg.rf.8b7975e366aa1ae52c12d4a06a74d67d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-134_jpg.rf.aa5c1a90ad7ccbf06d38e515fa525920.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-17_jpg.rf.fb3d1579f0f0ee4a78cb7dab1630404b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-162_jpg.rf.59da1a3a91c1e74d85e4ff717683e0b3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-53_jpg.rf.e2fdbc5250d53b6edb4debfb962e5b6c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-96_jpg.rf.257ae64fa343dbb3c4a0a0b2d8a99a05.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-10_jpg.rf.17ebfb1c6dda2328bbe7d622ed7bd686.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-32_jpg.rf.09115e0bbe38f608e8677b1073918df3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-92_jpg.rf.211b849ace020ec9c2d75335c7efe0c1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-34_jpg.rf.43f3ec2b4ff20ba1d8f80195cbb9b7ce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-189_jpg.rf.58e7695ab1ac9dcb67c3f8cf8c3f8550.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-266_jpg.rf.9335266b57c74526dabdb031f1876c58.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-159_jpg.rf.488f515fb1158990336879bb571d2ec9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-54_jpg.rf.9d3b77e16cb5ac351698aa75ec34e90a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-133_jpg.rf.aca524de725691a203bec90cad435486.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-37_jpg.rf.0dad75b2afa474603f33a750a13f4e3d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-15_jpg.rf.c0b66c4d2b4e81794f2a21e122e759f9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-177_jpg.rf.2dd7e98915b345f9abf978edba2c70a5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-48_jpg.rf.a36f06e2f657e3279aeb8f9d0edffcc2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-182_jpg.rf.e8b2ac9ec49004893dbd8a60ccc8641e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-156_jpg.rf.b946cd450b8bdc58db4d382179f4586b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-46_jpg.rf.4873461e022a2176d60eeb9b75ab127f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-37_jpg.rf.32ab6164e4764e38dac76b2e6ac9c4ef.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-123_jpg.rf.e19754640a99ddfb8b902d4d00ba24fd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-143_jpg.rf.4b8d48a3b69cc308eb1938b948656d86.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-154_jpg.rf.6e820d752fb5071e01d09f0b6aea0134.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-41_jpg.rf.ac0a4407d0bc6f3bb3935e1003f8c2fc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-16_jpg.rf.9696f88c608b7d7af6aecd333068508b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-128_jpg.rf.6182a426b1ba3c7ce158aba96a636911.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-175_jpg.rf.d18fff08e1d784e9b89f9dbf37cdf3b9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-12_jpg.rf.d6db725f9b9cb3be0c2deeddd45845fe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-107_jpg.rf.b7777deb4f7655b5cb23cd0c23bb6234.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-20_jpg.rf.6dcd984ab23d854ab27066ebba2551ec.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-89_jpg.rf.b9111abaa0bd42f82a613578cf636da4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-104_jpg.rf.8a5b5744a916eaced0d1478679610fdf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-58_jpg.rf.26e534fe115672de7de86a15d8cb4f80.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-292_jpg.rf.f1177d3d3ba2219f3a76fd35aba81497.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-66_jpg.rf.8bb6ee2759b546d690cff3c165708fc8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-12_jpg.rf.35a8d1594db1d3a9db39118ef30ab51a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-153_jpg.rf.915c3ba770f90f87f8af21f75864f3b3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-4_jpg.rf.46efcad035e2e26d56f74068379f6dc7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-26_jpg.rf.4365477c9d20c190a7a6c50cdc5a383f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-97_jpg.rf.31bbfcda2869f612fc59756a6bf37e12.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-183_jpg.rf.71cdc1d35e84279ac6b37b1c33c12fa0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-74_jpg.rf.67b47e763105de2c2b07c694080ca300.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-61_jpg.rf.d671efa84f8f70c2c2e5594c30b9fb0b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-38_jpg.rf.84c6b33331168b9d7a99abd7a5deac03.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-15_jpg.rf.52e9af2a9779501dfa6bebbf3bde6629.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-203_jpg.rf.8149df946cdf31ae46c95676127adc42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-211_jpg.rf.e6d719e77818b811e72e529f3e2b4467.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-182_jpg.rf.3a520b1fed0982adc752ae48f5fd5497.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-1_jpg.rf.c70d675d92e3f6f0a69edc251796b0b8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-217_jpg.rf.e55a470c004bd2481ae675c548d733e9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-252_jpg.rf.3bc7e4b2868cf0eb2f97af610bc61bdd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-154_jpg.rf.fe109a5e8b3c649fbb9b57c47e54acb9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-162_jpg.rf.fefaf6d5354bcac2a054f2562e9c3588.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-93_jpg.rf.4666b3dbcc1d924fc157506f8be1a909.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-228_jpg.rf.f89e8dae32cee8cdbb88a451063553ea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-175_jpg.rf.aedea0fab74f2250dcb39512e86f853d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-142_jpg.rf.130d827539991a9daafd626b31537e94.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-8_jpg.rf.a54f1b80055c98dab3e3f79bf04bbdf3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-86_jpg.rf.9ac3cfb4b04bf8cc7cb19fcaba8ee267.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-68_jpg.rf.5bb563e97a9cab8154e62adf3f0dd707.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-13_jpg.rf.9f4928a189064f0caeced7cc6937fdff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-275_jpg.rf.68a080ea0a3ab7680891e16d43f4d42f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-239_jpg.rf.321c2c661b4ac798dc9a44753d0e5081.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-45_jpg.rf.ee9747f162440f73ea2cbd0d950e926e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-52_jpg.rf.eaa2760cb47aaeafc7224a27b7449eef.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-178_jpg.rf.40b822cfc516645aa8ad3afc0b8ef9b3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-1_jpg.rf.bd7ef3dd7aa632659470544dffde295a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-178_jpg.rf.73c555a46b78910dac735b2b4f12cd58.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-67_jpg.rf.eef63bbf19a2e352a0e826cdf3938486.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-179_jpg.rf.cacd511df9f750bc63034c083a7c3974.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-234_jpg.rf.4d1947a5a7b479016e32ff6ff3b592a8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-16_jpg.rf.9bd0fea37d6ea1879f8ae9bbd546bef2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-177_jpg.rf.5ac55742d21a0290fed41d93ee6010ec.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-98_jpg.rf.e68b7de84bf8e4344ac0052a527625d8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-21_jpg.rf.33b3d52b2610c464b0d6bc240f03be5e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-17_jpg.rf.ae47751fa546f55b25ec1bb11a504448.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-60_jpg.rf.4f075b602771781b2937f213eff1bcf6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-197_jpg.rf.8d9d2675cbcd46b77021978c6588a128.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-88_jpg.rf.90821cbb167502a8cba5d20a78432a43.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-187_jpg.rf.84c48eb59a7dcf351fee52abbb5c6a02.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-120_jpg.rf.b31ad275e4f09ebf393ef2f7fba4f9ba.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-269_jpg.rf.d4917bc2c295e2eded10c4582d7da1e4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-102_jpg.rf.d5fcf0dea8b52799cf79a38fa5f812bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-78_jpg.rf.7703294dc8c09a612757253d1e319ed4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-205_jpg.rf.298a9702737a4dd53198c37c599f5721.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-176_jpg.rf.7d4104ea10e2150b6ab133a291700cb3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-177_jpg.rf.1736a39e0b6d8d01df40898a7dc33f0f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-4_jpg.rf.7edbdb99fc57854af804d770ca01eaf3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-50_jpg.rf.63a197ff9b957125dbaa21700afc6e92.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-22_jpg.rf.78ee5773252414657e8fc2269734492d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-151_jpg.rf.7b09cb7291b67793b998654b4e3fd6f9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-116_jpg.rf.4e820d59ccf0b8f639414491e898c12d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-199_jpg.rf.1940bffaac18333a6d328b430c9e82c2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-28_jpg.rf.3f2d9385226892edd2f7727985a3610c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-186_jpg.rf.b71ec2c18b99f99d05d8d2e438925b41.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-127_jpg.rf.dfc8b82dc12fa928fba0dc3055b0d7ff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-62_jpg.rf.19877e6f6e1f6f40856a8aa06c148e74.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-81_jpg.rf.fc88d781872a0169642bbf0c22593726.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-59_jpg.rf.fc3cf8b6811f3fbd6031a86660260c4e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-181_jpg.rf.3e7b69cf7ea14d6d4e4b95d4e988f293.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-95_jpg.rf.0fce1db8f24424f4f72be85a606782b2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-152_jpg.rf.20db49089ce235803180f4d495f28bef.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-55_jpg.rf.0819a79e1db98494ed2061ec7283f63f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-210_jpg.rf.38a180e75ccd7ffab0ea181a88bb66b6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-141_jpg.rf.dae8a72aa2cbc22be106dfa2814ca18c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-60_jpg.rf.00e27b3abede3f089c02fb328900d3db.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-128_jpg.rf.00030c5fa564bad009ea2a13b3401c16.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-208_jpg.rf.52a1acd18ea2ce1861acfe441d867461.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-3_jpg.rf.308c1f5905288308a646b8de929ed46e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-165_jpg.rf.7336df229a7b26d4263303477d51dd76.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-188_jpg.rf.a349353b3ec680e7c83a390af843d328.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-164_jpg.rf.42190f690dea8ddfe10da5b1e1074eb6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-47_jpg.rf.eefd1a5bc6b363a88a2d85626a92031c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-170_jpg.rf.3ba74ce7fd93379604d4a1c64e91ac44.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-47_jpg.rf.f703230a3df3ebb95d63cd8cb58dd4f7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-129_jpg.rf.f92c240a60171703a857358fd53eb2eb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-46_jpg.rf.6e7907af5ffdd81dc3a3fada708e7eab.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-49_jpg.rf.c060c804ac46420c29aa3118de12f639.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-29_jpg.rf.0387615daffbc69cc5109ce4bd9db1db.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-165_jpg.rf.56920dd3965e900914545b0ceb7061db.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-90_jpg.rf.ffd26ffd5d638d125e89f0816366b4e9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-173_jpg.rf.a71f82f7fed2f8b87687274090a3ae73.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-21_jpg.rf.f1c37a8733b45ca693795c3731f7d186.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-122_jpg.rf.fda22519be7fe9698ddb3b38fe4d9ad4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-43_jpg.rf.ba95f826a0c2bf338b24272ed83b1656.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-34_jpg.rf.d5f20e8b383e59032610df6449aa03d1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-37_jpg.rf.316f7d84aae3be96b6b64a50185bded4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-155_jpg.rf.3bc2845ea59c35963f402f4afb6986dc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-58_jpg.rf.a5198ff419dda0608ae6308351556130.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-137_jpg.rf.f54730558d053ad1b74f09383925fc7d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-108_jpg.rf.7bb72bb4bd8e5fb849ddc6e49bf6c218.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-112_jpg.rf.d5178462b1c480a1c7f5c7fa561c2f0d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires2-108_jpg.rf.d5a1ad74562abb92dd6f9394f658f860.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-90_jpg.rf.40f9826582ecf2629ee7423980f12c5e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-130_jpg.rf.fa65e2142d0904af61937641ce2dab1f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-61_jpg.rf.6b43884ac4d54a29845396817257d6cc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-133_jpg.rf.6a4d3bc5991fcc082db54e3871430066.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-160_jpg.rf.d6e243bc4972a0ce0ba8deed25aa234e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-141_jpg.rf.7fede9d2974ec5a840b9d8a96838958f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-30_jpg.rf.29402dd3c6899d83854af5451e93e67f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-60_jpg.rf.24f52a01e996593965bcc0dd04e11b90.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-214_jpg.rf.8ae744a5300ffa08998fd71ee95fd6ba.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-70_jpg.rf.4cc837231d3bd228617a31a2111bc895.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-103_jpg.rf.a2d6e6dfdd2821dce237809a79ae5ed6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-144_jpg.rf.f25a9d010d5f8838c44baa3c382c706c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-133_jpg.rf.88254ad69e3b60b3617efb396ce1f0f5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-75_jpg.rf.a219fe8c7e0de8736d7380f4b2f22965.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-4_jpg.rf.93665a05e835a43b8da53bd29853c65b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-3_jpg.rf.7067a4d389deeb761b0a745308ea7ff1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-57_jpg.rf.795b3d393dd49ddcc23c173db161ed13.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-183_jpg.rf.6b67e54aaf8626ab1067d85b9e88431f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-240_jpg.rf.a39b5ed9c358fdd2ad21cbd1a3e45800.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-261_jpg.rf.d2e2b3b67987ac772ea20f9db17d579e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-104_jpg.rf.6f42b1f138c5972caf2b50c78c1818e2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-94_jpg.rf.ef25ffaeccf174e27f842a7a7574fd9a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-117_jpg.rf.278dc8faf921a7429d49125e6b9f1919.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-123_jpg.rf.e70051c459d1fe203965272b0131819f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-96_jpg.rf.9443ecf322ac4560d0e68bbed4b44f0f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-61_jpg.rf.8a002134a92c95c8da1060013d5f5817.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-74_jpg.rf.7c28452d0f309f4c2f827d4dcee925b4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-30_jpg.rf.f86acfee0ea24dfaa8d4c96deb8165a8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-36_jpg.rf.df9087aee517c8c1b127e8a9250f6562.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-42_jpg.rf.cb42488ab84b6104bde2fb07527e0616.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-243_jpg.rf.342636369d0a4a173aed9b833bbfae16.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-32_jpg.rf.980950be226dc64e02dc00b7e455aec7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-89_jpg.rf.a5d442fb41c6e9db9d469d82e72cbc69.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-2_jpg.rf.297a10afbe26a72cfa423f13eec33400.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-217_jpg.rf.583e77ddba1a7fe06c05f0b15aadaa32.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-182_jpg.rf.a01ccd2a0e42ebc498a7aacddef40498.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-117_jpg.rf.28c24a9034bdc37534eaac696939b51c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-200_jpg.rf.88fabcc8aa883a87900a4c3cee04d240.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-86_jpg.rf.c2a9684f73e39b47858183766a018a17.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-305_jpg.rf.8213a2ac9cde8fd4c918d90effddd395.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-168_jpg.rf.d88efe1d1f28b400f79adc1246c5c9d4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-274_jpg.rf.a4a0696df8fec812430223c02e0c32c3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-153_jpg.rf.b0f5027222c4dda02aa638ff05e694d9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-37_jpg.rf.00d69cb4c66113ddf968f68e2ef65531.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-283_jpg.rf.0f7d7ae88d51ec18cf54aa33e5e74688.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-215_jpg.rf.fd32580082c5c9fd4c051516d97e9f2e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-272_jpg.rf.5faa279ad462da123278def06492babe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-150_jpg.rf.60d6f16399a02f92bed364db6bbca907.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-32_jpg.rf.89e2b9a5d8430a87436c9be180d4c9eb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-52_jpg.rf.b46c40144e70ede85f604ef8d0060f88.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-218_jpg.rf.c181d8caede45ab8c316b7bc4bd93f8c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-262_jpg.rf.35f7691d5a7c5b86541380adf61c5cb7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-53_jpg.rf.587cef6121982017581cc46e7263aee9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-289_jpg.rf.5b2a09d17f8d223ba03751a44808da33.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-9_jpg.rf.98a9f68ab9c22d0b09b808bdca895be4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-17_jpg.rf.9b2fd2fdffa9a597be0e7a639fca8d38.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-4_jpg.rf.9ff63c649639325b77c5a2f4bf9b0631.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-99_jpg.rf.74dbb421a0197c9a5cbbd28b6b3dea52.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-51_jpg.rf.92f08a8bac16746f4d3428c0eabe38cc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-112_jpg.rf.92c571ebad6cff5e77299ed75bfec244.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-81_jpg.rf.3238eb681407f5b91d7d38b56e0c39da.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-114_jpg.rf.b1448cbb7dd53e6334f810a1271d9ab1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-94_jpg.rf.4faaf9602503b020068eecd4911b0dc6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-80_jpg.rf.71e6989947a650f293d2823317f0ca07.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-96_jpg.rf.412856ba5ce86e284ef46dd4406cbbb2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-142_jpg.rf.586fab0bbda018fbb5f7a03857a71e7e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-137_jpg.rf.64eeb960cc49964f64fb5d25736201fb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-125_jpg.rf.edaa7558751913d2d9830873e83cd72f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-121_jpg.rf.8b940a50111bde63f6e2d86984f023a3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-95_jpg.rf.e392e9518a675f1f4c549f479d3c44a7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-62_jpg.rf.ffbd33d46eb2ace622955aeca2280e31.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-128_jpg.rf.751c5962ef405624585622bdae654670.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-84_jpg.rf.0ba2d3565a59eee9c336554468c2c145.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-65_jpg.rf.8752a8cfffab2180ec0e3c898854db6d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-38_jpg.rf.ec48e8d68550f29216f5fec153ad1be5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-39_jpg.rf.2c0176e7f9d5b37e70453e6ac15c972f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-19_jpg.rf.bfea436f150df249d5d7c80d2f865eb3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-35_jpg.rf.ac287cd9fe3360249cf6e39c21b4a346.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-102_jpg.rf.9e06a8778068ac89a41359d2bbd41322.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-158_jpg.rf.c03c1049b34264a0bab5f7a5f4bbf98e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-77_jpg.rf.451c20b8620eb3dbe1e6608eaf5b099f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-10_jpg.rf.9e352ecef7761e3205fb2f93492a760d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-116_jpg.rf.ae74d4bf5820e488ad8a304cf08316e9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-294_jpg.rf.3871be8025fbc0b2284be9c34bcda55a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-26_jpg.rf.a2f96a63cbd9ad6ec3f60144771dae94.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-82_jpg.rf.cfed98ad50488d98c0a78ca6719bb32f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-69_jpg.rf.5950f024d3b5be53b639c7c932383d99.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-27_jpg.rf.b900d46c01d5e8f99acdc94e88a49614.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-9_jpg.rf.d1ad463299d109a8c9c8900f88d0a5c2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-83_jpg.rf.c04596fb8995f9a7de5aad0ef3d5a63e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-150_jpg.rf.d4021bd9e2a0ede5fd99e8c45b4bd2de.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-157_jpg.rf.5c67ab1811f5a3c3db1865b906360506.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-64_jpg.rf.00308467d5f60bad42959786e9c42c47.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-172_jpg.rf.d2e75490d64efe3ef856029b266b1f6a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-36_jpg.rf.9b15081d5cb0ac7bc5697d6680296bfe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-110_jpg.rf.5d2a00cfd5ce7644a76e2f9aedbc05f1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-57_jpg.rf.5419324cc605f8aaecbecef84fe7b969.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-86_jpg.rf.6bd1f6410d3d57b7f06a29fa3033f23b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-92_jpg.rf.101df846608e2606868354aed83e92b1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-206_jpg.rf.56069e2ad3abb83d80f49b29d78d989e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-33_jpg.rf.c43d8c9880fef7b2bff69b7866e35fbe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-207_jpg.rf.a46794baa6d8c84669ed530614ede3c5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-187_jpg.rf.5bd4ad80eb7998c82d7a50edc7609544.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-160_jpg.rf.cfcef2f7aef7c0d600dbf1b936316ada.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-293_jpg.rf.11f09d89bc75eb37a67188de9c28b6c1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-43_jpg.rf.a5161467438d89a8f998497f68da75e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-106_jpg.rf.8ec1190fd89c319dd52a86fedf24906e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-140_jpg.rf.a45f01397d7c96414d7d4c576b50164f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-103_jpg.rf.e1c401b9f0638b054e8f8d1435f91bc7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-129_jpg.rf.8208faf0a5b34c3a854f89ec49a670e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-178_jpg.rf.43c1654e3dbf5fc1232e50c2ebc02a66.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-121_jpg.rf.f5c2b735146550bcb57cf94ddf314384.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-19_jpg.rf.d15ceb8b0f800b1933e83cdb7dc9e78f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-13_jpg.rf.7b26e8c307b205ed6a2bbfd58e1718da.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-175_jpg.rf.10dc79dc4e1fe4abb876b47174487048.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-151_jpg.rf.8761a913d0f7a61c87a8a65f1d33920d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-113_jpg.rf.8a5d998cc71ca747999b1ea8a447e562.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-287_jpg.rf.4abe9b1aa56c7cc4114672736f218cea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-85_jpg.rf.d3d02ea1c279967b746189e276a1dc37.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-180_jpg.rf.53a76c6cdb121c5c35c853bffa7adc38.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-71_jpg.rf.ea9967db291955b7eac05f45ca20dd75.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-31_jpg.rf.92d0adbac750c68ed1a97a4fb31329b2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-5_jpg.rf.4db9be375cf43ebb729425f545d723cc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-176_jpg.rf.10cb9bdc8f062fd6b026dbb754b4d8d1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-136_jpg.rf.1a70234e1acefd6b0639e76dbc9b5b77.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-183_jpg.rf.ce09f9956934b2b1e5e8292ed60351fc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-90_jpg.rf.c4d712e9db382af37ab3fcadc249d2ba.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-96_jpg.rf.86c455085ca23cc4b2ef61191056cee1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-57_jpg.rf.1bab88cef3fafab4e7ddce2c62d653b2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-35_jpg.rf.93808c8e1d9601b7e98d5a57035d84b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-140_jpg.rf.96970a1e7ff6a9679f68cc4835b734e3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-22_jpg.rf.d2b1e6883bad5d6f1fba3732035d44dc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-10_jpg.rf.faad0cba229ec3e5e5ca4be55c09e663.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-166_jpg.rf.813d1fff4abab118a50c15808cd744ce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-118_jpg.rf.431c28ef580c3b70804f6e7cfaaf3fd5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-273_jpg.rf.616406be4ea1f28af3d91ffabfa224b4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-216_jpg.rf.fdfc3f25ee77631b1069cfa81885d0dc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-242_jpg.rf.17c461f2e6fa0622892eecab3d4a76d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-130_jpg.rf.a574ca3334965188b854903e80ad0e29.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-137_jpg.rf.384608ce88749481a936fadb40fa519a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-105_jpg.rf.fee63ebc93a833bb6ba31d08871d14f6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-7_jpg.rf.a8e65446226f347b07406d17a18fedfc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-54_jpg.rf.b7a4b2151994219610b6feae394c9d09.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-23_jpg.rf.edeed5a3786f3f529adbf2037d88f5c1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-157_jpg.rf.8510d44d3708fe6237b28d98c6816931.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-148_jpg.rf.7a33fa5ac436e538ec833dcc4bbcccf0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-93_jpg.rf.5d543979f3c516fdf7d49569461c9641.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-22_jpg.rf.80694a758054966d59209cd30b93235c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-195_jpg.rf.93aab9ff91b1d2a4de3d767896a06bd3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-161_jpg.rf.a5869cb72f1757f8f5feb9320463285d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-180_jpg.rf.55489834404c606f325d4ed7bbae8817.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-94_jpg.rf.35ba85dc2f5b70840e6d9f470f0cc64a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-30_jpg.rf.e5b16f02ddb0081e12dc98edc6ffbb80.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-165_jpg.rf.6f4077e8ba29030a5aecdef10b578b22.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-112_jpg.rf.3d8917e62df484f9f415097a6b4c13c4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-186_jpg.rf.46acc08160b616f0c5426253e04e6ffd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-109_jpg.rf.726b3bdaa7e65079fa1f3af896fb689a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-60_jpg.rf.9231b509df627225c20dcf7985ac91a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-193_jpg.rf.bce9946c0820d011c32aa062dcb30d18.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-140_jpg.rf.181c874df6eb3fa37ee27f68e15bb976.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-56_jpg.rf.a929fb749bb1597f786734b3725b8277.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-37_jpg.rf.4cf33931f38aeb0a162719ba7f866eaf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-179_jpg.rf.18dcf06cd061744347c671138a7aee42.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-90_jpg.rf.1ffd5f6cfe6c288dfd51bcc86225a0e2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-195_jpg.rf.6d27a7a15053d643587eced0f0bb7e7a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-209_jpg.rf.7cc76797ccf032f8f96b884ece55153b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-104_jpg.rf.d7e8f484540d0423a430113a4e043735.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-118_jpg.rf.594c8e16c32e51fd29c9b116545e6898.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-96_jpg.rf.d2dd489923473777a524d4fbf5518b77.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-105_jpg.rf.62bbc8c1faba5ad2c75f6d1c239ddd71.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-216_jpg.rf.9c6d51283325537301c5dc1b92b7788d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-180_jpg.rf.884e19fdc7e8c25a3efe6dd06b0b0515.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-145_jpg.rf.f8885c56b16ad4cadb481452f5862d21.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-115_jpg.rf.85768de79757d14146dc5d4c7bfd23af.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-112_jpg.rf.592236daac71dd466b257e1f73100577.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-107_jpg.rf.d77afcb3fa871055712965ea96126795.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-6_jpg.rf.0cd7e9feb6538bebba409eeea7c3b0d9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-119_jpg.rf.87776757d782cea45a9ba483b7186ba5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-123_jpg.rf.bd36c23d06c0f30dc7a84184e7bb679f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-64_jpg.rf.3cb03f17211e1fbf7bfe0279235fb98a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-177_jpg.rf.933d239b490e484e599475ff02c6832d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-22_jpg.rf.3492a25011349ceee8626bd01b47db4f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-231_jpg.rf.84826c04a36a7e7823be0fcdebb41f49.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-131_jpg.rf.5ca1e4e89569ae270d2318521fbb44f4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-27_jpg.rf.8879323f12e72292eacbc469063a5a1d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-156_jpg.rf.ee5e3a14eae92ddd5ab3f46589932e4e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-82_jpg.rf.219bdd3fbc4a693fcbd67d223307cbbd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-282_jpg.rf.d77621990e961ff6fb4427eaa5cab766.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-53_jpg.rf.23395f84ddf6fe2e444631e61b71bce4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-212_jpg.rf.f89119dda2b111abff373ce3339526f6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-138_jpg.rf.035d07cfc961b9ffb38e28ccd2bec599.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-40_jpg.rf.cf7815c623be2426eda463f592853fc9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-148_jpg.rf.aec51e10c1ec94b16c916c61f7924281.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-270_jpg.rf.693a13547e627c6fce65fde42dafc4bd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-113_jpg.rf.a8bbb2f05be659cb655f47be215c98fc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-184_jpg.rf.f0cb56b5f8fe3c1b76286c78b2d00587.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-142_jpg.rf.24516476750b9cee76b7e69055a49c57.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-124_jpg.rf.3c3c4d5e9a1fc07f77e00d53ea2dfe47.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-129_jpg.rf.570bf4a2b0e48bda6c1eadf57f6614ae.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-64_jpg.rf.a29e846738c2816a1256a032576015dd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-223_jpg.rf.8ee9f6e27fb5755543d6ed125db9e9cf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-174_jpg.rf.5c95b1cf7339e32cfcaa961cf2bc75d9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-115_jpg.rf.ea30b3102823520da7b83c5883f8f8e9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-110_jpg.rf.a4ce105d834bdb1db40df522ac84371d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-92_jpg.rf.354cb44107216c06398ca005cdda1733.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-42_jpg.rf.6336a60d0287b7e1d824daf55d808404.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-278_jpg.rf.4d4fdc296581b4cc36da3841ecc35575.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-152_jpg.rf.05d647feb20c2eb8f0dd34a9d0f9f9eb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-45_jpg.rf.6d24b3ca482cd015757488dc217d4a61.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-44_jpg.rf.2bf4bd7e3fb7f3faee0d165484202779.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-64_jpg.rf.7883040f404a9eeb6aab309425a52c4a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-3_jpg.rf.fda7961a6a2b0221e89754d91cabcd55.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-153_jpg.rf.204a36932c3624dc0c513dbddd8a07cd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-139_jpg.rf.cc2ee35e558ab7162341a6df65131dbe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-236_jpg.rf.5ca413a12addfb91251ed0b18edbb50d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-122_jpg.rf.84ec6cf7c436a4b4365afab3678ac325.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-106_jpg.rf.c97f77e91adbe9e94c237a08656a43e4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-154_jpg.rf.cf3a07894734432f7626d83f0cf5eb73.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-163_jpg.rf.1a1a14ea561d609653c7eac80a3026db.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-42_jpg.rf.63eff4570fe4c3f40c2a4de88c0fc5a3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-106_jpg.rf.1ca5412f44388377c0901be093f11b4b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-295_jpg.rf.d3018adfb30dc2d698dd246486888d0d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-49_jpg.rf.018a4e5304b2ad2c1a2b0e24b37b151b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-40_jpg.rf.e0689c38cda4e08b2ada57a0ede85770.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-83_jpg.rf.3af17f323d42e9345ffeacb57216a112.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-124_jpg.rf.9aaf1ebd742d2bbec3720d8f653cdc23.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-185_jpg.rf.ce05e2bc33f5764a7261820c5c42a9ce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-76_jpg.rf.ddb3b7ffc96b11a4f61967780e9b0d1f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-302_jpg.rf.6f6a568fc0d2e6d2790a9c1e95c78d40.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-67_jpg.rf.062ab00034f38c6cfde84a2b17bfc5ac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-85_jpg.rf.ab0451e1084bc0f754b8d7fc69dcbd41.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-7_jpg.rf.7eac78b414ff6b4d0cbff88227644970.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-102_jpg.rf.84983416a5558dc06866f7ff84d56120.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-171_jpg.rf.1765ceac4280cdbc876a45e720e15557.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-101_jpg.rf.0499220d1435e3cc27964cd7aba198d6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-102_jpg.rf.cf700aa50c04a0b79a57e28c52fd0be2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-68_jpg.rf.ecb49b329b82790408566d35823bdfa5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-63_jpg.rf.9567616f4dd134c6874c74bf815bd91b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-211_jpg.rf.593646e964001249ab4bc6a1268ee336.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-1_jpg.rf.4029f4dcc75405e47d2e65fb6b2310da.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-76_jpg.rf.d1dcad9659f616113f214332d3bd7956.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-63_jpg.rf.7bf2c31268116696f013e476f56f02c2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-196_jpg.rf.8fc11a901140f5e1dbcfa1743915e1c1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-169_jpg.rf.ff16208a5b049ea26dbd063307449921.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-134_jpg.rf.71e7fd63a0e5e21e7638ffedddeed330.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-69_jpg.rf.e1bfda9e8be307130f2550775eed1a2c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-30_jpg.rf.ba3cdca43da0f753c03367c091ea6bb5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-86_jpg.rf.618ac925cbdf988d85bf0ac93f901a00.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-165_jpg.rf.900078407dd18cf5f71570efb853e391.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-134_jpg.rf.e008e3ac628081faea21680a7831a273.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-68_jpg.rf.3620ae3ddfa58cb61ee420d39016564f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-303_jpg.rf.b667416eccbd53158879ec410887b26b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-164_jpg.rf.23d9be5937c101fa548cb20759952f10.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-110_jpg.rf.e0c154be3c5d0ba84d3517962d34f8ac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-125_jpg.rf.dca348a672573a44ebfd4314c202facc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-98_jpg.rf.936b9c5854ade9d7a9f9a7ad16218217.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-151_jpg.rf.f747e8d79051041caa0bdcdfe8f86582.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-97_jpg.rf.6be9588cad4110618466902120259353.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-48_jpg.rf.b98e6e508288c5755b101bf3bee317d4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-192_jpg.rf.dab698920071fb30f62beac74ad54621.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-260_jpg.rf.ceccb835f123d10d2eb8a8e27a1c240a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-34_jpg.rf.1cb4333449794949255127e95c35ee37.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-80_jpg.rf.78e91b5c98011394fc193445f4120a88.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-78_jpg.rf.5ecdc9a6cf8365e1610b54c5abcc2ffa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-15_jpg.rf.ebcd38ad18e768dd734f3339a9d5e1f2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-241_jpg.rf.aaca2ceb20a07e4fcdad4c5c1e080478.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-193_jpg.rf.cdc8428b6de7456f7a3f4c8580cc82b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-296_jpg.rf.66dcc8f77d2abe9206e619292cff3476.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-25_jpg.rf.ae18e6127bf3b18c9330d583639513b7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-101_jpg.rf.6df4c7283e335d77bf875e4b42132591.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-61_jpg.rf.98b40a6442fbffd21045dd29b38e2e4b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-251_jpg.rf.e4e9c8ceec09f4a8bded5729669ec4db.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-112_jpg.rf.e35a23a641e2f2da32dd8fa10d08a452.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-128_jpg.rf.343f91ff827d10bd5c19a7cf9fcccc0b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-127_jpg.rf.5b0bcdb461156f506a665bc329db0857.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-143_jpg.rf.cf0be0b9bd37b1a1de7647c0903779c6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-29_jpg.rf.5544f4153678d14fe2edcf3cff6ca0f3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-143_jpg.rf.5ecf0bf9c09531b455f2e02823880eb3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-33_jpg.rf.9664f64be141aef3243424c69108198e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-41_jpg.rf.3ea9520237482f7aafce84861c4777ad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-66_jpg.rf.f7a9e967e93b11d84373a9d1579792d9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-196_jpg.rf.aaced71f65980b71a57b23bacf0fccbf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-197_jpg.rf.0eb8574fe1856dfdb0e9cf35f2a1efd7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-58_jpg.rf.723c1b2e2c1e4f9e73f87dbb771feb0f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-137_jpg.rf.30a620060b490b2b8cfedd0ff358d49a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-147_jpg.rf.4a620088083e05df044ec528f9973a2c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-73_jpg.rf.6e3121b4210bb2543f5294c0581ac8c7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-227_jpg.rf.78351a838c23ecc9e8a911999d5e2934.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-23_jpg.rf.f77f719083bb33f4da3d04a67a8e3484.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-152_jpg.rf.ecedc4375fd21a1ca277d8a455242de8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-136_jpg.rf.f94e0a4502afd785bb8b4ba6fc9a0f20.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-171_jpg.rf.64a8d8cce7ff8d6a66d3166af903e649.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-84_jpg.rf.6afdcde0b04bae1dbd84bc4bb4965dca.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-198_jpg.rf.f09da0404234be2ef888bfe03d174cac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-174_jpg.rf.b0efcf7245db6d5682454a605d4ea539.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-87_jpg.rf.acb857ab469b6cb1d1eaddafc9edb4a5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-138_jpg.rf.b853ab22205c8f0460664edd7d9d10df.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-162_jpg.rf.0358ff930fb09c451baa17ad2329f092.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-141_jpg.rf.97e5ab78a5d6603d09ced9dd15c4e353.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-101_jpg.rf.2b7030037367ab709cfb0ec3e6c60db1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-200_jpg.rf.7b1bd98e04970ae73f53951157e5cfb4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-40_jpg.rf.2f0622c57acba704cc97d7d67e9c2564.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-182_jpg.rf.9da727749111c6b29b070b5501e34a70.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-230_jpg.rf.0a6e74023461c9e26c51b7bbf6516fe4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-174_jpg.rf.3fe8c576ef339c8f0104f5bbccdc3fa2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-42_jpg.rf.d052805a293acfc1868e46f8ddf594a6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-115_jpg.rf.fae2384d2efc0b8233bbec8810f0db45.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-13_jpg.rf.00cafd00a8aec93d219af5a036709ab5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-195_jpg.rf.092acee891a7e0c3ce2cc7d724762b5d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-43_jpg.rf.b0abbbd056bf84a96c6bd1abef6e94de.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-63_jpg.rf.a9c91aef705f87631622c7f5761d97da.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-245_jpg.rf.4d864ebf22eb3488d0adbc2719262122.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-138_jpg.rf.388b5e26a4ffc0d96352a279524042a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-163_jpg.rf.faec778b6f9cdba6d94f4429057b185d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-38_jpg.rf.65701180a798bba394c4c23e19c7907f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-120_jpg.rf.adfd511d8fb06304fa679c3cd9aac5cc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-48_jpg.rf.4c4dca0ce48c5b4406ee11530dba96bd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-56_jpg.rf.150cb168a71627b808218e8f14dc8fd7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-189_jpg.rf.37502e1c02b1a562ab0f65ba5fa156dd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-54_jpg.rf.dd43251f7e230f9ff4f2ed34eaa3c306.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-158_jpg.rf.ce9e280b1347b8e7aa4ffa576c207255.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-192_jpg.rf.df8e3d90fbd5c8fb0032f7d747d31c79.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-144_jpg.rf.934ee61abdbf696fe73a1c58f558283d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-24_jpg.rf.1c3db991bf2d7d8b0441fa92273eb55c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-70_jpg.rf.3470bbe81334357bfa988a5c97dc9929.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-181_jpg.rf.457e6e66b6a4ec9016d7c35632cecf68.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-27_jpg.rf.4db602cb8f8e8c38e7cb34dc4e09d643.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-126_jpg.rf.71ae979579fc53ea93adb82ad7f177ce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-201_jpg.rf.0bdd3462bc75c281e36ef211b49d39bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-10_jpg.rf.869574f805778c8a78fe7eaccec9c447.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-126_jpg.rf.9d03e679bff130719d4ffb8c4951cce5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-20_jpg.rf.8c14cf69a6d8efc3bf356960723d8287.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-176_jpg.rf.a0492979b47dcd68852339b2180321f8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-94_jpg.rf.a326521d95f9355fbdcdc589b85c5734.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-35_jpg.rf.ad71d2b53026c941a84aa674a269e24e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-291_jpg.rf.3bcec6ec40a44aa19cfeb445198adeb8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-83_jpg.rf.708d1cb7b6dd0a70117edc98470d5afa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-62_jpg.rf.9553a0bf1bde61cb4e0174e877623157.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-116_jpg.rf.89959f1c15d205dee29614b6ab691486.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-56_jpg.rf.3c571ca1aaf37297045528f693c9c3af.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-46_jpg.rf.57a73567279a88e0c90277f5a36909ed.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-72_jpg.rf.fc69105815324da70f4d75d2af71ea2d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-230_jpg.rf.c540aa68e52fa9161f2fa07a2a35af05.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-72_jpg.rf.40f2cc2c46878fe7bc9ce62c4a184829.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-4_jpg.rf.fbfbdcb6bee4dae5df02234faafe8838.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-190_jpg.rf.b808e634a644213f5d2bab64e00d02b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-158_jpg.rf.bf7c686b6d6c184da07da59823a652b9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-11_jpg.rf.4d638266b3171ecd16ada933799e28eb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-12_jpg.rf.3b28c6960793906941f23fe498b0bef6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-94_jpg.rf.151920bcc41f884563fb279600bfffac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-232_jpg.rf.cd3dfe569f2ba74bd2342488026a1c76.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-59_jpg.rf.80615e4b303b3a2ff2b30cbdfe2e89a9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-77_jpg.rf.e61b08c3bf56b4178e395055830e3d52.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-119_jpg.rf.dd5d86d432475c11d6c360e4befbde96.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-139_jpg.rf.82b465e176df494a167abb21aac241b5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-67_jpg.rf.4800d089c6ffe3c44fe531f18c3d4d9c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-154_jpg.rf.022737b1f2ee5118f280310dc8922d1a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-107_jpg.rf.2dddfa45c025e1485c8865491dc043af.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-191_jpg.rf.b3bd5fbd3b80b2c2f32742c150979cdc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-222_jpg.rf.7c35d9db98601da46b855f9ede2e8322.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-47_jpg.rf.b692db4a7099293240e3ecfdd927a36d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-89_jpg.rf.8c38203733bb705e8212246011571b3d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-120_jpg.rf.3847b8d3b9423fd42340f645bf0d5465.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-56_jpg.rf.cc520858fbc82b737020dce837a9f31b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-70_jpg.rf.9688b8cea2e20fa6b545581148067b86.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-161_jpg.rf.ab19bf493ca5ffe94e79704c54280236.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-169_jpg.rf.9cf59d071e868220fd225b89bc64da03.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-7_jpg.rf.dc78e33ba89cbb4f9e68222516e3ff55.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-116_jpg.rf.78a6860c4c3794d5dd365c4b99a7cfa6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-149_jpg.rf.dc3f5d456a33c03c74308a168311257c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-51_jpg.rf.f4faf41081232ed7ff0edbfa440db113.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-123_jpg.rf.bfd09ee76d86fe6e84c0e3af02989110.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-31_jpg.rf.f6321772930c1a7ea61757e8fa476e17.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-202_jpg.rf.b32abc97f94bbb1e0e00161bc59e3213.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-138_jpg.rf.b53edc0286936e14b8d85c596b9ac1b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-90_jpg.rf.ff7d7af14fdcc4a44f32cf90c243ad70.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-173_jpg.rf.40f5b74c0c9d5e0fda7978ba9cd04961.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-145_jpg.rf.950c64f5e26846711e94606e7857269b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-235_jpg.rf.b8b8ea80f201223c481ebc5d70429f87.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-111_jpg.rf.9ad97279a508cc8f0a61cc4c466546d4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-164_jpg.rf.d922ca707e6c012ad3ae64bde17f95e9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-167_jpg.rf.767612090259bf7dc1f14883e24f6360.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-290_jpg.rf.8e31566d2eefdf4e592cbe71714a0b3e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-145_jpg.rf.ce4ea67cf8b55417b2e6336b9a7f9692.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-70_jpg.rf.46392c5e7435ffa97d5549d5b50cbdcf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-152_jpg.rf.1ea95785d2a89d76cfd98b60372c05ac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-92_jpg.rf.5b1dd00d4032c36818ef97ace5f60b4f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-197_jpg.rf.cce361f008ec38a2bfd8fd2853d4d882.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-73_jpg.rf.2b579a764da0aea8989efc896208eb31.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-132_jpg.rf.2182cc2deb8b958861c94f29fb42f431.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-151_jpg.rf.89dbc403cc7e49c02e1e10553afdcbca.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-108_jpg.rf.dd2efc746d9d3538abc9bce646baa04c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-156_jpg.rf.1d62f02c9e523886aca2840f729590d8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-11_jpg.rf.89a8800ffa0bf01fa62ff593513062ff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-24_jpg.rf.6f1e45a5b420d5fc2d20d6ab510b7a09.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-80_jpg.rf.a771d0d74a3ca516db1a79ccab9ba677.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-64_jpg.rf.bf51ab2ae8620c147dc5d13777c74b73.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-156_jpg.rf.4f51ef709b27b199c43080863668c14a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-47_jpg.rf.404178320b34a340781df4ef4744e574.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-37_jpg.rf.7b050fc1e660f0497162b829eb836796.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-76_jpg.rf.e42440b2e319ab3880d03f03a4a2c0c9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-39_jpg.rf.adffc739344dd7c80705f4f0308106a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-134_jpg.rf.9e1bd89782af8fe7a4af8a670de4d359.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-1_jpg.rf.118847619caf8a38f8d0de8de6ddc87b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-215_jpg.rf.a60414aad1579bb0c74c926c1be9c133.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-12_jpg.rf.f096ccc1ec55230334b817f5dcd70369.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-116_jpg.rf.c5eff64517742497a1dc0c8035f0a21c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-63_jpg.rf.a17d6995f7dfe4bc3bd8a311952b6517.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-139_jpg.rf.f695ae9ece29064571c49fe4bb2c2011.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-35_jpg.rf.1bba28c1442bdcc5b01ccbe67dfc6d53.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-91_jpg.rf.2fb997052254f6910566525d019d1315.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-5_jpg.rf.4d76e449fa8cbdac1b98c3c0dc8a3f5d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-77_jpg.rf.b47acd8d045d8ebf9b8627bfee3a3248.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-12_jpg.rf.ee9a9042a22b4d282ff9829776e1627b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-146_jpg.rf.d64fcb8809f4b577395b95a2d747c260.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-0_jpg.rf.c4da9bb3ab3873448f66fd0135b4f0df.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-20_jpg.rf.95424c9adc09469fcdacbbb7a428036f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-184_jpg.rf.ab9e38261ca160a392d9c6628bd394c4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-69_jpg.rf.10ed1e602052b1aa82067c96aec76b3f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-135_jpg.rf.34d6cbc8a6255cfd8123eafa268e0374.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-5_jpg.rf.038605b026a22e6adba92bfc95c2d75e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-66_jpg.rf.7b6dadb8d440f61c04749446081f1bc1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-120_jpg.rf.6d1c1bbc6873eed853a70f7dc456c7e2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-175_jpg.rf.1f806f3df14eb8f8656418ecef397c95.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-113_jpg.rf.f10f6bd9503261788005c48c6db8922c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-126_jpg.rf.177f621388ca459ca8d7f2e3c9824389.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-75_jpg.rf.6f134a07641f91db7ac37a7c50754ad0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-20_jpg.rf.d1015d4563d285c2d33d06bbab48165f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-123_jpg.rf.46b878b45e1570d8a04cebfd8c21bac4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-9_jpg.rf.efb86552e37952fa689025dc264222a3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-169_jpg.rf.dc8ad9f494ae3d8b70087843e1d1c168.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-96_jpg.rf.66d19b0ce45a599a9aac7c9bdc381539.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-202_jpg.rf.b99139479e4af9136d52cc9b42d59a66.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-92_jpg.rf.6f7df7cb00841a7501ec2050f2d879a0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-276_jpg.rf.5b9b7b3063a3bccf2e408ab2b4596233.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-187_jpg.rf.07d651c0525181109f066df18040d79f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-300_jpg.rf.fc721a4d20cf83d3969365dc607fa004.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-13_jpg.rf.e6642d2174b3cb7eb01ea7e6966b68d7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-84_jpg.rf.b7b1e19609d31440184f415b63297866.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-181_jpg.rf.1424a787a7552152d53222af3d47bd99.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-130_jpg.rf.df4904de7e7b2dc07af9298b3188fbb2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-109_jpg.rf.d5479974edd303ec8c9f4068d19e0bb9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-34_jpg.rf.d931da4dfd7c715047e1498591582c58.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-185_jpg.rf.b174d5087521498a204e317f36455fc8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-52_jpg.rf.42c759950e278ed6bdb618e8df7c7d3e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-301_jpg.rf.bbd5137d7032664a8b5b0f8afe6bfdc3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires2-0_jpg.rf.29eb84d489abe6ad8421eacb63f260fb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-1_jpg.rf.df1f2764ddef17a6992c8ea33d588b9c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-41_jpg.rf.e3a69c82be46b556fdb1d946d1cb8f00.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-162_jpg.rf.b6e84c3975880484833185cb79595a1b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-104_jpg.rf.f2b26f521a4f0d8dd0aec9b3c7f1027a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-2_jpg.rf.babcfb07b70cbae1a42a2b63d8ef8fac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-8_jpg.rf.be877aa05beded87aad8cbc33a42f2d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-192_jpg.rf.a0e610478abe943db3a1bc1577920386.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-99_jpg.rf.18cee5dec61c04dcba115975bb8f4e8c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-135_jpg.rf.dbe7a279d33d28243cd4a7b41518195d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-58_jpg.rf.dfd5916a681e2078bf864c715b6d1eac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-55_jpg.rf.f1749d87076e1b1bce8d52910e5bfdf9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-190_jpg.rf.bf05960c761a22f983f56d5cc5653ec4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-171_jpg.rf.f79ec5a3a7aafa04440b752993457413.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-91_jpg.rf.00a8919c381032cc30445b8b04ab21c8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-25_jpg.rf.0375ab58f2c91c6ccaba8f035f61ef15.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-15_jpg.rf.3a81d2841ee819bf7bcf6ec345b48492.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-124_jpg.rf.9d5adf3a37384b710ab10daf989ad106.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-25_jpg.rf.1afd5e301c079db9cc7b346b88845b74.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-141_jpg.rf.808a4ab103d8efb4c2a0d86c13ebeffa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-148_jpg.rf.096e55948843e4fded1561ae594ed75e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-110_jpg.rf.4bac420f6f300a6e99dd507166f2462b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-179_jpg.rf.4575cfb3ff839734d9693da42d8a8b1b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-136_jpg.rf.1c28ec71bbe9ebbbce45c1a8f666651c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-190_jpg.rf.1423c2877fc5eee6016b9bff9696d7e0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-188_jpg.rf.15ed4ef498851565daaee6cddb8f65a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-146_jpg.rf.ac7267e462924e50d324ebbe55deb0b1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-163_jpg.rf.ff8970b84582aedf24684bcf2ce89aac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-202_jpg.rf.ce4fd7c06cbabe877fccaee3805d354a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-121_jpg.rf.2cf2484bcd715d1eecae8c2baa16b83e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-134_jpg.rf.6fc2c19abd6faa758b89bf31c6b11031.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-206_jpg.rf.fe4c294c65006492a221770f3b521ba0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-72_jpg.rf.3fe3ef46dcc335289aa24a7c3b5aca6a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-6_jpg.rf.44b081dc73cb59366af14a8c24852853.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-139_jpg.rf.5f3444837ac28e43def9000ac197852f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-150_jpg.rf.c99b08eaa19c689e1291f1f4155994bd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-233_jpg.rf.2a4820dafe4303cc015a12014fb99ba9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-195_jpg.rf.17e8bd08f6bf146fc6254c99abdb0f4e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-87_jpg.rf.ab299e6fbf45c435955a2e8146ff949a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-176_jpg.rf.db77c3c9cb43c031e905d34674fcff55.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-194_jpg.rf.d5a97e7121d2b3c9ae9cb8390d5a6fe8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-133_jpg.rf.3468a6c0f62483618788bca1a091169f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-57_jpg.rf.6ffb578c80c1222726144c919bbb6bac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-22_jpg.rf.34fc43f18e0602ea2fe4aa0cd31af6b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-47_jpg.rf.7c34b12e2d0ab0b040fc5c0febfc6ba8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-178_jpg.rf.a9566db329e6990e98274c5b2da832a9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-6_jpg.rf.dd4fce1eb3102c8110ccd00f7140d891.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-77_jpg.rf.f498324c1de2823a7db834825e9be98d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-44_jpg.rf.9ee9c3746ebc63ab0b9753b9462c7f60.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-99_jpg.rf.60bd1a0487043e641369d10b751dc916.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-45_jpg.rf.e4a896dfdacf1a26b7aeba39696f752f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-80_jpg.rf.6ab689b862a52d754bb9d824c0cc1043.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-206_jpg.rf.af1081d6f4f8f1532139064e1ad08e91.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-80_jpg.rf.47d39cb09e170456f201b8278d20c41a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-46_jpg.rf.30e9932909e2040bed24c9965082b9ef.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-127_jpg.rf.80e38351f36c04781451e6705b74876b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-14_jpg.rf.7691c4d03fd954a645ef80c4aea17ff0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-99_jpg.rf.600841ccb4f05b0dcd75ceb99b7a20fd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-172_jpg.rf.57d8d38fdd8ff3f13e4d812bf8607a45.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-2_jpg.rf.d3faa3574f5a7bcde7675dd87c27dc7e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-143_jpg.rf.00dfab6f067ef969545546d6f4b9fa6d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-77_jpg.rf.d4e4dd2eb6b7921fb15e297fc4acf133.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-78_jpg.rf.6b7dae5fb01243d5d6f2e94149f101c3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-181_jpg.rf.f42a1118063f752829619dce2fe83573.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-78_jpg.rf.bd00cfaefd97245c35e5c9b63432351b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-115_jpg.rf.e5578b4e426bfe6bec7dc83bac76ad05.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-235_jpg.rf.22d2010a503219ecd57cc8b22d5089a8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-121_jpg.rf.1da03ec16f273d0c2135eb0c39eb6c67.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-79_jpg.rf.243fc67092b7b3525ba5697ee24994be.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-57_jpg.rf.1993c6a9f2926b19e5cea886bc7d58cf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-114_jpg.rf.6c7934dd08c958abb0772d18bcd50e95.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-120_jpg.rf.eea79202c4f04b74b70dc1ede99c53f4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-9_jpg.rf.d6b75fd481eb0d7da6e91570956b261d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-88_jpg.rf.e6fa2b5ae41c736117ed2c536f7baeaf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-142_jpg.rf.f42e6632bd0568dc12555b17205f523a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-71_jpg.rf.3fdab56016a5c5ce66bed749d2f2a5ad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-67_jpg.rf.4bf7c7713fc887b526b0bc26f861c306.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-203_jpg.rf.7006068b111c73d549851508976c0932.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-118_jpg.rf.b7c7a27c9e759e9087c51f6bd8f3e677.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-124_jpg.rf.91307dd5c21505d2bee3d3f6411d6c17.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-122_jpg.rf.352f34ab1c44ed40462105128b823e76.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-65_jpg.rf.8d2ebcdc40835ff559402e2f17f47e38.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-51_jpg.rf.f96e81049e72b45f1df6566771a9a94c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-17_jpg.rf.28ad451f0ebea7fdf156da5da210b846.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-109_jpg.rf.84f04d996a66b75781323ba40d49f137.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-92_jpg.rf.3e61539050786e91bd860f3fe24e1ac7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-28_jpg.rf.143e75f34df547750a40d8f84ef94e00.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-0_jpg.rf.bef59aefe8790d0bc4d0a0f487074a05.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-246_jpg.rf.f8aecfa7cac3e68c43782a302a16c345.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-93_jpg.rf.3c203d7ea31164dcb12f06417940de3b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-220_jpg.rf.b5afe3f1d0d3491f2c3a6edc3efcb0b8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-62_jpg.rf.727459b800f2e07c79dc67910ed21b3b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-120_jpg.rf.79a932f0bfa0ce0a3f12d29a07c1f3d6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-144_jpg.rf.99567a876c4bc6df2b86c21b00d16bb6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-26_jpg.rf.510bb14d56f9353bcc4af21fb79877a4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-12_jpg.rf.70c771258cb21aa8007c40181c9082de.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-182_jpg.rf.7afcf878a3a7a93b6a74bade9a3aa21b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-101_jpg.rf.ed913192ada9883e2d07cd26198120f2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-89_jpg.rf.512ba148f56b691a97cd300e128e67ea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-213_jpg.rf.fcea760d72881d5cac6a0b3b8c87b510.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-12_jpg.rf.8f4d029f14ae04c08aa984d9da29fc1c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-166_jpg.rf.9652473290cba210ad396c267f0d3e0b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-34_jpg.rf.e7b312d324efaaca439997dbaf55c9eb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-14_jpg.rf.447cf45b96c3ebff906290b6b8514ba3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-286_jpg.rf.280ee04534265fb2c70cf0f967ed41bf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-26_jpg.rf.2c044cc0a6e3af2188e47f7df5b7257b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-44_jpg.rf.098bb28b212857d821caa453485961ad.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-199_jpg.rf.e486ecc79ff3f968383a25655873e537.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-110_jpg.rf.8f7ade3a6e1b69a5a890a732e88544e6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-105_jpg.rf.c0198b0afbc898d929030daabf18a744.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/_annotations.coco.json\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-201_jpg.rf.9e605d43d22a39e7dd88286b73bf1d9e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-126_jpg.rf.95b068ec17b4611bd5fe8064cbaa7fbb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-104_jpg.rf.10152831a5e81af39a70664261b42086.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-147_jpg.rf.4cc2008d302b545cd24f038c15ccdd2e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-88_jpg.rf.f53474b9395c79059aff875847efeb28.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-27_jpg.rf.ec2fe1a2ebf668e5ab27a29a45c22561.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-117_jpg.rf.c14b6ae43ffb7d3750a17ca2b6ee46be.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-1_jpg.rf.a83e1dc3c6afa107a1ff6cd2c9d36ec7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-149_jpg.rf.f0f26e0f63f52ad493c3389aa5c90b63.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-180_jpg.rf.b126abc30d289453be663d3f45fb2f0c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-32_jpg.rf.aad997d9d98b91d23d04a26171e2c23c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-231_jpg.rf.84a34dd4a99e273c155ea281c62ba469.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-146_jpg.rf.a587543f6bf0fced339bdf08386f265a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-28_jpg.rf.a441c7d2d3c3c971eed6aeba573e26e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-58_jpg.rf.3c5b4a8313fbfa7c57d35d67b59f0eb7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-21_jpg.rf.2dd89a00da5dc5a58da18b4eca0ecfa5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-115_jpg.rf.495cd7cd078e1d4d7f52326caf80155b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-53_jpg.rf.544962f3c8d59ed637763cdc850a0f16.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-149_jpg.rf.4f364650fdb98fc85107732178167256.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-8_jpg.rf.f9972b463fd67d95af6015fdc03e0dce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-125_jpg.rf.1fb36c426b10f8dcd8d12a651843e5a5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-78_jpg.rf.a01ca7d56b7831777334e10dfc08b48d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-168_jpg.rf.f631fb530d6a7921185ef0bccd078e6b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-28_jpg.rf.e40fb0b1cfe61eed4af2554283312c11.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-19_jpg.rf.efba47928adeb6aa6534480866ced22a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-140_jpg.rf.6a220f38f02bec13eb39cba6fe1ae45e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-114_jpg.rf.168a794ade2e92ebee2a351ddc09b0ce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-24_jpg.rf.c6a7338b1b5f9acc0b012ed6e79c9fd5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-95_jpg.rf.10ef3f07943e8c1d4226d68f9f502b1c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-117_jpg.rf.741a58ca6883155ffb8e73746ff97e31.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-184_jpg.rf.1f84b522ae3b47e069c116b104e43c71.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-43_jpg.rf.3aebbbf388f4950a4a605d2ef89611d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-52_jpg.rf.7588b20231ba00840470c93a9388ad79.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-174_jpg.rf.650faec97bd7be0cbca25f75b523056f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-21_jpg.rf.a79444696880218f67f0883c4184169a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-78_jpg.rf.9cb7baab1560e7fcbc071e7c9bed4185.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-117_jpg.rf.4b064cd8c0ed565d036e0b6cf4b467d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-85_jpg.rf.cba2f2bafa2a7c62257dcac17fcee89e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-129_jpg.rf.5cd1cd74679a3634fa58247bc4bb0bf8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-168_jpg.rf.4c9cad26d6a47ce7d77155509791b1aa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-18_jpg.rf.03049534278cdbf5f470d6115b87f222.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-51_jpg.rf.fe787eec03225c2df78b03d355e7a999.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-105_jpg.rf.8984022cc45a971389104056d7ed88cf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-105_jpg.rf.4d76bb8fd5725381cd38659d7839cd38.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-204_jpg.rf.9cbf4122eb3826166935cbad949fc0f5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-194_jpg.rf.7da4746a7a55382224aa6978c9cd2578.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-87_jpg.rf.49b243fa2195849306b21c83946c92cd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-29_jpg.rf.5ccb5e685340ab0c1f6d85aaf2c9418f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-200_jpg.rf.060bab32764482dafc75b48db8176010.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-72_jpg.rf.2df227d8058cac72a9aa38a74a896c3f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-147_jpg.rf.f4de20c3abe10850aa9d0ade139026b1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-183_jpg.rf.48b5231b6b0c6358dd79defb8c7e6f78.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-232_jpg.rf.65271306d83d9038c0a81910f4ef2881.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-160_jpg.rf.58facffd344a32110fb7b103a07bc4db.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-130_jpg.rf.238ffeb7e9eb06b2ef192431072267e7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-126_jpg.rf.295498776a1b5d7184885731f8a0b69f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-26_jpg.rf.ae390542a91a85e5d1ad02d9745aced3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-130_jpg.rf.ce128074690e5c06289bf9f5c9c422e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-151_jpg.rf.a5f4992df46793d57671f9f3ec2a4737.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-111_jpg.rf.98586f972d89606486103bdd4725ce66.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-18_jpg.rf.a1e3f5373b611bc2035df1edc1e7a193.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-7_jpg.rf.da71cb842e3bc94d2b4576a8141029bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-186_jpg.rf.98c0c0bfba925772a0c0ec67a787f6ca.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-43_jpg.rf.43b9fed5742315a0788778d7dcdb4d0c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-3_jpg.rf.181722b07f6803531721b9659d5a7148.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-114_jpg.rf.9166e3e274719745ba00d2c3dfc95755.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-224_jpg.rf.d6322880538632d93a201c2b4c425b63.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-18_jpg.rf.48bd2b41b05422fa2424278a9d0bc925.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-39_jpg.rf.bc97acbade1976178f836c70aad494b1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-5_jpg.rf.3983bc56738d160127e5ba4fc94e4e99.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-53_jpg.rf.972e47cdee425eb42e697cdb301af835.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-87_jpg.rf.4857f20db0b418bea42815a1e403e672.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-298_jpg.rf.82269590ae51c9bfd2eb5187e4e261a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-29_jpg.rf.7d2f7972f5149fd1920ba330de3e87f8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-66_jpg.rf.c5fd8f7d13fc9289eb6cc62ab2055ba4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-14_jpg.rf.25219cd2e48fdce0a2d852250b73c3c9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-7_jpg.rf.fb981a9f0ea109b9c9147868fa6ba522.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-149_jpg.rf.0ebe035fc74b4bd3b2e056deee086f4e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-182_jpg.rf.c5b040405979ff1497ed83b0eded21e7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-10_jpg.rf.57d1d3a7c1f12a19e3b89082679e4e7e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-15_jpg.rf.3f5a93ee3152e5fbfbc4352ed7a09b7e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-162_jpg.rf.6ac2353a2c5f2081574adca74c2794ff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-28_jpg.rf.f9f8a433a98f5a547d3351cd75c5fd37.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-188_jpg.rf.b3811774c4c4125974af26dfef37c3cd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-2_jpg.rf.d9999fd368c18f2144d1b0e41fe0a590.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-132_jpg.rf.27dd050ec548cb24a0be53efae959e37.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-76_jpg.rf.c47337d156886191494c943807de7211.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-67_jpg.rf.72544ba3dfc98671bf1ff5aba15f528d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-131_jpg.rf.8b7927ce22ed75c810cd2d3f845bcb4b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-185_jpg.rf.e27369eaaa349bf07d2995e59f7ea8ea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-124_jpg.rf.a7b2f831371365992c9dc50c1aa7c14c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-93_jpg.rf.bffca916cb62722e4432b5e1581856ce.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-148_jpg.rf.9c6fa894bac4d20ad3d48abf98bccf46.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-157_jpg.rf.450db00f0aba1572816383c330ab26bc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-85_jpg.rf.819212a221dad32ad5d62a39be614fb6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-2_jpg.rf.edff653286d3941263e6b4dfa08ad493.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-98_jpg.rf.fc63c8ae024eadb1c29ea38fe572b889.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-80_jpg.rf.fdae391e776119c76d70146b632b6c49.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-40_jpg.rf.dc7e204269525f86ed3f377a0b66c2a5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-135_jpg.rf.8cbe805edec440e478a544e3a6c0560f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-67_jpg.rf.8905c655c394c1f515c40293c6f0ec86.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-30_jpg.rf.58c8d8d87662961de2449ee10678d3b9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-49_jpg.rf.7c045d78b485dfe7661797898a05bb92.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-132_jpg.rf.c0cdbff936ba9dcb2454316a28b767b8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-158_jpg.rf.92756496eb3c54cf8b382cdb6f5beaf9.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-85_jpg.rf.b556f7384b1c88758b705913fff8698e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-186_jpg.rf.0182821041465dcb73ef22003a2318f8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-166_jpg.rf.1d60f6f945d9faec61b8ac914c7d58c8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-105_jpg.rf.561a9c41b5853e72626ebc8d8c616c4b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-194_jpg.rf.1db8db5b4d0886e60272fc4b7322f0b4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-33_jpg.rf.bca50b19e0ec8eb68cafbcf0338e7387.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-219_jpg.rf.d89a1454848dd1a71c3a0ef47ec77f8c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-137_jpg.rf.b4ca42c8abee1fbd0a1aaa3c55397283.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-25_jpg.rf.bbe88d9882c5870c88498d8524315e4a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-155_jpg.rf.4391dd0fdbb77b1c233c1bde410df8a1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires2-77_jpg.rf.5ffd13d5881609dc04a13e193176a087.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-1_jpg.rf.e7d39e0c4a6737731e305575a95e08bd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-91_jpg.rf.af3811b2bfa9de7a367f748d33f9df39.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-167_jpg.rf.fca0c4a5c1cd8b5d9afd12b720c7c4d5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-34_jpg.rf.00917fb824d2c19599a4ab6dea0430ba.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-61_jpg.rf.5790edb21a54fe0d6f8695a3dc7dae7c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-123_jpg.rf.8b09b90b6a42c013dd286b4a86db779b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-108_jpg.rf.17489846d25018c8d92b493db92673be.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-30_jpg.rf.7031d9d819b9e7e8f292a17fa4d85015.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-66_jpg.rf.44f6e5b1af9e2a061452bd91b90acbcf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-191_jpg.rf.42ec0c0582903ae96f2d9c6dce36c549.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-128_jpg.rf.4f5d16c5cf67a259ede9bde8b52f33b0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-83_jpg.rf.2015740b19698f85606fff66082a6eb8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-100_jpg.rf.f9709b35b3868f2e31730aa35200816d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-73_jpg.rf.6664806802dffca0fdbcefa540098197.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-237_jpg.rf.63aa2df7082065e5d18fd76d7a88e963.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-74_jpg.rf.b359e3099009ef937b97f34cf10b59c8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-89_jpg.rf.c65d63a8791dcc6424ffbeb732d5b624.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-29_jpg.rf.16959d6a058ca69af7b3b9d22cc6c9df.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-82_jpg.rf.7affc3eb54dcb68657cf49a0419e324c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-174_jpg.rf.99f649bc981ce94a16b5a19c8a5d1ad3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-8_jpg.rf.e0e7a40424e1523120f7642d241aaa0f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-16_jpg.rf.23103a2e022dea69b3b243a738fda399.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-149_jpg.rf.8bec3df10039814d871f1d70f7057414.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-5_jpg.rf.5df11913cb7f86b6b991b6c59ea832b8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-129_jpg.rf.c8e2476186a7804bc3575e4fde2c28d2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-32_jpg.rf.827af337fe06d5ad738c5d05882b7c85.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-169_jpg.rf.8a242da229fdc770b2458821c0773d08.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-172_jpg.rf.3fdcf115af256f5fd84271d09d235a0d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-21_jpg.rf.e711c7c89cef69bb098b084a04d4dfbe.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-10_jpg.rf.6a5502928eb083f58a535c3a7610b06a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-135_jpg.rf.b97be165ce81d4bacfef1737aaf08ad2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-40_jpg.rf.6aa82a96c0621ea4e1a004f976654d80.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-299_jpg.rf.a3d5848ae13fc35e09fc81bc5867c0a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-165_jpg.rf.6565c9338a0d2fcaf9ded622d19ab501.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-271_jpg.rf.45d6fe6c2ba8b443c7f2efe1466c3dc6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-188_jpg.rf.8003f8d2f83ac3fcea268264d5c7b719.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-173_jpg.rf.94092e54a0c22d29f52570a86eae5cf2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-297_jpg.rf.da9c897709a55617dc35128dbf8cdfd8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-0_jpg.rf.c223dfb01b95a4758a0b80cf8f767276.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-226_jpg.rf.60840b0af42f79dbf24ceb90e3ee375d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-23_jpg.rf.24f47616bdb434b9650cec9868a280ee.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-149_jpg.rf.03a5f7efab2d1af30a4c967c6b7fac6b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-244_jpg.rf.f82c184e2234589955beed6a884bc63c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-155_jpg.rf.48fe45472d6362d2b412c808b5a25512.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-118_jpg.rf.440d9c8fa215f9cd7ae3e028c055dace.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-220_jpg.rf.e25699b8a1843c3353ea821180902a0e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-71_jpg.rf.f5a2a59f878a4efe85e93cb9f5c84021.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-196_jpg.rf.08ce9e1d8fe27e7f775a0ef4f7b53c49.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-199_jpg.rf.09792442cb7bacd641b3987841ccd75a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-42_jpg.rf.4667572c3af5ed489d2665f4bf367236.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-56_jpg.rf.b51a8085910a7db791fabe03d9797510.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-135_jpg.rf.07fc63c780cd0789b4406d9c2206e8d2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-75_jpg.rf.11620910dc741dd28d863797c7b8a36a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-153_jpg.rf.ba530bf227132051936e142c436cca19.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-38_jpg.rf.4557e393dec2586182a59e2a2b3e2e71.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-98_jpg.rf.1455ac435e75abcc62e32bac84ea9412.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-156_jpg.rf.fcb1f5ff37033787081984b3e8577c89.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-225_jpg.rf.926e773ab26199fe5016004347ed2f75.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-131_jpg.rf.0393da02c9bea62a253124f80fd67cd8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-158_jpg.rf.36caf358045b5622645e4227ddea8749.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-79_jpg.rf.f4706c8984a764838c6985b3bf1c6613.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-141_jpg.rf.27ce7fd0614a8eb17426ab5716019b3c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-4_jpg.rf.a1b2b656fc94b3a55a4688e483c5bfeb.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-120_jpg.rf.84ed7542ebbdae0dff322e60f3905d71.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-131_jpg.rf.b9e13052b44ab106e4c4b55dcb7411b2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-23_jpg.rf.583032b6fa5e68c13d7526fce2028c2b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-9_jpg.rf.65f6741ebb2fb4f2fa904536d563b0e1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-60_jpg.rf.65e54077f8127ee80f0fe4448bde1650.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-119_jpg.rf.13e92d6fb014db6a2988c1c02ee8a8a2.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-8_jpg.rf.bc0b78fdc43cd1ef1b3d51ca397982ff.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-129_jpg.rf.ec89eb6356dd7a1a3b4384152ed18b6d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-6_jpg.rf.47d29bebdfe0d235f1d5ea5d8e3b336b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-9_jpg.rf.a3b30d24cd0492f6a441a30de752930e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-113_jpg.rf.8c200ef4a201c40fb8b750085ccab868.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-77_jpg.rf.cbbd141cf9f28b0b92e859c08ddd0599.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-87_jpg.rf.c157fedada03f3fa42093b470a30a05d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-142_jpg.rf.a4da7ee0173f98bbadce92136743ab66.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-139_jpg.rf.bed23ad55574286c6293dd2fb8ff047a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-205_jpg.rf.f73945057affcf3dfef9c19eaec0056f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-128_jpg.rf.ff5e75701ef02291a350923ce3671bc0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-100_jpg.rf.375eabbfa529d21eb42e090fbe9b9040.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-68_jpg.rf.6c811cae2b69a1ecd5788a45989ffdef.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-13_jpg.rf.1e728a68df5196d015cc1b3705cb6cfd.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-72_jpg.rf.4dfdf6fd4e5e9509713159c087d98944.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-86_jpg.rf.435ae5fd465e02d818cfe09f0aa671c1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-164_jpg.rf.88f11bf3291c49bd39c495f5574d1daa.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-146_jpg.rf.a1ace85a2a75fbdfd2f09e3bb25f823e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-100_jpg.rf.f08ced8e211e3b04c9013d1245664f81.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-98_jpg.rf.1a2985b27e766fb9165eeb4f9ebd7047.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-13_jpg.rf.af571b8f3ef3be311cda14496950e76d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-71_jpg.rf.1ab7eee13c0fd1c95af1cb18ec219b52.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-141_jpg.rf.c79663308adc0c6490173b9441bc5bed.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-155_jpg.rf.508bc22169512aeed80ddec4df8286f8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-24_jpg.rf.6f6f3434861cdff299beb806d0fe4710.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-170_jpg.rf.d843fbc961df223fbd0dea8ab7febecf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-84_jpg.rf.929a3bebf2a926c5f64f8aab0e827f31.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-60_jpg.rf.7c176f9f925e6e74b677db757ca26b9a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-1_jpg.rf.1c52f9aebd402732c3e5a3ad0aac43cf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-15_jpg.rf.8bce7ca4f5ff53dca6131bb589565c74.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-62_jpg.rf.6bc0fcb71e394f0f664c1eeac1717de3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-14_jpg.rf.eb39f3b001fcaa7de331e8206a927927.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-40_jpg.rf.89227c727debfa0f3542946b88b5910f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-136_jpg.rf.213acdda43c0037f99d78d795ed895ed.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-38_jpg.rf.197cbf3d6f808a0b608d1364eba4274a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-50_jpg.rf.ea4e66ac19c0dd3fefd66862eec7e852.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-45_jpg.rf.c6fbc03d15d23e89ae9f0763c15fffa4.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-157_jpg.rf.386c2b33ffbaa2d4204b6788fa4990b3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-82_jpg.rf.eb1af995d0b16eb6db9fe7aebde18e75.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-81_jpg.rf.39c619cbeb121661b8d2dc7a10c31a1a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-145_jpg.rf.a5099d587b38e89f9b2e6084de6b1119.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-184_jpg.rf.37f49562223f61aca107de707acb95d6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-2_jpg.rf.ebd8be3ff2949718b1cc444f4b77d648.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-79_jpg.rf.bb3c1a4b78b466042eb7d20dd6bc29c0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-87_jpg.rf.5e562026477982dd4681e0b1bd932916.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-41_jpg.rf.14cf10aca8caa7ba705edad519c0d63e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-14_jpg.rf.3dc426249cf5deec3adb59635f6e7534.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-119_jpg.rf.4e98dc6440297beb960a7a8cd75a409e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-152_jpg.rf.385c88401a2aa37397f6ae27c6b0357b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-280_jpg.rf.be583afce1c224261ba545c8b39eec91.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-25_jpg.rf.9665558117d81227a9dcd770e1355aa1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-24_jpg.rf.b9c67914ceb077e522e8cc7bd0b960d7.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-49_jpg.rf.cc2427b7bab05a640b066c1059c7746c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-21_jpg.rf.723911bc9d382ca56678d3f66935033d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-69_jpg.rf.71e16f05dfbd1418ab820bf6168b9b7d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-5_jpg.rf.22a3efb34372f44c2232a164e66095e5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-7_jpg.rf.bbcc70cbd25b22d5d6d8f75f7c3a1092.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-155_jpg.rf.cc960db17a792a29a07306f32a129ad8.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-109_jpg.rf.aaf5ddb87d12e3cbb09ab27545c8a94a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-125_jpg.rf.b5852dcf95534c9083c38b8ea3206b18.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-304_jpg.rf.12015aa8bb7d6db7c78e36042e5c5275.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-114_jpg.rf.9dc42e62e2396c1edad70ed038fa631c.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-207_jpg.rf.e1fe873b2ba415ae1c7f97766e4304b3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-77_jpg.rf.1518871fbb8fbc149f436e2b4c7d887a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-44_jpg.rf.d86689cb649ea4f14fcf5b5619c357ec.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-33_jpg.rf.dd81db1400a0ab9f4bcfb073c995bfac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-8_jpg.rf.f5288a3fa412c34d79274e74301aa8de.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-22_jpg.rf.cfd42059d4c5fed5f7bfd108b8d993f5.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-212_jpg.rf.f48c103689a6193d69dc3289a0ec41ec.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-70_jpg.rf.bfe0d859d2f2dfa5ec98c8b0be22da8f.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-189_jpg.rf.999da1a4b8de17e985da48b3c309670a.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-52_jpg.rf.ba531b4c18fa5153e5d2b51fd470f222.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-100_jpg.rf.9ee35c70e9d389ee0ca095a631b619ac.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-194_jpg.rf.5deaa291ea3cc3c1ebc299b51f056396.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-49_jpg.rf.fc86b4135a66c118cfdbdcb3e8b05a6e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-198_jpg.rf.2a33479eb672c5f9dbab70b95ea7ef68.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-76_jpg.rf.86d164648b8597d72cd487445ad67da6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-97_jpg.rf.37ed79d58ef6acb730fd1f20663d9c44.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-161_jpg.rf.85df123b7cd2b38b12fd8e1dbe84e8a6.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-191_jpg.rf.3609ee85796811ec124de67b92884aa3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-48_jpg.rf.1d8f951a2c81905c11c14872b4c71076.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-160_jpg.rf.a453bd3d9fef7bc14697e896705b2746.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires2-103_jpg.rf.c969d34a87101b3ed4dd51254b3e9f1e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-196_jpg.rf.0f961913e09407b73d1ed40242e2c4bf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-169_jpg.rf.9e10c90a9c06e8824f77bd4ec75cca23.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-105_jpg.rf.ee44e3509bafc0bb5d63f663dee76412.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-0_jpg.rf.ca9d2e76abe6edaee48a2a73e08b0595.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-103_jpg.rf.278c300a6779ef3cf920c9f2c919e0ea.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-71_jpg.rf.f8cd35d2b58a1e864c5d7b72e02f5d12.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-71_jpg.rf.253240ae39ffb6492d144c8aba629bc1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-128_jpg.rf.288b2b49709d8569a2c2078e83cdd51b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-16_jpg.rf.049c4665b177b7928b1c4fc681b48e12.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-48_jpg.rf.2a7132b2366342ffd3c92b1b7320503b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/towers-57_jpg.rf.bec92c37999d63ed1dbcf13e3c9633b3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/billboard-81_jpg.rf.e227f2e9272db463518bd8c210f6dd50.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-267_jpg.rf.7ffe68c9fd765aa2beca48e45667dd4e.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-137_jpg.rf.c7f8c749ea3bff1e84bffff85198e24b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-143_jpg.rf.46a208faff2dd40b929502b0e04574fc.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-21_jpg.rf.6ab11c812674467e8094652b1c7172cf.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-150_jpg.rf.1fcd7dcbf198785a6daa42511edf5af0.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-39_jpg.rf.d59732f3c468be9c389a4ca20e9ce404.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-239_jpg.rf.7a46729dba410797d17e578df8fcd707.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-121_jpg.rf.a947eb6c58067345b6ef3f525722d749.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-109_jpg.rf.8e9c5fe44959db7157534e6ebb24c92b.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-177_jpg.rf.704e2b06ed6f4934db08aaec8374e34d.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/bricks-0_jpg.rf.bd9846ddf7410d23d1e719b345fdaad3.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/wires-123_jpg.rf.4632e3a1b20e32dec06fadf67fab4832.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-122_jpg.rf.5c50c4534f1bbe285c5c1a16ffba4fc1.jpg\n/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-138_jpg.rf.0ee7da77b1adc9ffa0dc7bbca67316b1.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m pip install pyyaml==5.1\nimport sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nsys.path.insert(0, os.path.abspath('./detectron2'))\n\n# Properly install detectron2. (Please do not install twice in both ways)\n# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:50:47.125609Z","iopub.execute_input":"2022-12-06T14:50:47.126171Z","iopub.status.idle":"2022-12-06T14:51:46.335145Z","shell.execute_reply.started":"2022-12-06T14:50:47.126135Z","shell.execute_reply":"2022-12-06T14:51:46.333850Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pyyaml==5.1\n  Downloading PyYAML-5.1.tar.gz (274 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pyyaml\n  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=2dd7f2c82573dc0029f0b7a45a50089aa28e823cd76812ec1004853eae4c4a19\n  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\nSuccessfully built pyyaml\nInstalling collected packages: pyyaml\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0\n    Uninstalling PyYAML-6.0:\n      Successfully uninstalled PyYAML-6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\npytorch-lightning 1.7.7 requires PyYAML>=5.4, but you have pyyaml 5.1 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nkubernetes 24.2.0 requires pyyaml>=5.4.1, but you have pyyaml 5.1 which is incompatible.\nflax 0.6.1 requires PyYAML>=5.4.1, but you have pyyaml 5.1 which is incompatible.\ndask 2022.2.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\ndask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\ndask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\ncookiecutter 2.1.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyyaml-5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCloning into 'detectron2'...\nremote: Enumerating objects: 14634, done.\u001b[K\nremote: Counting objects: 100% (50/50), done.\u001b[K\nremote: Compressing objects: 100% (42/42), done.\u001b[K\nremote: Total 14634 (delta 16), reused 34 (delta 8), pack-reused 14584\u001b[K\nReceiving objects: 100% (14634/14634), 5.99 MiB | 14.13 MiB/s, done.\nResolving deltas: 100% (10572/10572), done.\nRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (9.1.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.5.3)\nCollecting pycocotools>=2.0.2\n  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (1.1.0)\nRequirement already satisfied: yacs>=0.1.8 in /opt/conda/lib/python3.7/site-packages (0.1.8)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (0.9.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (4.64.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (2.10.1)\nCollecting fvcore<0.1.6,>=0.1.5\n  Downloading fvcore-0.1.5.post20221122.tar.gz (50 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\nCollecting omegaconf>=2.1\n  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting hydra-core>=1.1\n  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m151.1/151.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: black in /opt/conda/lib/python3.7/site-packages (22.6.0)\nCollecting timm\n  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (21.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.21.6)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (4.33.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.4.3)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs>=0.1.8) (5.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.8.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (59.8.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.15.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.37.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.4.6)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.19.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.3.7)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.2.2)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.43.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.35.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.28.1)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath<0.1.10,>=0.1.7) (2.6.0)\nCollecting antlr4-python3-runtime==4.9.*\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.1) (5.8.0)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from black) (8.0.4)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.7/site-packages (from black) (2.5.1)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from black) (2.0.1)\nRequirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black) (1.5.4)\nRequirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from black) (0.9.0)\nRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from black) (4.1.1)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black) (0.4.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard) (1.15.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=8.0.0->black) (4.13.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\nRequirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core>=1.1) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\nBuilding wheels for collected packages: pycocotools, fvcore, antlr4-python3-runtime\n  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp37-cp37m-linux_x86_64.whl size=373774 sha256=86bc946e5eaef3bc61c0ec482357e822f6d79fd7e36e1849bc98d7876cec823d\n  Stored in directory: /root/.cache/pip/wheels/06/f6/f9/9cc49c6de8e3cf27dfddd91bf46595a057141d4583a2adaf03\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221122-py3-none-any.whl size=61483 sha256=8cd202b4f061af8c2b57a6da783df2a08fb87c14fca6ecc1cf280468c6628346\n  Stored in directory: /root/.cache/pip/wheels/2d/e4/d7/be0b4010933f5fffea6385e9b319eac9d6e56c82ee4a0164e5\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=b5992fe98d0a2c4727c6074141a9a8966a8e7eb60cc10b93fd112481a22906ed\n  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\nSuccessfully built pycocotools fvcore antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, omegaconf, iopath, hydra-core, fvcore, timm, pycocotools\nSuccessfully installed antlr4-python3-runtime-4.9.3 fvcore-0.1.5.post20221122 hydra-core-1.2.0 iopath-0.1.9 omegaconf-2.2.3 pycocotools-2.0.6 timm-0.6.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch, detectron2\n!nvcc --version\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\nprint(\"detectron2:\", detectron2.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:46.337161Z","iopub.execute_input":"2022-12-06T14:51:46.339483Z","iopub.status.idle":"2022-12-06T14:51:48.162984Z","shell.execute_reply.started":"2022-12-06T14:51:46.339432Z","shell.execute_reply":"2022-12-06T14:51:48.161611Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2020 NVIDIA Corporation\nBuilt on Wed_Jul_22_19:09:09_PDT_2020\nCuda compilation tools, release 11.0, V11.0.221\nBuild cuda_11.0_bu.TC445_37.28845127_0\ntorch:  1.11 ; cuda:  1.11.0\ndetectron2: 0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\n\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:48.165997Z","iopub.execute_input":"2022-12-06T14:51:48.166767Z","iopub.status.idle":"2022-12-06T14:51:49.637763Z","shell.execute_reply.started":"2022-12-06T14:51:48.166721Z","shell.execute_reply":"2022-12-06T14:51:49.636613Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from detectron2.data.datasets import register_coco_instances\n\nregister_coco_instances(\"my_dataset_train\", {}, \"/kaggle/input/vispol/dhaka-streets-coco/train/_annotations.coco.json\", \"/kaggle/input/vispol/dhaka-streets-coco/train\")\nregister_coco_instances(\"my_dataset_val\", {}, \"/kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\", \"/kaggle/input/vispol/dhaka-streets-coco/valid\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:49.639296Z","iopub.execute_input":"2022-12-06T14:51:49.640121Z","iopub.status.idle":"2022-12-06T14:51:49.645649Z","shell.execute_reply.started":"2022-12-06T14:51:49.640068Z","shell.execute_reply":"2022-12-06T14:51:49.644641Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#visualize training data\nmy_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\ndataset_dicts = DatasetCatalog.get(\"my_dataset_train\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:49.647238Z","iopub.execute_input":"2022-12-06T14:51:49.647835Z","iopub.status.idle":"2022-12-06T14:51:49.692709Z","shell.execute_reply.started":"2022-12-06T14:51:49.647799Z","shell.execute_reply":"2022-12-06T14:51:49.691697Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 14:51:49 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 14:51:49 d2.data.datasets.coco]: \u001b[0mLoaded 1117 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/train/_annotations.coco.json\n","output_type":"stream"}]},{"cell_type":"code","source":"my_dataset_train_metadata","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:49.694701Z","iopub.execute_input":"2022-12-06T14:51:49.695444Z","iopub.status.idle":"2022-12-06T14:51:49.709303Z","shell.execute_reply.started":"2022-12-06T14:51:49.695397Z","shell.execute_reply":"2022-12-06T14:51:49.708232Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"namespace(name='my_dataset_train',\n          json_file='/kaggle/input/vispol/dhaka-streets-coco/train/_annotations.coco.json',\n          image_root='/kaggle/input/vispol/dhaka-streets-coco/train',\n          evaluator_type='coco',\n          thing_classes=['pollutants', '0', '1', '2', '3', '4', '5'],\n          thing_dataset_id_to_contiguous_id={0: 0,\n                                             1: 1,\n                                             2: 2,\n                                             3: 3,\n                                             4: 4,\n                                             5: 5,\n                                             6: 6})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_dicts","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:49.711298Z","iopub.execute_input":"2022-12-06T14:51:49.712266Z","iopub.status.idle":"2022-12-06T14:51:50.165415Z","shell.execute_reply.started":"2022-12-06T14:51:49.712229Z","shell.execute_reply":"2022-12-06T14:51:50.164603Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[{'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-200_jpg.rf.0091f429b7e095410054c79a32f2519e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 0,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [44, 149, 153, 305],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-47_jpg.rf.02808f4344303abbb8a0ec8a21c7871f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 1,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [86, 147, 71, 211],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [253, 161, 39, 161],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-143_jpg.rf.00dfab6f067ef969545546d6f4b9fa6d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 2,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [87, 100, 161, 151],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-37_jpg.rf.00d69cb4c66113ddf968f68e2ef65531.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 3,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [362, 265, 66, 58],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-49_jpg.rf.018a4e5304b2ad2c1a2b0e24b37b151b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 4,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [370, 14, 54, 100],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [16, 83, 258, 247],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-92_jpg.rf.019206f547fed68a8a1705d71cd34d36.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 5,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [382, 337, 71, 35],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [167, 380, 155, 49],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-154_jpg.rf.022737b1f2ee5118f280310dc8922d1a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 6,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [253, 169, 80, 251],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [169, 280, 48, 140],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [116, 215, 48, 190],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-60_jpg.rf.00e27b3abede3f089c02fb328900d3db.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 7,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [193, 158, 70, 327],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-13_jpg.rf.00cafd00a8aec93d219af5a036709ab5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 8,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [244, 142, 92, 95],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-156_jpg.rf.01f116c28eec9ac7b0f8af65a85a5271.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 9,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [364, 282, 65, 47],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [122, 291, 270, 161],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [410, 254, 33, 62],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-34_jpg.rf.00917fb824d2c19599a4ab6dea0430ba.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 10,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [152, 174, 130, 84],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [380, 125, 119, 80],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-29_jpg.rf.0387615daffbc69cc5109ce4bd9db1db.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 11,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [171, 177, 225, 154],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [189, 209, 311, 291],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-128_jpg.rf.00030c5fa564bad009ea2a13b3401c16.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 12,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [51, 78, 151, 260],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-138_jpg.rf.035d07cfc961b9ffb38e28ccd2bec599.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 13,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [274, 227, 166, 98],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-131_jpg.rf.0393da02c9bea62a253124f80fd67cd8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 14,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [15, 44, 389, 217],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-91_jpg.rf.00a8919c381032cc30445b8b04ab21c8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 15,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [309, 309, 173, 143],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-186_jpg.rf.0182821041465dcb73ef22003a2318f8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 16,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [254, 318, 174, 154],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-149_jpg.rf.03a5f7efab2d1af30a4c967c6b7fac6b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 17,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [180, 84, 94, 44],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-18_jpg.rf.03049534278cdbf5f470d6115b87f222.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 18,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [147, 163, 189, 119],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [50, 194, 253, 143],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-162_jpg.rf.0358ff930fb09c451baa17ad2329f092.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 19,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 8, 233, 193],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-160_jpg.rf.042182e73433b6da291bd51fac2c1d36.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 20,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 202, 296, 296],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [298, 430, 167, 70],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-63_jpg.rf.04194b34c1db6627c85c97838e00fc42.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 21,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [303, 288, 182, 109],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-25_jpg.rf.0375ab58f2c91c6ccaba8f035f61ef15.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 22,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [49, 125, 92, 164],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-5_jpg.rf.038605b026a22e6adba92bfc95c2d75e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 23,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [92, 72, 97, 373],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-64_jpg.rf.00308467d5f60bad42959786e9c42c47.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 24,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 238, 263, 196],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-101_jpg.rf.0499220d1435e3cc27964cd7aba198d6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 25,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 94, 38, 28],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [268, 130, 225, 286],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-15_jpg.rf.05b78a2ade570714d6cacd06a178965a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 26,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [175, 249, 325, 221],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [179, 205, 125, 155],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-114_jpg.rf.05cd120a8046ba0de18d3fcba0eaafe2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 27,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [231, 139, 81, 265],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [142, 313, 47, 136],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-152_jpg.rf.05d647feb20c2eb8f0dd34a9d0f9f9eb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 28,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [15, 277, 346, 212],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-187_jpg.rf.07d651c0525181109f066df18040d79f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 29,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 315, 206, 138],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [97, 227, 93, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-135_jpg.rf.07fc63c780cd0789b4406d9c2206e8d2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 30,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 263, 300, 237],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-200_jpg.rf.060bab32764482dafc75b48db8176010.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 31,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [272, 266, 102, 81],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-0_jpg.rf.043ef88d61debce067569c63ac282916.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 32,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [91, 236, 176, 184],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-16_jpg.rf.049c4665b177b7928b1c4fc681b48e12.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 33,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [359, 189, 95, 49],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-67_jpg.rf.062ab00034f38c6cfde84a2b17bfc5ac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 34,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [299, 223, 107, 53],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [213, 224, 88, 70],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-196_jpg.rf.08ce9e1d8fe27e7f775a0ef4f7b53c49.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 35,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [168, 261, 244, 138],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-55_jpg.rf.0819a79e1db98494ed2061ec7283f63f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 36,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [272, 290, 193, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-195_jpg.rf.092acee891a7e0c3ce2cc7d724762b5d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 37,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [13, 337, 134, 67],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [108, 292, 153, 80],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [259, 152, 32, 35],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-32_jpg.rf.09115e0bbe38f608e8677b1073918df3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 38,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [53, 303, 126, 98],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-199_jpg.rf.09792442cb7bacd641b3987841ccd75a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 39,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [119, 214, 275, 91],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-148_jpg.rf.096e55948843e4fded1561ae594ed75e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 40,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [246, 135, 208, 193],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [27, 40, 216, 297],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-44_jpg.rf.098bb28b212857d821caa453485961ad.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 41,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [268, 37, 104, 157],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-84_jpg.rf.0ba2d3565a59eee9c336554468c2c145.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 42,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [246, 309, 225, 157],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-230_jpg.rf.0a6e74023461c9e26c51b7bbf6516fe4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 43,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [157, 200, 237, 182],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [278, 289, 192, 156],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [128, 195, 86, 68],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-37_jpg.rf.0dad75b2afa474603f33a750a13f4e3d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 44,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [229, 266, 127, 72],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-201_jpg.rf.0bdd3462bc75c281e36ef211b49d39bc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 45,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [167, 271, 127, 88],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-82_jpg.rf.0d04c5b727d85a6d0253779aaa401e78.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 46,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [261, 149, 56, 258],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-6_jpg.rf.0cd7e9feb6538bebba409eeea7c3b0d9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 47,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [86, 72, 109, 194],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-81_jpg.rf.0b4b2161ddba93fbfb9f9d408ce13d45.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 48,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [386, 262, 43, 38],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [232, 220, 153, 143],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 283, 45, 186],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-197_jpg.rf.0eb8574fe1856dfdb0e9cf35f2a1efd7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 49,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [122, 244, 170, 143],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [301, 137, 85, 27],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-14_jpg.rf.0e800311e82ea75ff3d1c0a6cd981d65.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 50,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [145, 120, 92, 74],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-138_jpg.rf.0ee7da77b1adc9ffa0dc7bbca67316b1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 51,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [271, 202, 173, 112],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [390, 186, 110, 38],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-283_jpg.rf.0f7d7ae88d51ec18cf54aa33e5e74688.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 52,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 276, 500, 224],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-196_jpg.rf.0f961913e09407b73d1ed40242e2c4bf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 53,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [254, 254, 22, 88],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [220, 240, 22, 88],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [280, 272, 32, 88],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [312, 285, 35, 83],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-285_jpg.rf.0fd39e3cd89ca20e67ed5d361e892edf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 54,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 245, 500, 255],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-92_jpg.rf.101df846608e2606868354aed83e92b1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 55,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [218, 282, 32, 147],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [355, 196, 43, 146],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [433, 300, 33, 89],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [297, 212, 49, 109],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-104_jpg.rf.10152831a5e81af39a70664261b42086.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 56,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [63, 394, 40, 91],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-95_jpg.rf.0fce1db8f24424f4f72be85a606782b2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 57,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [69, 247, 430, 253],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [70, 150, 195, 151],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-176_jpg.rf.10cb9bdc8f062fd6b026dbb754b4d8d1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 58,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 135, 61, 226],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-149_jpg.rf.0ebe035fc74b4bd3b2e056deee086f4e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 59,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [137, 188, 362, 265],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [136, 154, 208, 105],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [471, 107, 29, 77],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [451, 110, 22, 24],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 117, 52, 81],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 175, 47, 87],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-1_jpg.rf.118847619caf8a38f8d0de8de6ddc87b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 60,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [326, 274, 165, 120],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-95_jpg.rf.10ef3f07943e8c1d4226d68f9f502b1c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 61,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [18, 333, 172, 146],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-69_jpg.rf.10ed1e602052b1aa82067c96aec76b3f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 62,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [151, 73, 227, 116],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-175_jpg.rf.10dc79dc4e1fe4abb876b47174487048.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 63,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [91, 209, 223, 224],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [290, 221, 166, 98],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [200, 196, 92, 55],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-142_jpg.rf.130d827539991a9daafd626b31537e94.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 64,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [111, 258, 27, 37],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [136, 232, 96, 67],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [155, 74, 339, 219],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-75_jpg.rf.11620910dc741dd28d863797c7b8a36a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 65,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [261, 273, 239, 227],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-304_jpg.rf.12015aa8bb7d6db7c78e36042e5c5275.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 66,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [86, 194, 281, 124],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-250_jpg.rf.1358872695bcc0a2b5d569d9eea8544e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 67,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [133, 73, 345, 220],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-190_jpg.rf.1423c2877fc5eee6016b9bff9696d7e0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 68,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 256, 72, 228],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-119_jpg.rf.13e92d6fb014db6a2988c1c02ee8a8a2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 69,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [256, 90, 61, 406],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-28_jpg.rf.143e75f34df547750a40d8f84ef94e00.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 70,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [170, 32, 309, 315],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-56_jpg.rf.150cb168a71627b808218e8f14dc8fd7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 71,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [114, 344, 164, 95],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [365, 305, 83, 77],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-77_jpg.rf.1518871fbb8fbc149f436e2b4c7d887a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 72,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [95, 222, 143, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [241, 213, 170, 110],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-41_jpg.rf.14cf10aca8caa7ba705edad519c0d63e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 73,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 70, 178, 282],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-94_jpg.rf.151920bcc41f884563fb279600bfffac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 74,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [283, 399, 217, 101],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-181_jpg.rf.1424a787a7552152d53222af3d47bd99.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 75,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 155, 386, 173],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-29_jpg.rf.16959d6a058ca69af7b3b9d22cc6c9df.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 76,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [345, 314, 76, 125],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [328, 269, 24, 63],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [308, 265, 14, 29],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-114_jpg.rf.168a794ade2e92ebee2a351ddc09b0ce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 77,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [268, 155, 219, 238],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [459, 228, 41, 82],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-5_jpg.rf.15f22c5fa423a4194f1fe79cfb2e3a37.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 78,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 185, 286, 112],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-3_jpg.rf.1621776119062a89042073d64697e0ff.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 79,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [153, 316, 91, 45],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-98_jpg.rf.1455ac435e75abcc62e32bac84ea9412.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 80,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [97, 358, 94, 138],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [119, 360, 247, 84],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-188_jpg.rf.15ed4ef498851565daaee6cddb8f65a2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 81,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [241, 236, 65, 182],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-36_jpg.rf.1684b35602fac58d4d0031e49e0a0f13.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 82,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [322, 293, 50, 127],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-171_jpg.rf.1765ceac4280cdbc876a45e720e15557.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 83,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 348, 90, 109],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [78, 316, 170, 149],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-242_jpg.rf.17c461f2e6fa0622892eecab3d4a76d5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 84,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [119, 153, 330, 305],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-293_jpg.rf.11f09d89bc75eb37a67188de9c28b6c1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 85,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 236, 330, 228],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-3_jpg.rf.181722b07f6803531721b9659d5a7148.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 86,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [334, 130, 34, 83],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [362, 269, 77, 42],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [90, 261, 107, 135],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [401, 100, 75, 33],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-195_jpg.rf.17e8bd08f6bf146fc6254c99abdb0f4e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 87,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [79, 146, 306, 171],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-108_jpg.rf.17489846d25018c8d92b493db92673be.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 88,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 310, 245, 119],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [248, 252, 252, 161],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-126_jpg.rf.177f621388ca459ca8d7f2e3c9824389.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 89,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [327, 169, 149, 85],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [134, 210, 165, 89],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-10_jpg.rf.17ebfb1c6dda2328bbe7d622ed7bd686.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 90,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [116, 93, 101, 133],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-140_jpg.rf.181c874df6eb3fa37ee27f68e15bb976.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 91,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [107, 193, 256, 244],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [256, 212, 69, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-179_jpg.rf.18dcf06cd061744347c671138a7aee42.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 92,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 179, 35, 121],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [39, 190, 141, 69],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-57_jpg.rf.1993c6a9f2926b19e5cea886bc7d58cf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 93,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 292, 72, 105],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [161, 264, 117, 86],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-225_jpg.rf.18de150bf5a2a6ad011326c791ace908.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 94,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [36, 212, 114, 84],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-38_jpg.rf.197cbf3d6f808a0b608d1364eba4274a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 95,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [103, 319, 397, 181],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-62_jpg.rf.19877e6f6e1f6f40856a8aa06c148e74.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 96,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [62, 53, 348, 228],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-35_jpg.rf.1bba28c1442bdcc5b01ccbe67dfc6d53.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 97,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [16, 38, 187, 309],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 268, 52, 45],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-136_jpg.rf.1a70234e1acefd6b0639e76dbc9b5b77.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 98,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [93, 0, 407, 227],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-199_jpg.rf.1940bffaac18333a6d328b430c9e82c2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 99,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [251, 157, 200, 125],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 272, 193, 138],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [137, 223, 172, 119],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-163_jpg.rf.1a1a14ea561d609653c7eac80a3026db.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 100,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [64, 158, 350, 105],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [178, 375, 12, 77],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-24_jpg.rf.1c3db991bf2d7d8b0441fa92273eb55c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 101,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 278, 65, 82],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [32, 280, 113, 101],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-98_jpg.rf.1a2985b27e766fb9165eeb4f9ebd7047.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 102,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [336, 297, 92, 92],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [312, 292, 34, 47],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [286, 284, 26, 32],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-86_jpg.rf.1c7b472ae8dd84f7ea0bfe007ca12496.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 103,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [183, 298, 208, 92],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-71_jpg.rf.1ab7eee13c0fd1c95af1cb18ec219b52.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 104,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [78, 125, 64, 125],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-136_jpg.rf.1c28ec71bbe9ebbbce45c1a8f666651c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 105,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [239, 184, 37, 316],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-25_jpg.rf.1afd5e301c079db9cc7b346b88845b74.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 106,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [251, 189, 248, 163],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-1_jpg.rf.1c52f9aebd402732c3e5a3ad0aac43cf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 107,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [57, 231, 319, 223],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-166_jpg.rf.1d60f6f945d9faec61b8ac914c7d58c8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 108,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [124, 229, 255, 105],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-34_jpg.rf.1cb4333449794949255127e95c35ee37.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 109,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 142, 258, 190],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-156_jpg.rf.1d62f02c9e523886aca2840f729590d8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 110,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [46, 60, 115, 284],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-177_jpg.rf.1736a39e0b6d8d01df40898a7dc33f0f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 111,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [295, 221, 193, 173],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-48_jpg.rf.1d8f951a2c81905c11c14872b4c71076.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 112,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [335, 224, 76, 126],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-152_jpg.rf.1ea95785d2a89d76cfd98b60372c05ac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 113,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [63, 240, 308, 120],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-13_jpg.rf.1e728a68df5196d015cc1b3705cb6cfd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 114,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [88, 92, 210, 145],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-106_jpg.rf.1ca5412f44388377c0901be093f11b4b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 115,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [98, 393, 402, 106],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-194_jpg.rf.1db8db5b4d0886e60272fc4b7322f0b4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 116,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [200, 172, 43, 167],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-150_jpg.rf.1fcd7dcbf198785a6daa42511edf5af0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 117,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [97, 291, 327, 118],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-184_jpg.rf.1f84b522ae3b47e069c116b104e43c71.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 118,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [136, 329, 192, 117],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [262, 260, 160, 116],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-90_jpg.rf.1ffd5f6cfe6c288dfd51bcc86225a0e2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 119,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [375, 249, 104, 59],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [145, 325, 169, 79],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-175_jpg.rf.1f806f3df14eb8f8656418ecef397c95.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 120,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 327, 301, 94],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-125_jpg.rf.1fb36c426b10f8dcd8d12a651843e5a5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 121,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [183, 101, 77, 326],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [25, 114, 120, 322],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-99_jpg.rf.18cee5dec61c04dcba115975bb8f4e8c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 122,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [223, 71, 45, 86],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 282, 141, 168],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [193, 45, 42, 45],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-152_jpg.rf.20db49089ce235803180f4d495f28bef.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 123,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [81, 182, 198, 88],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-153_jpg.rf.204a36932c3624dc0c513dbddd8a07cd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 124,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [264, 128, 108, 304],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-83_jpg.rf.2015740b19698f85606fff66082a6eb8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 125,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [160, 244, 207, 40],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-92_jpg.rf.211b849ace020ec9c2d75335c7efe0c1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 126,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 322, 162, 178],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-132_jpg.rf.2182cc2deb8b958861c94f29fb42f431.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 127,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [182, 174, 166, 115],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [86, 220, 189, 176],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-136_jpg.rf.213acdda43c0037f99d78d795ed895ed.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 128,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [35, 154, 309, 116],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-5_jpg.rf.22a3efb34372f44c2232a164e66095e5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 129,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [340, 23, 148, 144],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-16_jpg.rf.23103a2e022dea69b3b243a738fda399.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 130,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [108, 178, 392, 227],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-82_jpg.rf.219bdd3fbc4a693fcbd67d223307cbbd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 131,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [171, 122, 201, 123],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-235_jpg.rf.22d2010a503219ecd57cc8b22d5089a8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 132,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [376, 99, 124, 101],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [271, 155, 149, 107],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-57_jpg.rf.1bab88cef3fafab4e7ddce2c62d653b2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 133,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [192, 318, 308, 129],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-53_jpg.rf.23395f84ddf6fe2e444631e61b71bce4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 134,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [72, 276, 258, 109],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-11_jpg.rf.22b4654f9116e28e46937575c2b44215.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 135,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [122, 242, 133, 131],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-141_jpg.rf.27ce7fd0614a8eb17426ab5716019b3c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 136,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [108, 132, 103, 263],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-71_jpg.rf.253240ae39ffb6492d144c8aba629bc1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 137,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [111, 272, 112, 80],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-23_jpg.rf.24f47616bdb434b9650cec9868a280ee.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 138,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [129, 317, 166, 183],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [117, 28, 108, 99],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-130_jpg.rf.238ffeb7e9eb06b2ef192431072267e7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 139,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [87, 353, 197, 146],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [275, 388, 54, 32],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-60_jpg.rf.24f52a01e996593965bcc0dd04e11b90.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 140,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [244, 177, 45, 57],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [29, 216, 231, 174],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-103_jpg.rf.278c300a6779ef3cf920c9f2c919e0ea.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 141,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [232, 289, 106, 84],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [170, 257, 107, 80],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-96_jpg.rf.257ae64fa343dbb3c4a0a0b2d8a99a05.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 142,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 242, 210, 136],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-164_jpg.rf.23d9be5937c101fa548cb20759952f10.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 143,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [290, 325, 210, 134],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-58_jpg.rf.26e534fe115672de7de86a15d8cb4f80.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 144,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [88, 197, 239, 109],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-117_jpg.rf.28c24a9034bdc37534eaac696939b51c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 145,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [41, 142, 258, 315],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [10, 432, 150, 68],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-126_jpg.rf.295498776a1b5d7184885731f8a0b69f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 146,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [94, 198, 197, 217],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-30_jpg.rf.29402dd3c6899d83854af5451e93e67f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 147,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [343, 399, 58, 66],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-136_jpg.rf.28612e83355ac33951608249a1c5517a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 148,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 239, 259, 169],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-2_jpg.rf.297a10afbe26a72cfa423f13eec33400.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 149,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [297, 262, 138, 53],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [126, 228, 104, 48],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-117_jpg.rf.278dc8faf921a7429d49125e6b9f1919.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 150,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [332, 161, 65, 210],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-79_jpg.rf.243fc67092b7b3525ba5697ee24994be.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 151,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [162, 175, 166, 324],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-14_jpg.rf.25219cd2e48fdce0a2d852250b73c3c9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 152,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [22, 5, 137, 200],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [359, 236, 123, 89],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-286_jpg.rf.280ee04534265fb2c70cf0f967ed41bf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 153,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [402, 184, 98, 64],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [110, 191, 293, 178],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-142_jpg.rf.24516476750b9cee76b7e69055a49c57.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 154,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [174, 240, 308, 217],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [111, 226, 94, 44],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-17_jpg.rf.28ad451f0ebea7fdf156da5da210b846.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 155,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [3, 155, 244, 312],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-132_jpg.rf.27dd050ec548cb24a0be53efae959e37.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 156,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [228, 272, 101, 60],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-187_jpg.rf.26502ea7748a88bbb6a70aa4618aa49c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 157,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [291, 134, 209, 217],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-121_jpg.rf.1da03ec16f273d0c2135eb0c39eb6c67.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 158,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [191, 260, 268, 90],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-73_jpg.rf.23cc23bfc3edbc58f31fb98efb80d8a7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 159,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [130, 34, 370, 203],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-205_jpg.rf.298a9702737a4dd53198c37c599f5721.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 160,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [101, 320, 97, 41],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [145, 290, 74, 31],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [65, 350, 91, 55],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-233_jpg.rf.2a4820dafe4303cc015a12014fb99ba9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 161,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [101, 239, 221, 128],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [343, 206, 79, 42],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-128_jpg.rf.288b2b49709d8569a2c2078e83cdd51b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 162,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [144, 250, 252, 205],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-73_jpg.rf.2b579a764da0aea8989efc896208eb31.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 163,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [12, 339, 190, 143],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-48_jpg.rf.2a7132b2366342ffd3c92b1b7320503b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 164,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [183, 295, 201, 115],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [299, 259, 121, 76],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-198_jpg.rf.2a33479eb672c5f9dbab70b95ea7ef68.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 165,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [92, 168, 376, 221],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-39_jpg.rf.2c0176e7f9d5b37e70453e6ac15c972f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 166,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [223, 309, 64, 80],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-101_jpg.rf.2b7030037367ab709cfb0ec3e6c60db1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 167,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 257, 389, 231],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-44_jpg.rf.2bf4bd7e3fb7f3faee0d165484202779.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 168,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [171, 262, 17, 24],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [203, 208, 19, 91],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [250, 232, 35, 89],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [53, 266, 16, 27],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [68, 262, 10, 22],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [90, 245, 12, 25],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [132, 259, 13, 27],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [223, 255, 13, 29],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-26_jpg.rf.2c044cc0a6e3af2188e47f7df5b7257b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 169,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [246, 111, 190, 254],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-151_jpg.rf.2b0837a1115230547b7aeeda0b5ca8df.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 170,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [143, 324, 138, 148],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-121_jpg.rf.2cf2484bcd715d1eecae8c2baa16b83e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 171,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 55, 258, 273],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-27_jpg.rf.2dbb7780c4e0c718d12eb40e67565fb2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 172,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [324, 256, 175, 101],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [125, 146, 243, 160],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-109_jpg.rf.2d7b306d112e41c29fadd4c94a8bcd5c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 173,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [189, 231, 52, 195],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-9_jpg.rf.2d21e1102f6b80edacbca709ca273e7c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 174,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [341, 337, 50, 59],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [461, 334, 39, 44],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [218, 335, 50, 60],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-21_jpg.rf.2dd89a00da5dc5a58da18b4eca0ecfa5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 175,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [129, 213, 356, 222],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-40_jpg.rf.2f0622c57acba704cc97d7d67e9c2564.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 176,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [231, 62, 238, 192],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-177_jpg.rf.2dd7e98915b345f9abf978edba2c70a5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 177,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [114, 190, 225, 223],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-91_jpg.rf.2fb997052254f6910566525d019d1315.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 178,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [325, 266, 155, 136],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-72_jpg.rf.2df227d8058cac72a9aa38a74a896c3f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 179,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [143, 208, 35, 26],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [367, 162, 133, 44],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [267, 195, 129, 88],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [194, 190, 74, 50],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [13, 299, 107, 76],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [24, 180, 47, 34],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [91, 223, 59, 33],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [110, 198, 40, 25],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-41_jpg.rf.2f96f4c963d67bbf97b1e65a8e6350fc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 180,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [191, 149, 264, 352],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-3_jpg.rf.308c1f5905288308a646b8de929ed46e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 181,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [7, 91, 404, 126],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-137_jpg.rf.30a620060b490b2b8cfedd0ff358d49a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 182,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [115, 177, 285, 161],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [44, 145, 183, 89],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-149_jpg.rf.2f216353028a4c5dab3e730a4f03161c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 183,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [20, 111, 480, 305],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-97_jpg.rf.31bbfcda2869f612fc59756a6bf37e12.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 184,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 258, 499, 242],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-37_jpg.rf.316f7d84aae3be96b6b64a50185bded4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 185,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [233, 178, 67, 188],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [318, 263, 47, 117],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [374, 307, 34, 80],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-127_jpg.rf.30f777b4e0a64b3169c44cc2f3cec3b2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 186,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [72, 156, 397, 116],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 249, 175, 215],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-46_jpg.rf.30e9932909e2040bed24c9965082b9ef.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 187,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 220, 330, 134],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-239_jpg.rf.321c2c661b4ac798dc9a44753d0e5081.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 188,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [236, 210, 112, 63],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [143, 181, 102, 38],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-7_jpg.rf.30f97c24bc40c1fc9635fe29697c7b7d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 189,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [219, 236, 239, 238],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-201_jpg.rf.32dd9dc2d690c45820c2161346f794bc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 190,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [146, 162, 117, 278],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [297, 153, 94, 289],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-21_jpg.rf.33b3d52b2610c464b0d6bc240f03be5e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 191,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [98, 67, 142, 80],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-37_jpg.rf.32ab6164e4764e38dac76b2e6ac9c4ef.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 192,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [88, 149, 391, 189],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-81_jpg.rf.3238eb681407f5b91d7d38b56e0c39da.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 193,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [112, 179, 116, 260],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-128_jpg.rf.343f91ff827d10bd5c19a7cf9fcccc0b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 194,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [233, 177, 53, 148],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-70_jpg.rf.3470bbe81334357bfa988a5c97dc9929.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 195,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [91, 122, 51, 182],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-133_jpg.rf.3468a6c0f62483618788bca1a091169f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 196,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [161, 306, 293, 134],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [219, 227, 147, 154],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-178_jpg.rf.33180d9d9dc9bf42ecb83177e9f50067.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 197,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [138, 163, 67, 232],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [71, 226, 51, 170],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-122_jpg.rf.352f34ab1c44ed40462105128b823e76.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 198,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [173, 145, 327, 286],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-107_jpg.rf.2dddfa45c025e1485c8865491dc043af.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 199,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [269, 214, 163, 160],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-94_jpg.rf.35ba85dc2f5b70840e6d9f470f0cc64a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 200,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [48, 241, 412, 83],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-262_jpg.rf.35f7691d5a7c5b86541380adf61c5cb7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 201,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [204, 212, 145, 114],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-22_jpg.rf.34fc43f18e0602ea2fe4aa0cd31af6b0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 202,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 374, 321, 104],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 309, 119, 135],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-22_jpg.rf.3492a25011349ceee8626bd01b47db4f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 203,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [130, 237, 269, 176],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [8, 170, 141, 93],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [357, 208, 143, 143],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-92_jpg.rf.354cb44107216c06398ca005cdda1733.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 204,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [76, 265, 167, 187],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-68_jpg.rf.3620ae3ddfa58cb61ee420d39016564f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 205,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [276, 59, 164, 345],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-135_jpg.rf.34d6cbc8a6255cfd8123eafa268e0374.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 206,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [315, 121, 56, 49],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [144, 158, 42, 26],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-161_jpg.rf.367e4ddc9b9b2b351571a4ca7ad91d53.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 207,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [142, 178, 358, 171],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-12_jpg.rf.35a8d1594db1d3a9db39118ef30ab51a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 208,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [189, 472, 26, 15],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [143, 61, 179, 436],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [131, 473, 23, 14],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires2-0_jpg.rf.29eb84d489abe6ad8421eacb63f260fb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 209,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [56, 108, 84, 124],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [370, 66, 7, 20],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [390, 53, 13, 34],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [407, 57, 11, 26],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-191_jpg.rf.3609ee85796811ec124de67b92884aa3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 210,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [138, 147, 47, 33],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [70, 185, 118, 91],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-158_jpg.rf.36caf358045b5622645e4227ddea8749.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 211,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [214, 78, 258, 169],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-100_jpg.rf.375eabbfa529d21eb42e090fbe9b9040.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 212,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [70, 273, 381, 156],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-59_jpg.rf.36bb7dac7a7f233d298895715a10a566.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 213,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [108, 174, 203, 250],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 215, 112, 248],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [303, 207, 197, 214],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-189_jpg.rf.37502e1c02b1a562ab0f65ba5fa156dd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 214,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [153, 131, 193, 200],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-136_jpg.rf.36cea2cd9d2ca556aad0542dc1194aa5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 215,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [285, 307, 31, 50],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [282, 347, 61, 33],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [350, 341, 108, 136],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-97_jpg.rf.37ed79d58ef6acb730fd1f20663d9c44.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 216,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [91, 195, 161, 75],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-120_jpg.rf.3847b8d3b9423fd42340f645bf0d5465.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 217,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [69, 189, 37, 51],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [138, 195, 84, 133],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-184_jpg.rf.37f49562223f61aca107de707acb95d6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 218,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [225, 279, 234, 133],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-43_jpg.rf.38567b2f9346fa3d656bb986512ec31d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 219,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [255, 138, 95, 46],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [43, 97, 99, 57],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-5_jpg.rf.3983bc56738d160127e5ba4fc94e4e99.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 220,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [42, 390, 175, 95],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-137_jpg.rf.384608ce88749481a936fadb40fa519a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 221,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [216, 129, 284, 214],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-81_jpg.rf.39c619cbeb121661b8d2dc7a10c31a1a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 222,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [135, 364, 26, 103],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [183, 357, 31, 68],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [233, 259, 38, 130],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [280, 232, 41, 157],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [310, 194, 84, 127],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-152_jpg.rf.385c88401a2aa37397f6ae27c6b0357b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 223,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [194, 311, 52, 137],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-294_jpg.rf.3871be8025fbc0b2284be9c34bcda55a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 224,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [111, 136, 335, 163],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-15_jpg.rf.3a81d2841ee819bf7bcf6ec345b48492.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 225,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [356, 206, 13, 31],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [384, 264, 74, 124],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [374, 211, 26, 67],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-182_jpg.rf.3a520b1fed0982adc752ae48f5fd5497.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 226,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [205, 231, 278, 235],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-83_jpg.rf.3af17f323d42e9345ffeacb57216a112.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 227,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [25, 79, 212, 247],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-43_jpg.rf.3aebbbf388f4950a4a605d2ef89611d5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 228,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [158, 144, 262, 213],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [132, 73, 107, 87],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-157_jpg.rf.386c2b33ffbaa2d4204b6788fa4990b3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 229,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [130, 362, 154, 68],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [86, 391, 162, 66],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [242, 319, 85, 41],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [222, 347, 165, 60],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [77, 284, 79, 59],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-210_jpg.rf.38a180e75ccd7ffab0ea181a88bb66b6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 230,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [217, 253, 167, 69],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [340, 279, 159, 91],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-155_jpg.rf.3bc2845ea59c35963f402f4afb6986dc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 231,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [192, 218, 19, 43],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [211, 239, 13, 28],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [259, 254, 15, 42],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [292, 274, 26, 41],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [323, 292, 14, 39],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-12_jpg.rf.3b28c6960793906941f23fe498b0bef6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 232,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [263, 110, 202, 92],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-252_jpg.rf.3bc7e4b2868cf0eb2f97af610bc61bdd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 233,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 281, 423, 208],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 259, 80, 82],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-170_jpg.rf.3ba74ce7fd93379604d4a1c64e91ac44.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 234,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [125, 286, 312, 169],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-291_jpg.rf.3bcec6ec40a44aa19cfeb445198adeb8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 235,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [314, 303, 119, 106],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-64_jpg.rf.3cb03f17211e1fbf7bfe0279235fb98a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 236,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [131, 254, 123, 125],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [254, 260, 96, 74],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [351, 278, 105, 72],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [260, 403, 119, 63],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-56_jpg.rf.3c571ca1aaf37297045528f693c9c3af.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 237,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [49, 372, 441, 116],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-112_jpg.rf.3d8917e62df484f9f415097a6b4c13c4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 238,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [266, 223, 222, 103],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-14_jpg.rf.3dc426249cf5deec3adb59635f6e7534.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 239,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [66, 1, 206, 210],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [250, 372, 180, 83],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-124_jpg.rf.3c3c4d5e9a1fc07f77e00d53ea2dfe47.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 240,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [179, 306, 321, 194],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [151, 253, 161, 77],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [47, 286, 131, 85],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-41_jpg.rf.3ea9520237482f7aafce84861c4777ad.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 241,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [220, 172, 179, 53],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-58_jpg.rf.3c5b4a8313fbfa7c57d35d67b59f0eb7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 242,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [199, 272, 201, 136],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-108_jpg.rf.3d11c40695dbff42ea0fdb9bf33875c1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 243,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [5, 115, 295, 173],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-92_jpg.rf.3e61539050786e91bd860f3fe24e1ac7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 244,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [216, 200, 280, 286],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-138_jpg.rf.388b5e26a4ffc0d96352a279524042a2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 245,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [357, 100, 129, 175],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [197, 50, 173, 173],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-181_jpg.rf.3e7b69cf7ea14d6d4e4b95d4e988f293.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 246,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [169, 378, 180, 116],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [14, 326, 183, 114],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-93_jpg.rf.3c203d7ea31164dcb12f06417940de3b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 247,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [79, 203, 88, 92],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-56_jpg.rf.3ee6b9f8ea5ab7d369f4a6f55b2e3e8b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 248,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [140, 170, 229, 265],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-243_jpg.rf.342636369d0a4a173aed9b833bbfae16.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 249,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [170, 199, 330, 301],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [70, 147, 117, 105],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-152_jpg.rf.ecedc4375fd21a1ca277d8a455242de8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 250,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [138, 138, 229, 278],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-140_jpg.rf.eb4fdd6e23e36cd2d71e80e7872cb23b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 251,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [361, 156, 77, 263],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-38_jpg.rf.ec48e8d68550f29216f5fec153ad1be5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 252,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [175, 241, 95, 164],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-198_jpg.rf.ece825ef6d409d69308ce2b6dd8436d8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 253,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [52, 244, 395, 205],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-27_jpg.rf.ec2fe1a2ebf668e5ab27a29a45c22561.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 254,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [149, 342, 211, 90],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-281_jpg.rf.eae857bf3caca9bc7c1fdd904656f431.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 255,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [338, 171, 147, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 213, 353, 235],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [218, 199, 186, 51],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-129_jpg.rf.ec89eb6356dd7a1a3b4384152ed18b6d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 256,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [60, 205, 399, 236],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-94_jpg.rf.ef25ffaeccf174e27f842a7a7574fd9a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 257,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [198, 177, 101, 64],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-105_jpg.rf.ee44e3509bafc0bb5d63f663dee76412.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 258,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [203, 289, 297, 184],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [52, 264, 184, 107],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-15_jpg.rf.ebcd38ad18e768dd734f3339a9d5e1f2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 259,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [240, 110, 210, 187],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-82_jpg.rf.eb1af995d0b16eb6db9fe7aebde18e75.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 260,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [54, 298, 116, 90],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [133, 346, 144, 87],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-47_jpg.rf.eefd1a5bc6b363a88a2d85626a92031c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 261,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 172, 232, 244],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-12_jpg.rf.ee9a9042a22b4d282ff9829776e1627b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 262,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [379, 243, 121, 146],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [276, 222, 116, 111],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [191, 213, 133, 63],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-125_jpg.rf.edaa7558751913d2d9830873e83cd72f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 263,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [287, 144, 16, 33],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [357, 170, 37, 23],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 417, 76, 82],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [222, 172, 51, 68],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [266, 162, 28, 53],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [303, 142, 12, 26],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-2_jpg.rf.ebd8be3ff2949718b1cc444f4b77d648.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 264,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [193, 207, 37, 200],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-23_jpg.rf.edeed5a3786f3f529adbf2037d88f5c1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 265,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [236, 196, 114, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-101_jpg.rf.ed913192ada9883e2d07cd26198120f2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 266,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [89, 191, 210, 84],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-2_jpg.rf.edff653286d3941263e6b4dfa08ad493.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 267,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [73, 196, 392, 181],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-68_jpg.rf.ecb49b329b82790408566d35823bdfa5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 268,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [132, 275, 187, 108],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-45_jpg.rf.ee9747f162440f73ea2cbd0d950e926e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 269,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [248, 92, 70, 90],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [376, 127, 61, 91],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-14_jpg.rf.eb39f3b001fcaa7de331e8206a927927.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 270,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [208, 59, 121, 363],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-156_jpg.rf.ee5e3a14eae92ddd5ab3f46589932e4e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 271,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 354, 128, 124],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-67_jpg.rf.eef63bbf19a2e352a0e826cdf3938486.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 272,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [80, 266, 420, 115],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-259_jpg.rf.eec4e4213918aa38d9e0fd248a4ea179.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 273,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 119, 107, 102],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [175, 149, 325, 246],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-120_jpg.rf.eea79202c4f04b74b70dc1ede99c53f4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 274,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [190, 290, 224, 99],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [349, 259, 66, 101],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-9_jpg.rf.efb86552e37952fa689025dc264222a3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 275,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [284, 245, 44, 69],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-19_jpg.rf.efba47928adeb6aa6534480866ced22a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 276,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [238, 114, 81, 116],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-12_jpg.rf.f096ccc1ec55230334b817f5dcd70369.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 277,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [445, 328, 55, 172],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [241, 237, 74, 76],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [230, 171, 61, 95],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-184_jpg.rf.f0cb56b5f8fe3c1b76286c78b2d00587.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 278,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [134, 312, 160, 187],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [72, 451, 93, 49],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-113_jpg.rf.f10f6bd9503261788005c48c6db8922c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 279,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [280, 182, 80, 76],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-100_jpg.rf.f08ced8e211e3b04c9013d1245664f81.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 280,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 319, 256, 49],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [277, 325, 220, 125],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-21_jpg.rf.f1c37a8733b45ca693795c3731f7d186.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 281,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 98, 360, 402],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-292_jpg.rf.f1177d3d3ba2219f3a76fd35aba81497.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 282,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 129, 255, 178],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-186_jpg.rf.f17a3f4fa258071369ab947c25be5187.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 283,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [167, 188, 61, 245],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [104, 238, 46, 174],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-144_jpg.rf.f25a9d010d5f8838c44baa3c382c706c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 284,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [270, 213, 163, 201],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [118, 197, 50, 25],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 233, 41, 35],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 274, 68, 61],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 395, 105, 103],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-55_jpg.rf.f1749d87076e1b1bce8d52910e5bfdf9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 285,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [114, 346, 318, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-198_jpg.rf.f09da0404234be2ef888bfe03d174cac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 286,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [206, 392, 110, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-104_jpg.rf.f2b26f521a4f0d8dd0aec9b3c7f1027a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 287,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [5, 226, 314, 144],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-149_jpg.rf.f0f26e0f63f52ad493c3389aa5c90b63.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 288,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [260, 157, 42, 320],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [317, 307, 46, 162],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [439, 403, 15, 44],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-22_jpg.rf.f304a1216ab13ba8c763a8fdbf409984.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 289,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [234, 60, 163, 234],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-166_jpg.rf.f303cf11a038509ce214b178699ab7ff.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 290,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [100, 139, 63, 300],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-41_jpg.rf.f3aaefb0bcafa4a5ae26d54829d4b034.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 291,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [68, 143, 258, 167],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-181_jpg.rf.f42a1118063f752829619dce2fe83573.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 292,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [82, 37, 197, 98],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-142_jpg.rf.f42e6632bd0568dc12555b17205f523a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 293,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [87, 239, 280, 110],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-79_jpg.rf.f4706c8984a764838c6985b3bf1c6613.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 294,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [111, 261, 164, 81],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-212_jpg.rf.f48c103689a6193d69dc3289a0ec41ec.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 295,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [90, 265, 375, 150],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-77_jpg.rf.f498324c1de2823a7db834825e9be98d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 296,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [34, 177, 170, 131],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-141_jpg.rf.f4b31fe91187debc475bee7241a9854d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 297,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [54, 188, 349, 126],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [270, 23, 230, 193],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [64, 87, 27, 58],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-147_jpg.rf.f4de20c3abe10850aa9d0ade139026b1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 298,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [297, 251, 183, 173],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-51_jpg.rf.f4faf41081232ed7ff0edbfa440db113.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 299,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [104, 168, 149, 170],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-8_jpg.rf.f5288a3fa412c34d79274e74301aa8de.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 300,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [49, 71, 247, 165],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-3_jpg.rf.f4fec8288af0c3614e4a77764af13a60.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 301,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 186, 22, 188],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-88_jpg.rf.f53474b9395c79059aff875847efeb28.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 302,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [14, 312, 190, 96],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-71_jpg.rf.f5a2a59f878a4efe85e93cb9f5c84021.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 303,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 278, 68, 118],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [61, 224, 175, 163],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-168_jpg.rf.f631fb530d6a7921185ef0bccd078e6b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 304,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [86, 112, 214, 96],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-137_jpg.rf.f54730558d053ad1b74f09383925fc7d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 305,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [340, 239, 160, 109],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [247, 320, 88, 56],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-121_jpg.rf.f5c2b735146550bcb57cf94ddf314384.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 306,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [308, 228, 109, 76],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-47_jpg.rf.f703230a3df3ebb95d63cd8cb58dd4f7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 307,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [425, 214, 75, 69],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [97, 218, 144, 94],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-151_jpg.rf.f747e8d79051041caa0bdcdfe8f86582.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 308,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 162, 99, 336],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-23_jpg.rf.f77f719083bb33f4da3d04a67a8e3484.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 309,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [329, 204, 105, 154],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-171_jpg.rf.f79ec5a3a7aafa04440b752993457413.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 310,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [251, 185, 68, 77],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-139_jpg.rf.f695ae9ece29064571c49fe4bb2c2011.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 311,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [152, 296, 348, 177],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-205_jpg.rf.f73945057affcf3dfef9c19eaec0056f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 312,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [146, 266, 114, 85],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-31_jpg.rf.f6321772930c1a7ea61757e8fa476e17.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 313,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 52, 374, 214],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-66_jpg.rf.f7a9e967e93b11d84373a9d1579792d9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 314,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [186, 277, 306, 212],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-244_jpg.rf.f82c184e2234589955beed6a884bc63c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 315,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [253, 249, 177, 106],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-258_jpg.rf.f7db9aa89e75e595e30121a7b5ca43ef.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 316,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [407, 172, 29, 30],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [236, 227, 172, 104],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-30_jpg.rf.f86acfee0ea24dfaa8d4c96deb8165a8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 317,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [165, 119, 137, 338],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-212_jpg.rf.f89119dda2b111abff373ce3339526f6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 318,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [276, 284, 179, 117],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-71_jpg.rf.f8cd35d2b58a1e864c5d7b72e02f5d12.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 319,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [53, 158, 174, 296],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [235, 48, 252, 55],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [193, 61, 171, 283],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-246_jpg.rf.f8aecfa7cac3e68c43782a302a16c345.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 320,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [49, 295, 224, 66],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-129_jpg.rf.f92c240a60171703a857358fd53eb2eb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 321,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [146, 127, 67, 348],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [49, 128, 60, 362],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-8_jpg.rf.f9972b463fd67d95af6015fdc03e0dce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 322,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [122, 146, 159, 151],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [121, 218, 366, 77],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-100_jpg.rf.f9709b35b3868f2e31730aa35200816d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 323,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [51, 225, 23, 108],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [80, 262, 24, 68],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [144, 276, 20, 45],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [191, 199, 27, 115],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-228_jpg.rf.f89e8dae32cee8cdbb88a451063553ea.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 324,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 254, 321, 179],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-136_jpg.rf.f94e0a4502afd785bb8b4ba6fc9a0f20.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 325,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [170, 314, 163, 90],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-51_jpg.rf.f96e81049e72b45f1df6566771a9a94c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 326,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [30, 140, 286, 161],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-130_jpg.rf.fa65e2142d0904af61937641ce2dab1f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 327,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 333, 204, 101],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [175, 288, 324, 153],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-68_jpg.rf.fa8bdd8ae83a50c0c4781cd4ae9fc60b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 328,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [337, 231, 148, 183],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 222, 32, 46],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [268, 213, 95, 113],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [185, 204, 86, 88],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [167, 198, 40, 45],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-154_jpg.rf.f9eee3bb1cfb4649acf2a71e8d4268a1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 329,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [324, 306, 163, 177],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [266, 266, 84, 92],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-115_jpg.rf.fae2384d2efc0b8233bbec8810f0db45.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 330,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [25, 185, 446, 274],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-10_jpg.rf.faad0cba229ec3e5e5ca4be55c09e663.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 331,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [110, 266, 206, 76],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-163_jpg.rf.faec778b6f9cdba6d94f4429057b185d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 332,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [194, 117, 199, 379],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-7_jpg.rf.fb981a9f0ea109b9c9147868fa6ba522.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 333,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [85, 342, 169, 126],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-145_jpg.rf.f8885c56b16ad4cadb481452f5862d21.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 334,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [274, 194, 77, 182],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-65_jpg.rf.fc51186f5ab8c23ca55ec59b2d961a99.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 335,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [309, 118, 81, 324],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-167_jpg.rf.fca0c4a5c1cd8b5d9afd12b720c7c4d5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 336,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [325, 216, 100, 106],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-4_jpg.rf.fbfbdcb6bee4dae5df02234faafe8838.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 337,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [254, 64, 115, 384],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-300_jpg.rf.fc721a4d20cf83d3969365dc607fa004.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 338,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [103, 264, 397, 236],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-98_jpg.rf.fc63c8ae024eadb1c29ea38fe572b889.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 339,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [93, 93, 107, 83],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-213_jpg.rf.fcea760d72881d5cac6a0b3b8c87b510.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 340,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [33, 288, 134, 49],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [89, 313, 217, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-215_jpg.rf.fd32580082c5c9fd4c051516d97e9f2e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 341,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 253, 56, 30],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [55, 261, 44, 45],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [100, 243, 38, 43],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [139, 236, 82, 50],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [118, 301, 278, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-122_jpg.rf.fda22519be7fe9698ddb3b38fe4d9ad4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 342,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [164, 176, 83, 41],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-19_jpg.rf.fc289ff0aa37cfc7b144fc2399d34da4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 343,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [247, 338, 57, 53],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-81_jpg.rf.fc88d781872a0169642bbf0c22593726.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 344,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [388, 218, 112, 74],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [217, 304, 174, 121],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-59_jpg.rf.fc3cf8b6811f3fbd6031a86660260c4e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 345,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 317, 500, 183],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-49_jpg.rf.fc86b4135a66c118cfdbdcb3e8b05a6e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 346,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [291, 256, 195, 131],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-72_jpg.rf.fc69105815324da70f4d75d2af71ea2d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 347,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [99, 251, 28, 58],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [284, 161, 81, 230],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [217, 221, 32, 82],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [171, 100, 43, 239],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-156_jpg.rf.fcb1f5ff37033787081984b3e8577c89.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 348,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 197, 44, 37],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [90, 228, 279, 210],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-3_jpg.rf.fda7961a6a2b0221e89754d91cabcd55.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 349,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 159, 252, 230],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-17_jpg.rf.fb3d1579f0f0ee4a78cb7dab1630404b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 350,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [398, 259, 92, 88],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-206_jpg.rf.fe4c294c65006492a221770f3b521ba0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 351,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [88, 337, 119, 89],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-216_jpg.rf.fdfc3f25ee77631b1069cfa81885d0dc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 352,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [70, 438, 83, 46],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-57_jpg.rf.fec14e746b635a6b57d495da3f9c5324.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 353,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [405, 207, 95, 135],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [106, 205, 315, 161],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-13_jpg.rf.fe81dac46be1ad66e4e47e5b63297aed.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 354,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [21, 139, 324, 186],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [145, 323, 356, 139],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-51_jpg.rf.fe787eec03225c2df78b03d355e7a999.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 355,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [437, 299, 53, 68],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-154_jpg.rf.fe109a5e8b3c649fbb9b57c47e54acb9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 356,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [237, 313, 164, 58],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [219, 331, 109, 93],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [176, 229, 60, 35],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [242, 223, 46, 26],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [7, 367, 121, 52],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-80_jpg.rf.fdae391e776119c76d70146b632b6c49.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 357,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [318, 281, 82, 77],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [114, 275, 175, 70],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-162_jpg.rf.fefaf6d5354bcac2a054f2562e9c3588.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 358,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 131, 82, 258],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-90_jpg.rf.ff7d7af14fdcc4a44f32cf90c243ad70.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 359,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [249, 304, 119, 85],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [341, 333, 102, 93],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-28_jpg.rf.f9f8a433a98f5a547d3351cd75c5fd37.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 360,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [16, 348, 192, 47],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-169_jpg.rf.ff16208a5b049ea26dbd063307449921.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 361,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 319, 498, 181],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-128_jpg.rf.ff5e75701ef02291a350923ce3671bc0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 362,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [3, 174, 317, 170],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-90_jpg.rf.ffd26ffd5d638d125e89f0816366b4e9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 363,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [104, 215, 79, 122],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-163_jpg.rf.ff8970b84582aedf24684bcf2ce89aac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 364,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [78, 218, 84, 57],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [41, 216, 50, 45],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [359, 372, 141, 124],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [255, 253, 181, 199],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-62_jpg.rf.ffbd33d46eb2ace622955aeca2280e31.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 365,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [222, 296, 67, 33],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [254, 319, 122, 74],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-105_jpg.rf.fee63ebc93a833bb6ba31d08871d14f6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 366,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [125, 230, 375, 257],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-180_jpg.rf.b126abc30d289453be663d3f45fb2f0c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 367,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [37, 243, 344, 174],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-185_jpg.rf.b174d5087521498a204e317f36455fc8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 368,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [456, 197, 44, 106],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [28, 294, 366, 165],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [326, 220, 51, 26],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [279, 220, 30, 28],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-174_jpg.rf.b0efcf7245db6d5682454a605d4ea539.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 369,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [253, 265, 42, 130],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-153_jpg.rf.b0f5027222c4dda02aa638ff05e694d9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 370,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [27, 140, 257, 138],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-114_jpg.rf.b1448cbb7dd53e6334f810a1271d9ab1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 371,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [240, 259, 115, 45],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [264, 369, 77, 52],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-99_jpg.rf.b004ccad5b9ecd903c882846b77ef736.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 372,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [287, 118, 94, 222],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-43_jpg.rf.b0abbbd056bf84a96c6bd1abef6e94de.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 373,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [141, 240, 67, 110],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-10_jpg.rf.af64a6346a31d4802880dcc2de894e42.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 374,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [164, 83, 241, 183],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-162_jpg.rf.b6e84c3975880484833185cb79595a1b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 375,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [300, 375, 136, 54],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-74_jpg.rf.b359e3099009ef937b97f34cf10b59c8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 376,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [312, 212, 91, 181],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-191_jpg.rf.b3bd5fbd3b80b2c2f32742c150979cdc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 377,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [207, 229, 65, 173],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [352, 331, 32, 93],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-56_jpg.rf.b51a8085910a7db791fabe03d9797510.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 378,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [262, 334, 145, 51],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [163, 302, 55, 21],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-303_jpg.rf.b667416eccbd53158879ec410887b26b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 379,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 105, 377, 340],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-125_jpg.rf.b5852dcf95534c9083c38b8ea3206b18.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 380,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 105, 132, 58],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [296, 246, 204, 176],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [135, 330, 189, 170],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-220_jpg.rf.b5afe3f1d0d3491f2c3a6edc3efcb0b8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 381,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [45, 269, 276, 221],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-188_jpg.rf.b3811774c4c4125974af26dfef37c3cd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 382,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [77, 183, 102, 67],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-202_jpg.rf.b32abc97f94bbb1e0e00161bc59e3213.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 383,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [230, 278, 138, 75],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [307, 300, 188, 93],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-102_jpg.rf.b52b54556568b650835dab11aa962173.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 384,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [69, 286, 431, 168],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-120_jpg.rf.b31ad275e4f09ebf393ef2f7fba4f9ba.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 385,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [371, 177, 115, 289],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 144, 141, 225],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-85_jpg.rf.b556f7384b1c88758b705913fff8698e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 386,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [44, 221, 104, 73],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [245, 253, 123, 43],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-138_jpg.rf.b53edc0286936e14b8d85c596b9ac1b0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 387,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [157, 228, 56, 49],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [129, 218, 30, 30],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-77_jpg.rf.b47acd8d045d8ebf9b8627bfee3a3248.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 388,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [233, 206, 134, 48],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [159, 257, 207, 98],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [280, 258, 220, 232],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-52_jpg.rf.b46c40144e70ede85f604ef8d0060f88.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 389,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [21, 39, 479, 320],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-47_jpg.rf.b692db4a7099293240e3ecfdd927a36d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 390,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [66, 200, 150, 192],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [236, 361, 66, 56],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-137_jpg.rf.b4ca42c8abee1fbd0a1aaa3c55397283.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 391,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [149, 289, 30, 99],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [179, 267, 30, 123],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [272, 283, 36, 131],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [242, 313, 29, 97],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-107_jpg.rf.b7777deb4f7655b5cb23cd0c23bb6234.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 392,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [295, 161, 149, 339],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-186_jpg.rf.b71ec2c18b99f99d05d8d2e438925b41.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 393,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [238, 244, 132, 194],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-84_jpg.rf.b7b1e19609d31440184f415b63297866.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 394,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [270, 161, 68, 212],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-164_jpg.rf.b738f48a9f1007b0e7098869c449f228.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 395,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [146, 223, 39, 182],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [290, 166, 67, 234],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-54_jpg.rf.b7a4b2151994219610b6feae394c9d09.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 396,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [213, 110, 255, 147],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-190_jpg.rf.b808e634a644213f5d2bab64e00d02b0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 397,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [248, 265, 130, 72],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [146, 249, 72, 70],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-27_jpg.rf.b900d46c01d5e8f99acdc94e88a49614.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 398,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [147, 152, 94, 144],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-89_jpg.rf.b9111abaa0bd42f82a613578cf636da4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 399,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [79, 235, 304, 170],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-235_jpg.rf.b8b8ea80f201223c481ebc5d70429f87.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 400,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [24, 182, 184, 123],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-138_jpg.rf.b853ab22205c8f0460664edd7d9d10df.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 401,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [226, 215, 83, 178],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [333, 214, 66, 167],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-156_jpg.rf.b946cd450b8bdc58db4d382179f4586b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 402,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 292, 330, 134],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-135_jpg.rf.b97be165ce81d4bacfef1737aaf08ad2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 403,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [165, 352, 157, 101],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-118_jpg.rf.b7c7a27c9e759e9087c51f6bd8f3e677.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 404,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [336, 218, 95, 48],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [285, 69, 25, 96],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [60, 297, 256, 146],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [254, 247, 104, 58],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-48_jpg.rf.b98e6e508288c5755b101bf3bee317d4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 405,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 170, 58, 217],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-202_jpg.rf.b99139479e4af9136d52cc9b42d59a66.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 406,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [170, 351, 100, 76],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-24_jpg.rf.b9c67914ceb077e522e8cc7bd0b960d7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 407,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [127, 199, 113, 140],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-131_jpg.rf.b9e13052b44ab106e4c4b55dcb7411b2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 408,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [358, 383, 142, 69],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [301, 300, 122, 113],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [226, 252, 104, 105],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-35_jpg.rf.ba194bbcf8c278764f94bd3e72b0c4df.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 409,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [144, 289, 219, 117],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-52_jpg.rf.ba531b4c18fa5153e5d2b51fd470f222.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 410,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [28, 136, 62, 54],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [32, 129, 172, 136],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-153_jpg.rf.ba530bf227132051936e142c436cca19.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 411,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 40, 348, 244],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-30_jpg.rf.ba3cdca43da0f753c03367c091ea6bb5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 412,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [420, 173, 40, 112],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-185_jpg.rf.bb8dec5024eb038a1ba52ae6ed83b21e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 413,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [344, 179, 83, 268],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [316, 343, 34, 109],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-301_jpg.rf.bbd5137d7032664a8b5b0f8afe6bfdc3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 414,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 295, 461, 205],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-2_jpg.rf.babcfb07b70cbae1a42a2b63d8ef8fac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 415,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [131, 214, 192, 125],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-7_jpg.rf.bbcc70cbd25b22d5d6d8f75f7c3a1092.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 416,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [48, 252, 98, 54],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [228, 130, 126, 193],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-39_jpg.rf.bc97acbade1976178f836c70aad494b1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 417,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [4, 9, 207, 453],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-25_jpg.rf.bbe88d9882c5870c88498d8524315e4a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 418,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 49, 289, 310],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-8_jpg.rf.bc0b78fdc43cd1ef1b3d51ca397982ff.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 419,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [73, 188, 291, 258],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-43_jpg.rf.ba95f826a0c2bf338b24272ed83b1656.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 420,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 289, 398, 211],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-33_jpg.rf.bca50b19e0ec8eb68cafbcf0338e7387.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 421,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [53, 116, 214, 122],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-39_jpg.rf.ba1f41acdf299c1f66e64f3a67a757e2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 422,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [145, 221, 113, 57],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-79_jpg.rf.bb3c1a4b78b466042eb7d20dd6bc29c0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 423,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [468, 183, 32, 116],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [62, 224, 273, 223],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [310, 207, 185, 136],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-193_jpg.rf.bce9946c0820d011c32aa062dcb30d18.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 424,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [100, 31, 14, 65],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [222, 307, 107, 58],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [140, 39, 10, 60],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-78_jpg.rf.bd00cfaefd97245c35e5c9b63432351b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 425,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [43, 115, 212, 227],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-123_jpg.rf.bd36c23d06c0f30dc7a84184e7bb679f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 426,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [50, 313, 74, 83],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [397, 335, 19, 25],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [291, 313, 55, 42],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [363, 329, 34, 47],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [374, 344, 126, 93],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-1_jpg.rf.bd7ef3dd7aa632659470544dffde295a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 427,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [242, 168, 58, 70],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-109_jpg.rf.bddf692e9ac8c4bab3303bc94c413873.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 428,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 293, 250, 108],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [245, 259, 193, 136],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-280_jpg.rf.be583afce1c224261ba545c8b39eec91.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 429,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [18, 178, 292, 156],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-8_jpg.rf.be877aa05beded87aad8cbc33a42f2d5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 430,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [147, 25, 176, 174],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-139_jpg.rf.bed23ad55574286c6293dd2fb8ff047a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 431,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [123, 153, 172, 257],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-57_jpg.rf.bec92c37999d63ed1dbcf13e3c9633b3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 432,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [280, 173, 91, 215],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [375, 271, 40, 95],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-0_jpg.rf.bef59aefe8790d0bc4d0a0f487074a05.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 433,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [253, 161, 106, 48],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-190_jpg.rf.bf05960c761a22f983f56d5cc5653ec4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 434,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 314, 74, 40],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [75, 276, 118, 58],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-0_jpg.rf.bd9846ddf7410d23d1e719b345fdaad3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 435,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 188, 311, 90],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [379, 178, 100, 30],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [79, 221, 176, 75],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-64_jpg.rf.bf51ab2ae8620c147dc5d13777c74b73.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 436,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [281, 230, 219, 176],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 195, 300, 87],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-123_jpg.rf.bfd09ee76d86fe6e84c0e3af02989110.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 437,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [119, 51, 353, 208],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-158_jpg.rf.bf7c686b6d6c184da07da59823a652b9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 438,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [42, 142, 91, 67],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [223, 202, 244, 289],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [117, 209, 107, 179],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [92, 156, 134, 78],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-70_jpg.rf.bfe0d859d2f2dfa5ec98c8b0be22da8f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 439,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [74, 196, 326, 167],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-19_jpg.rf.bfea436f150df249d5d7c80d2f865eb3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 440,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [329, 238, 86, 110],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-93_jpg.rf.bffca916cb62722e4432b5e1581856ce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 441,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [348, 411, 152, 89],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-158_jpg.rf.c03c1049b34264a0bab5f7a5f4bbf98e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 442,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [188, 142, 107, 187],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-105_jpg.rf.c0198b0afbc898d929030daabf18a744.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 443,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [52, 184, 41, 176],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-15_jpg.rf.c0b66c4d2b4e81794f2a21e122e759f9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 444,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [200, 281, 33, 45],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [270, 17, 166, 246],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-83_jpg.rf.c04596fb8995f9a7de5aad0ef3d5a63e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 445,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [267, 176, 101, 113],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [176, 85, 111, 213],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [473, 161, 27, 165],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-218_jpg.rf.c181d8caede45ab8c316b7bc4bd93f8c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 446,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 295, 130, 164],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [413, 217, 87, 129],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [130, 262, 341, 193],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-117_jpg.rf.c14b6ae43ffb7d3750a17ca2b6ee46be.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 447,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [272, 109, 108, 105],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-49_jpg.rf.c060c804ac46420c29aa3118de12f639.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 448,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [171, 125, 174, 71],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-0_jpg.rf.c223dfb01b95a4758a0b80cf8f767276.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 449,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [257, 152, 138, 102],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-87_jpg.rf.c157fedada03f3fa42093b470a30a05d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 450,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [233, 204, 71, 68],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [273, 232, 195, 206],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-86_jpg.rf.c2a9684f73e39b47858183766a018a17.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 451,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [105, 296, 313, 182],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-167_jpg.rf.c2f17c52c2f758e406a5692aeb7865e1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 452,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [273, 249, 56, 49],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [96, 285, 66, 70],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-33_jpg.rf.c43d8c9880fef7b2bff69b7866e35fbe.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 453,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [110, 245, 107, 78],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-132_jpg.rf.c0cdbff936ba9dcb2454316a28b767b8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 454,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [378, 197, 84, 139],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-76_jpg.rf.c47337d156886191494c943807de7211.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 455,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [3, 273, 208, 213],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [211, 226, 289, 157],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-0_jpg.rf.c4da9bb3ab3873448f66fd0135b4f0df.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 456,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [184, 90, 243, 157],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-66_jpg.rf.c5fd8f7d13fc9289eb6cc62ab2055ba4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 457,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [135, 159, 143, 61],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [50, 218, 25, 20],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-198_jpg.rf.c6319e5321baa63d81292741ca998fd7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 458,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [274, 261, 61, 177],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-116_jpg.rf.c5eff64517742497a1dc0c8035f0a21c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 459,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [188, 216, 32, 109],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [71, 373, 130, 127],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [231, 307, 261, 185],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-36_jpg.rf.c568e1f375297317586f42a4a49b2d6e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 460,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [104, 251, 397, 238],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-230_jpg.rf.c540aa68e52fa9161f2fa07a2a35af05.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 461,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [45, 228, 418, 107],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-182_jpg.rf.c5b040405979ff1497ed83b0eded21e7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 462,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [43, 251, 317, 188],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-89_jpg.rf.c65d63a8791dcc6424ffbeb732d5b624.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 463,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [179, 246, 267, 244],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-24_jpg.rf.c6a7338b1b5f9acc0b012ed6e79c9fd5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 464,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [180, 165, 314, 119],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-1_jpg.rf.c70d675d92e3f6f0a69edc251796b0b8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 465,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [297, 191, 49, 218],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-141_jpg.rf.c79663308adc0c6490173b9441bc5bed.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 466,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [276, 184, 87, 189],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-137_jpg.rf.c7f8c749ea3bff1e84bffff85198e24b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 467,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [71, 170, 64, 27],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [164, 131, 137, 64],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-0_jpg.rf.ca9d2e76abe6edaee48a2a73e08b0595.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 468,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [249, 105, 61, 228],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-150_jpg.rf.c99b08eaa19c689e1291f1f4155994bd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 469,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 247, 499, 253],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires2-103_jpg.rf.c969d34a87101b3ed4dd51254b3e9f1e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 470,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [9, 29, 191, 90],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-17_jpg.rf.c78ea3e288538e37703776aefb3cf865.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 471,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [234, 171, 254, 126],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-179_jpg.rf.cacd511df9f750bc63034c083a7c3974.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 472,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [11, 120, 181, 101],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-106_jpg.rf.c97f77e91adbe9e94c237a08656a43e4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 473,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [215, 79, 102, 140],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [247, 335, 216, 91],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [336, 212, 85, 30],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-42_jpg.rf.cb42488ab84b6104bde2fb07527e0616.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 474,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 227, 235, 229],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-129_jpg.rf.c8e2476186a7804bc3575e4fde2c28d2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 475,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 307, 394, 75],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-165_jpg.rf.c74ab872e369fb6a1bc952d9a129bfc5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 476,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [182, 195, 318, 306],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-77_jpg.rf.cbbd141cf9f28b0b92e859c08ddd0599.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 477,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [166, 202, 220, 179],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [26, 353, 459, 137],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-56_jpg.rf.cc520858fbc82b737020dce837a9f31b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 478,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [71, 271, 185, 78],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-85_jpg.rf.cba2f2bafa2a7c62257dcac17fcee89e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 479,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [364, 260, 47, 128],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [420, 288, 39, 86],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [110, 258, 67, 106],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [283, 312, 26, 59],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [331, 229, 40, 174],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-49_jpg.rf.cc2427b7bab05a640b066c1059c7746c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 480,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [155, 217, 249, 200],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [146, 277, 255, 137],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-155_jpg.rf.cc960db17a792a29a07306f32a129ad8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 481,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [365, 307, 81, 51],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [136, 258, 240, 170],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-139_jpg.rf.cc2ee35e558ab7162341a6df65131dbe.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 482,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [83, 79, 335, 167],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [62, 187, 217, 204],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [214, 32, 225, 72],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-90_jpg.rf.c4d712e9db382af37ab3fcadc249d2ba.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 483,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 230, 181, 175],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-197_jpg.rf.cce361f008ec38a2bfd8fd2853d4d882.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 484,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [147, 270, 130, 133],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-232_jpg.rf.cd3dfe569f2ba74bd2342488026a1c76.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 485,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [245, 220, 137, 75],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-18_jpg.rf.cd4d2066ec6ea740c4718b3ee7ab11ae.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 486,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [74, 155, 244, 55],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-45_jpg.rf.c6fbc03d15d23e89ae9f0763c15fffa4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 487,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [146, 221, 326, 211],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-183_jpg.rf.ce09f9956934b2b1e5e8292ed60351fc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 488,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [282, 360, 162, 86],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [195, 297, 70, 75],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-130_jpg.rf.ce128074690e5c06289bf9f5c9c422e1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 489,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 0, 500, 421],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-193_jpg.rf.cdc8428b6de7456f7a3f4c8580cc82b0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 490,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 103, 72, 289],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-145_jpg.rf.ce4ea67cf8b55417b2e6336b9a7f9692.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 491,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [200, 295, 289, 182],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-158_jpg.rf.ce9e280b1347b8e7aa4ffa576c207255.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 492,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [332, 292, 19, 127],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [360, 334, 28, 118],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [127, 293, 26, 116],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [289, 245, 29, 135],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [251, 260, 28, 126],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [390, 404, 16, 78],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-202_jpg.rf.ce4fd7c06cbabe877fccaee3805d354a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 493,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [187, 189, 80, 174],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-185_jpg.rf.ce05e2bc33f5764a7261820c5c42a9ce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 494,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [196, 230, 277, 186],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-157_jpg.rf.cef6523ec2a45bba86e1a54026f82053.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 495,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [167, 244, 62, 115],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-154_jpg.rf.cf3a07894734432f7626d83f0cf5eb73.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 496,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [115, 206, 288, 71],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-260_jpg.rf.ceccb835f123d10d2eb8a8e27a1c240a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 497,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [42, 171, 245, 164],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-143_jpg.rf.cf0be0b9bd37b1a1de7647c0903779c6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 498,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [110, 90, 389, 410],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-102_jpg.rf.cf700aa50c04a0b79a57e28c52fd0be2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 499,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [279, 142, 206, 347],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-40_jpg.rf.cf7815c623be2426eda463f592853fc9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 500,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [55, 254, 445, 245],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-22_jpg.rf.cfd42059d4c5fed5f7bfd108b8d993f5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 501,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [9, 333, 129, 64],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [142, 350, 102, 97],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [144, 196, 38, 37],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [260, 119, 51, 66],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-160_jpg.rf.cfcef2f7aef7c0d600dbf1b936316ada.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 502,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [120, 55, 333, 122],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-42_jpg.rf.d052805a293acfc1868e46f8ddf594a6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 503,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [295, 166, 196, 223],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-175_jpg.rf.d18fff08e1d784e9b89f9dbf37cdf3b9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 504,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 270, 147, 45],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [224, 234, 118, 50],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-99_jpg.rf.d06613b5984b787325c0cda84a24d561.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 505,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [82, 274, 235, 63],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [201, 277, 182, 99],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-20_jpg.rf.d1015d4563d285c2d33d06bbab48165f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 506,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [114, 86, 94, 283],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [404, 263, 27, 65],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-9_jpg.rf.d1ad463299d109a8c9c8900f88d0a5c2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 507,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [36, 60, 249, 152],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-76_jpg.rf.d1dcad9659f616113f214332d3bd7956.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 508,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [254, 142, 195, 156],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-96_jpg.rf.d2dd489923473777a524d4fbf5518b77.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 509,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 201, 102, 102],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [44, 280, 98, 128],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-19_jpg.rf.d15ceb8b0f800b1933e83cdb7dc9e78f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 510,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [184, 64, 39, 122],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-22_jpg.rf.d2b1e6883bad5d6f1fba3732035d44dc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 511,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 207, 54, 30],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [129, 205, 148, 51],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-172_jpg.rf.d2e75490d64efe3ef856029b266b1f6a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 512,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [306, 240, 174, 100],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-150_jpg.rf.d4021bd9e2a0ede5fd99e8c45b4bd2de.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 513,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [227, 60, 99, 438],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [334, 247, 58, 175],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-295_jpg.rf.d3018adfb30dc2d698dd246486888d0d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 514,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 141, 499, 337],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-82_jpg.rf.cfed98ad50488d98c0a78ca6719bb32f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 515,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [132, 286, 267, 168],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-2_jpg.rf.d3faa3574f5a7bcde7675dd87c27dc7e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 516,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [6, 221, 423, 181],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-112_jpg.rf.d5178462b1c480a1c7f5c7fa561c2f0d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 517,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [162, 186, 85, 65],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-109_jpg.rf.d5479974edd303ec8c9f4068d19e0bb9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 518,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [317, 96, 38, 34],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [247, 141, 68, 131],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-85_jpg.rf.d3d02ea1c279967b746189e276a1dc37.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 519,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [98, 324, 262, 167],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-199_jpg.rf.d490dcadfebee327b93ee263426b3c35.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 520,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [151, 279, 49, 85],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [95, 309, 96, 124],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-89_jpg.rf.d55f504ae492ed963427170dc1d3016f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 521,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [95, 131, 72, 84],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-77_jpg.rf.d4e4dd2eb6b7921fb15e297fc4acf133.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 522,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [38, 142, 377, 267],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-102_jpg.rf.d5fcf0dea8b52799cf79a38fa5f812bc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 523,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [116, 136, 91, 66],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [170, 160, 328, 280],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-194_jpg.rf.d5a97e7121d2b3c9ae9cb8390d5a6fe8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 524,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [114, 220, 51, 26],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [233, 174, 54, 48],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires2-108_jpg.rf.d5a1ad74562abb92dd6f9394f658f860.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 525,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [100, 106, 168, 180],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-34_jpg.rf.d5f20e8b383e59032610df6449aa03d1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 526,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [273, 63, 86, 380],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-224_jpg.rf.d6322880538632d93a201c2b4c425b63.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 527,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [13, 206, 381, 246],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 95, 156, 167],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-146_jpg.rf.d64fcb8809f4b577395b95a2d747c260.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 528,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [300, 303, 186, 85],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-261_jpg.rf.d2e2b3b67987ac772ea20f9db17d579e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 529,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [76, 320, 222, 125],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-39_jpg.rf.d59732f3c468be9c389a4ca20e9ce404.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 530,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [143, 139, 183, 124],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-9_jpg.rf.d6b75fd481eb0d7da6e91570956b261d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 531,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [195, 156, 197, 193],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-282_jpg.rf.d77621990e961ff6fb4427eaa5cab766.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 532,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 295, 174, 104],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-61_jpg.rf.d671efa84f8f70c2c2e5594c30b9fb0b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 533,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 257, 500, 177],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-160_jpg.rf.d6e243bc4972a0ce0ba8deed25aa234e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 534,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [239, 163, 62, 333],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-12_jpg.rf.d6db725f9b9cb3be0c2deeddd45845fe.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 535,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [84, 236, 147, 90],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [16, 167, 140, 71],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-170_jpg.rf.d843fbc961df223fbd0dea8ab7febecf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 536,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [183, 125, 317, 375],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-107_jpg.rf.d77afcb3fa871055712965ea96126795.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 537,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [156, 153, 96, 50],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-104_jpg.rf.d7e8f484540d0423a430113a4e043735.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 538,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 255, 499, 197],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-269_jpg.rf.d4917bc2c295e2eded10c4582d7da1e4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 539,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 109, 246, 141],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-44_jpg.rf.d86689cb649ea4f14fcf5b5619c357ec.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 540,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [35, 271, 465, 218],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-219_jpg.rf.d89a1454848dd1a71c3a0ef47ec77f8c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 541,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [413, 378, 87, 104],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [143, 285, 303, 93],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-126_jpg.rf.d8f494da768ef1d2ea485dd8fefdba97.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 542,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [59, 209, 441, 147],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-168_jpg.rf.d88efe1d1f28b400f79adc1246c5c9d4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 543,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [64, 142, 386, 136],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-2_jpg.rf.d9999fd368c18f2144d1b0e41fe0a590.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 544,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [86, 149, 82, 144],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-11_jpg.rf.d8bc43e022b1bd8c2ede2663fd965099.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 545,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [138, 171, 151, 191],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-164_jpg.rf.d922ca707e6c012ad3ae64bde17f95e9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 546,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [209, 264, 262, 136],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-192_jpg.rf.dab698920071fb30f62beac74ad54621.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 547,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [139, 95, 164, 307],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-135_jpg.rf.dbe7a279d33d28243cd4a7b41518195d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 548,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [26, 258, 103, 109],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-297_jpg.rf.da9c897709a55617dc35128dbf8cdfd8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 549,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [84, 221, 207, 150],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-141_jpg.rf.dae8a72aa2cbc22be106dfa2814ca18c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 550,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [202, 348, 147, 70],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-176_jpg.rf.db77c3c9cb43c031e905d34674fcff55.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 551,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 328, 498, 172],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-149_jpg.rf.dc3f5d456a33c03c74308a168311257c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 552,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 269, 500, 230],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-7_jpg.rf.da71cb842e3bc94d2b4576a8141029bc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 553,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [358, 260, 107, 94],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 331, 278, 166],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-54_jpg.rf.dbbbdcb534647a046ae8553d1ccd0c50.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 554,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [184, 314, 187, 60],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-6_jpg.rf.dd4fce1eb3102c8110ccd00f7140d891.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 555,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [23, 71, 477, 208],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-108_jpg.rf.dd2efc746d9d3538abc9bce646baa04c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 556,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [173, 211, 218, 72],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [262, 45, 210, 172],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [168, 213, 126, 174],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-7_jpg.rf.dc78e33ba89cbb4f9e68222516e3ff55.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 557,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [201, 178, 127, 78],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-40_jpg.rf.dc7e204269525f86ed3f377a0b66c2a5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 558,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [55, 196, 424, 292],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-20_jpg.rf.dc673c284915d437bd189f578153f37e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 559,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [191, 279, 178, 72],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-34_jpg.rf.d931da4dfd7c715047e1498591582c58.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 560,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [138, 64, 362, 269],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-169_jpg.rf.dc8ad9f494ae3d8b70087843e1d1c168.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 561,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [41, 211, 347, 104],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-54_jpg.rf.dd43251f7e230f9ff4f2ed34eaa3c306.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 562,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 95, 302, 180],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-125_jpg.rf.dca348a672573a44ebfd4314c202facc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 563,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [270, 46, 206, 171],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [176, 183, 104, 131],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-119_jpg.rf.dd5d86d432475c11d6c360e4befbde96.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 564,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [131, 291, 126, 164],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [115, 451, 129, 49],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-76_jpg.rf.ddb3b7ffc96b11a4f61967780e9b0d1f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 565,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 218, 342, 282],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-36_jpg.rf.df9087aee517c8c1b127e8a9250f6562.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 566,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [26, 199, 261, 199],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-192_jpg.rf.df8e3d90fbd5c8fb0032f7d747d31c79.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 567,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [143, 265, 123, 100],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [100, 228, 48, 29],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-130_jpg.rf.df4904de7e7b2dc07af9298b3188fbb2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 568,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [19, 150, 446, 303],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-127_jpg.rf.dfc8b82dc12fa928fba0dc3055b0d7ff.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 569,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [47, 225, 96, 71],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-103_jpg.rf.e1c401b9f0638b054e8f8d1435f91bc7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 570,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [43, 230, 66, 53],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-48_jpg.rf.df869245248312a04e9cb9022efc06d0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 571,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [296, 8, 203, 199],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-110_jpg.rf.e0c154be3c5d0ba84d3517962d34f8ac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 572,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [331, 145, 133, 162],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [213, 197, 229, 111],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-58_jpg.rf.dfd5916a681e2078bf864c715b6d1eac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 573,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 257, 274, 135],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-1_jpg.rf.df1f2764ddef17a6992c8ea33d588b9c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 574,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [61, 72, 232, 148],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [245, 37, 155, 59],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-134_jpg.rf.e008e3ac628081faea21680a7831a273.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 575,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [298, 243, 44, 34],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-40_jpg.rf.e0689c38cda4e08b2ada57a0ede85770.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 576,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 288, 120, 88],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-69_jpg.rf.e1bfda9e8be307130f2550775eed1a2c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 577,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [3, 243, 486, 248],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-220_jpg.rf.e25699b8a1843c3353ea821180902a0e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 578,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [187, 275, 115, 63],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-33_jpg.rf.dd81db1400a0ab9f4bcfb073c995bfac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 579,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [202, 56, 65, 343],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-123_jpg.rf.e19754640a99ddfb8b902d4d00ba24fd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 580,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [310, 186, 189, 282],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-185_jpg.rf.e27369eaaa349bf07d2995e59f7ea8ea.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 581,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [190, 259, 181, 96],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-8_jpg.rf.e0e7a40424e1523120f7642d241aaa0f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 582,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [189, 27, 74, 328],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-112_jpg.rf.e35a23a641e2f2da32dd8fa10d08a452.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 583,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [240, 177, 73, 235],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [364, 236, 60, 156],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-95_jpg.rf.e392e9518a675f1f4c549f479d3c44a7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 584,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 108, 285, 158],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-53_jpg.rf.e2fdbc5250d53b6edb4debfb962e5b6c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 585,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [90, 358, 365, 140],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-58_jpg.rf.e345b6c9782a07dafa72f574f73b8d56.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 586,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [82, 332, 162, 166],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [233, 324, 143, 135],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 75, 476, 361],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-41_jpg.rf.e3a69c82be46b556fdb1d946d1cb8f00.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 587,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [18, 116, 246, 127],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-28_jpg.rf.e40fb0b1cfe61eed4af2554283312c11.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 588,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [303, 191, 175, 183],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-76_jpg.rf.e42440b2e319ab3880d03f03a4a2c0c9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 589,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [319, 162, 75, 211],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [421, 166, 52, 218],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-147_jpg.rf.e40e903b9b2182b8549c47f5b20af100.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 590,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [136, 280, 341, 82],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-199_jpg.rf.e486ecc79ff3f968383a25655873e537.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 591,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [342, 1, 64, 112],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [205, 93, 61, 407],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-45_jpg.rf.e4a896dfdacf1a26b7aeba39696f752f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 592,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [12, 295, 311, 172],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-207_jpg.rf.e1fe873b2ba415ae1c7f97766e4304b3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 593,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [311, 266, 146, 81],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-217_jpg.rf.e55a470c004bd2481ae675c548d733e9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 594,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [318, 334, 141, 80],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-115_jpg.rf.e5578b4e426bfe6bec7dc83bac76ad05.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 595,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [8, 226, 72, 101],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [76, 229, 214, 226],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-211_jpg.rf.e6d719e77818b811e72e529f3e2b4467.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 596,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [32, 339, 168, 49],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-251_jpg.rf.e4e9c8ceec09f4a8bded5729669ec4db.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 597,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [234, 115, 226, 172],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-88_jpg.rf.e6fa2b5ae41c736117ed2c536f7baeaf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 598,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [319, 228, 106, 167],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-123_jpg.rf.e70051c459d1fe203965272b0131819f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 599,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [324, 197, 22, 34],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [278, 237, 39, 63],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [173, 211, 116, 183],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-13_jpg.rf.e6642d2174b3cb7eb01ea7e6966b68d7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 600,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [205, 131, 225, 165],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-98_jpg.rf.e68b7de84bf8e4344ac0052a527625d8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 601,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [42, 329, 166, 82],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-30_jpg.rf.e5b16f02ddb0081e12dc98edc6ffbb80.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 602,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [5, 269, 233, 98],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-106_jpg.rf.e76b5f88483c141eddb2f398ef57f631.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 603,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [241, 243, 45, 225],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-31_jpg.rf.e744e773dbc23de0015089a001298407.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 604,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [170, 116, 70, 296],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-21_jpg.rf.e711c7c89cef69bb098b084a04d4dfbe.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 605,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [69, 262, 217, 99],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-115_jpg.rf.ea30b3102823520da7b83c5883f8f8e9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 606,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [252, 215, 37, 101],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [303, 210, 34, 141],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [369, 316, 28, 83],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-233_jpg.rf.e88d38e2cc2f5d9a40b6ce77dcd88d9c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 607,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 455, 116, 45],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 358, 308, 40],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-68_jpg.rf.e8de98cf5b549b11f0225334bc3f2992.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 608,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [54, 156, 178, 182],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-182_jpg.rf.e8b2ac9ec49004893dbd8a60ccc8641e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 609,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [110, 45, 338, 151],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-50_jpg.rf.ea4e66ac19c0dd3fefd66862eec7e852.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 610,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [122, 51, 314, 185],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-1_jpg.rf.e7d39e0c4a6737731e305575a95e08bd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 611,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [30, 103, 361, 131],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-71_jpg.rf.ea9967db291955b7eac05f45ca20dd75.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 612,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [251, 245, 26, 140],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [319, 224, 26, 146],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [366, 245, 26, 136],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [286, 272, 21, 106],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-52_jpg.rf.eaa2760cb47aaeafc7224a27b7449eef.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 613,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [315, 258, 172, 234],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-77_jpg.rf.e61b08c3bf56b4178e395055830e3d52.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 614,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [251, 228, 61, 147],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-34_jpg.rf.e7b312d324efaaca439997dbaf55c9eb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 615,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [293, 279, 196, 146],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-81_jpg.rf.e227f2e9272db463518bd8c210f6dd50.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 616,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [24, 226, 381, 214],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-28_jpg.rf.3f2d9385226892edd2f7727985a3610c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 617,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [137, 275, 206, 127],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-124_jpg.rf.3ef5f4cea08972bd75aa6988a1a1643b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 618,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [230, 328, 185, 151],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [86, 302, 143, 151],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-172_jpg.rf.3fdcf115af256f5fd84271d09d235a0d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 619,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [269, 364, 143, 136],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-72_jpg.rf.3fe3ef46dcc335289aa24a7c3b5aca6a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 620,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [180, 177, 98, 44],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-90_jpg.rf.40f9826582ecf2629ee7423980f12c5e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 621,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [32, 162, 263, 50],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-96_jpg.rf.412856ba5ce86e284ef46dd4406cbbb2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 622,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [84, 291, 133, 107],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-164_jpg.rf.42190f690dea8ddfe10da5b1e1074eb6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 623,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [213, 344, 158, 119],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [173, 254, 88, 64],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-191_jpg.rf.42ec0c0582903ae96f2d9c6dce36c549.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 624,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [188, 148, 178, 45],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-1_jpg.rf.4029f4dcc75405e47d2e65fb6b2310da.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 625,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [136, 145, 247, 212],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-174_jpg.rf.3fe8c576ef339c8f0104f5bbccdc3fa2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 626,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [87, 187, 247, 172],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-71_jpg.rf.3fdab56016a5c5ce66bed749d2f2a5ad.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 627,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 175, 425, 283],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-178_jpg.rf.40b822cfc516645aa8ad3afc0b8ef9b3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 628,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [21, 222, 265, 249],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [202, 276, 165, 120],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-72_jpg.rf.40f2cc2c46878fe7bc9ce62c4a184829.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 629,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [368, 256, 99, 162],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [245, 324, 220, 90],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 378, 235, 111],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-86_jpg.rf.435ae5fd465e02d818cfe09f0aa671c1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 630,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [275, 362, 167, 105],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-155_jpg.rf.4391dd0fdbb77b1c233c1bde410df8a1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 631,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [253, 265, 81, 39],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [364, 265, 88, 35],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [250, 398, 250, 102],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [115, 364, 92, 59],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-173_jpg.rf.40f5b74c0c9d5e0fda7978ba9cd04961.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 632,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 331, 500, 149],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-26_jpg.rf.4365477c9d20c190a7a6c50cdc5a383f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 633,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [41, 239, 113, 51],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-55_jpg.rf.421fb0c92fdd2684d8d6930c088e7d65.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 634,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [413, 297, 49, 118],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [48, 128, 39, 125],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [202, 231, 33, 61],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [148, 160, 44, 118],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-52_jpg.rf.42c759950e278ed6bdb618e8df7c7d3e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 635,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [212, 201, 108, 89],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-15_jpg.rf.3f5a93ee3152e5fbfbc4352ed7a09b7e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 636,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [140, 38, 105, 292],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-43_jpg.rf.43b9fed5742315a0788778d7dcdb4d0c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 637,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [13, 30, 209, 241],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-118_jpg.rf.431c28ef580c3b70804f6e7cfaaf3fd5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 638,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [296, 117, 56, 101],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-34_jpg.rf.43f3ec2b4ff20ba1d8f80195cbb9b7ce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 639,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [366, 80, 131, 41],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [181, 337, 120, 70],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-178_jpg.rf.43c1654e3dbf5fc1232e50c2ebc02a66.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 640,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [6, 251, 305, 122],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-47_jpg.rf.404178320b34a340781df4ef4744e574.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 641,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [11, 101, 423, 140],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-118_jpg.rf.440d9c8fa215f9cd7ae3e028c055dace.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 642,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [116, 279, 151, 86],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-14_jpg.rf.447cf45b96c3ebff906290b6b8514ba3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 643,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [328, 110, 172, 95],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [452, 107, 48, 47],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [418, 83, 82, 38],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-69_jpg.rf.45467aa71043eaff0e657471d6f0ece6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 644,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [137, 317, 203, 84],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-157_jpg.rf.450db00f0aba1572816383c330ab26bc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 645,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [70, 116, 343, 230],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-38_jpg.rf.4557e393dec2586182a59e2a2b3e2e71.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 646,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [171, 115, 184, 295],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-181_jpg.rf.457e6e66b6a4ec9016d7c35632cecf68.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 647,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [211, 207, 59, 230],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-77_jpg.rf.451c20b8620eb3dbe1e6608eaf5b099f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 648,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [59, 233, 89, 68],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [266, 48, 124, 195],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-179_jpg.rf.4575cfb3ff839734d9693da42d8a8b1b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 649,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [158, 153, 342, 151],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-271_jpg.rf.45d6fe6c2ba8b443c7f2efe1466c3dc6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 650,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [158, 231, 342, 269],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [36, 175, 245, 93],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [74, 202, 207, 126],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-4_jpg.rf.45cbaa6297e155d4310d341727250edd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 651,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [201, 9, 149, 276],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-66_jpg.rf.44f6e5b1af9e2a061452bd91b90acbcf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 652,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 274, 279, 83],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [215, 213, 204, 148],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-123_jpg.rf.4632e3a1b20e32dec06fadf67fab4832.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 653,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [56, 147, 121, 66],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-6_jpg.rf.44b081dc73cb59366af14a8c24852853.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 654,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [161, 139, 264, 178],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-42_jpg.rf.4667572c3af5ed489d2665f4bf367236.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 655,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [129, 131, 163, 63],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-93_jpg.rf.4666b3dbcc1d924fc157506f8be1a909.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 656,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [226, 221, 53, 167],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [193, 160, 40, 185],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-70_jpg.rf.46392c5e7435ffa97d5549d5b50cbdcf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 657,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [59, 314, 248, 31],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [195, 252, 177, 98],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-186_jpg.rf.46acc08160b616f0c5426253e04e6ffd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 658,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [312, 222, 127, 69],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [405, 203, 94, 58],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-123_jpg.rf.46b878b45e1570d8a04cebfd8c21bac4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 659,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [194, 249, 44, 134],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [416, 286, 26, 126],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [145, 292, 35, 100],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [124, 322, 18, 91],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-6_jpg.rf.47d29bebdfe0d235f1d5ea5d8e3b336b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 660,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [48, 270, 86, 69],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-80_jpg.rf.47d39cb09e170456f201b8278d20c41a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 661,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [86, 337, 145, 85],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-87_jpg.rf.4857f20db0b418bea42815a1e403e672.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 662,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [87, 156, 99, 262],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-4_jpg.rf.46efcad035e2e26d56f74068379f6dc7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 663,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [256, 249, 244, 250],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [97, 243, 151, 79],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [19, 215, 139, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-143_jpg.rf.46a208faff2dd40b929502b0e04574fc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 664,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [57, 292, 175, 126],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-159_jpg.rf.488f515fb1158990336879bb571d2ec9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 665,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [277, 91, 121, 178],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-18_jpg.rf.48bd2b41b05422fa2424278a9d0bc925.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 666,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [153, 200, 182, 159],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [195, 279, 227, 83],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-46_jpg.rf.4873461e022a2176d60eeb9b75ab127f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 667,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 199, 329, 277],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-183_jpg.rf.48b5231b6b0c6358dd79defb8c7e6f78.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 668,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [154, 196, 119, 120],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-155_jpg.rf.48fe45472d6362d2b412c808b5a25512.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 669,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [18, 60, 192, 123],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-164_jpg.rf.495a4fcbec95eabdadd5964835f1a0fc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 670,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [94, 292, 406, 114],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-11_jpg.rf.49f8d59f4b4ff82e4665c62cc9b27132.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 671,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [263, 121, 66, 78],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-147_jpg.rf.4a620088083e05df044ec528f9973a2c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 672,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [197, 279, 102, 172],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-115_jpg.rf.495cd7cd078e1d4d7f52326caf80155b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 673,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [247, 156, 99, 59],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-67_jpg.rf.4800d089c6ffe3c44fe531f18c3d4d9c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 674,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [12, 331, 482, 143],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-117_jpg.rf.4b064cd8c0ed565d036e0b6cf4b467d5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 675,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [79, 352, 159, 147],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [79, 405, 421, 95],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-287_jpg.rf.4abe9b1aa56c7cc4114672736f218cea.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 676,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 268, 202, 100],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [406, 261, 94, 59],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-143_jpg.rf.4b8d48a3b69cc308eb1938b948656d86.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 677,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [118, 216, 85, 218],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-110_jpg.rf.4bac420f6f300a6e99dd507166f2462b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 678,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [104, 179, 72, 195],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [322, 282, 52, 98],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [374, 191, 55, 195],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-87_jpg.rf.49b243fa2195849306b21c83946c92cd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 679,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [258, 310, 240, 52],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-48_jpg.rf.4c4dca0ce48c5b4406ee11530dba96bd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 680,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [120, 255, 137, 115],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-37_jpg.rf.4cf33931f38aeb0a162719ba7f866eaf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 681,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [342, 217, 112, 112],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [92, 274, 309, 166],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-168_jpg.rf.4c9cad26d6a47ce7d77155509791b1aa.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 682,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 320, 500, 180],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-67_jpg.rf.4bf7c7713fc887b526b0bc26f861c306.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 683,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [220, 198, 154, 107],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-278_jpg.rf.4d4fdc296581b4cc36da3841ecc35575.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 684,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [64, 291, 271, 181],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-70_jpg.rf.4cc837231d3bd228617a31a2111bc895.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 685,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [331, 241, 157, 158],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [219, 277, 113, 121],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-105_jpg.rf.4d76bb8fd5725381cd38659d7839cd38.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 686,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [252, 152, 203, 116],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-245_jpg.rf.4d864ebf22eb3488d0adbc2719262122.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 687,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [249, 201, 231, 186],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-11_jpg.rf.4d638266b3171ecd16ada933799e28eb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 688,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [105, 219, 160, 98],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-5_jpg.rf.4d76e449fa8cbdac1b98c3c0dc8a3f5d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 689,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 363, 222, 85],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [376, 163, 124, 41],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 251, 180, 200],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-234_jpg.rf.4d1947a5a7b479016e32ff6ff3b592a8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 690,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [93, 304, 402, 86],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 414, 500, 86],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 342, 118, 90],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-5_jpg.rf.4db9be375cf43ebb729425f545d723cc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 691,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [354, 123, 58, 56],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-72_jpg.rf.4dfdf6fd4e5e9509713159c087d98944.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 692,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [238, 285, 262, 103],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 310, 256, 113],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-27_jpg.rf.4db602cb8f8e8c38e7cb34dc4e09d643.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 693,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [160, 149, 205, 252],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-147_jpg.rf.4cc2008d302b545cd24f038c15ccdd2e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 694,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [159, 236, 40, 109],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-116_jpg.rf.4e820d59ccf0b8f639414491e898c12d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 695,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [13, 265, 365, 183],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [28, 146, 461, 166],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-60_jpg.rf.4f075b602771781b2937f213eff1bcf6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 696,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [221, 188, 54, 98],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [264, 68, 236, 214],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-149_jpg.rf.4f364650fdb98fc85107732178167256.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 697,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [166, 277, 334, 127],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-119_jpg.rf.4e98dc6440297beb960a7a8cd75a409e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 698,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [119, 206, 273, 196],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-156_jpg.rf.4f51ef709b27b199c43080863668c14a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 699,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [190, 116, 74, 270],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-128_jpg.rf.4f5d16c5cf67a259ede9bde8b52f33b0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 700,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [113, 188, 211, 142],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [318, 180, 82, 50],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-26_jpg.rf.510bb14d56f9353bcc4af21fb79877a4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 701,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [33, 400, 70, 70],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-94_jpg.rf.4faaf9602503b020068eecd4911b0dc6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 702,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [190, 250, 136, 104],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [98, 185, 75, 69],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-89_jpg.rf.512ba148f56b691a97cd300e128e67ea.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 703,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [79, 265, 240, 140],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-61_jpg.rf.522af0a9a3014938472f9d08066de404.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 704,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [181, 292, 273, 112],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [45, 267, 97, 99],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-155_jpg.rf.508bc22169512aeed80ddec4df8286f8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 705,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [63, 231, 191, 235],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-238_jpg.rf.532d7572f86c0205b615f6a7aba47c36.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 706,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [310, 171, 125, 111],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-208_jpg.rf.52a1acd18ea2ce1861acfe441d867461.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 707,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 250, 406, 140],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [346, 265, 154, 75],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-15_jpg.rf.52e9af2a9779501dfa6bebbf3bde6629.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 708,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [239, 272, 161, 71],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-180_jpg.rf.53a76c6cdb121c5c35c853bffa7adc38.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 709,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [134, 128, 113, 94],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [241, 215, 125, 146],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [365, 193, 135, 217],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [73, 102, 95, 56],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-53_jpg.rf.544962f3c8d59ed637763cdc850a0f16.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 710,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [180, 208, 37, 202],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-35_jpg.rf.54b048e99896cdbf572554a70c71720c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 711,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [16, 289, 455, 211],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-206_jpg.rf.56069e2ad3abb83d80f49b29d78d989e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 712,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [23, 305, 84, 37],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [104, 281, 94, 68],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-129_jpg.rf.570bf4a2b0e48bda6c1eadf57f6614ae.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 713,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [117, 10, 285, 439],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-29_jpg.rf.5544f4153678d14fe2edcf3cff6ca0f3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 714,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [10, 259, 149, 61],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-105_jpg.rf.561a9c41b5853e72626ebc8d8c616c4b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 715,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [116, 236, 80, 50],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-180_jpg.rf.55489834404c606f325d4ed7bbae8817.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 716,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [61, 185, 135, 314],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-165_jpg.rf.56920dd3965e900914545b0ceb7061db.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 717,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [51, 173, 395, 276],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-46_jpg.rf.57a73567279a88e0c90277f5a36909ed.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 718,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 118, 229, 197],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-61_jpg.rf.5790edb21a54fe0d6f8695a3dc7dae7c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 719,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 288, 328, 196],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-57_jpg.rf.5419324cc605f8aaecbecef84fe7b969.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 720,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 265, 386, 235],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-142_jpg.rf.586fab0bbda018fbb5f7a03857a71e7e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 721,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [183, 176, 100, 306],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-217_jpg.rf.583e77ddba1a7fe06c05f0b15aadaa32.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 722,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [183, 144, 318, 147],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [83, 290, 294, 132],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-10_jpg.rf.57d1d3a7c1f12a19e3b89082679e4e7e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 723,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [118, 13, 157, 372],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-172_jpg.rf.57d8d38fdd8ff3f13e4d812bf8607a45.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 724,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 172, 37, 107],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [351, 248, 46, 98],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [317, 220, 32, 104],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [276, 192, 32, 106],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [96, 170, 23, 99],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-23_jpg.rf.583032b6fa5e68c13d7526fce2028c2b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 725,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [5, 108, 407, 288],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-53_jpg.rf.587cef6121982017581cc46e7263aee9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 726,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 0, 163, 250],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [106, 56, 295, 208],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [171, 313, 120, 60],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [262, 56, 238, 212],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-106_jpg.rf.58c756d1b8fa34b2a4715b0a081b14d0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 727,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [259, 262, 135, 123],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [357, 222, 132, 103],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-189_jpg.rf.58e7695ab1ac9dcb67c3f8cf8c3f8550.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 728,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [90, 106, 121, 245],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-112_jpg.rf.592236daac71dd466b257e1f73100577.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 729,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [187, 55, 88, 73],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-160_jpg.rf.58facffd344a32110fb7b103a07bc4db.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 730,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [320, 319, 16, 80],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [275, 326, 20, 92],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [121, 161, 127, 85],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-118_jpg.rf.594c8e16c32e51fd29c9b116545e6898.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 731,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [250, 165, 55, 228],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-30_jpg.rf.58c8d8d87662961de2449ee10678d3b9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 732,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [100, 6, 398, 494],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-211_jpg.rf.593646e964001249ab4bc6a1268ee336.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 733,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [177, 247, 99, 63],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [78, 240, 102, 37],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [173, 313, 254, 127],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-69_jpg.rf.5950f024d3b5be53b639c7c932383d99.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 734,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [27, 174, 262, 184],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-9_jpg.rf.5a958146a575d8b08bf29699757a85d5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 735,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [29, 244, 465, 193],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [228, 2, 139, 275],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [108, 152, 123, 120],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-101_jpg.rf.5a62b59fd2e178a4b703073a50605a80.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 736,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [182, 331, 200, 60],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [199, 0, 37, 75],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-177_jpg.rf.5ac55742d21a0290fed41d93ee6010ec.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 737,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [249, 253, 177, 114],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-127_jpg.rf.5b0bcdb461156f506a665bc329db0857.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 738,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [80, 283, 227, 187],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-92_jpg.rf.5b1dd00d4032c36818ef97ace5f60b4f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 739,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [168, 185, 145, 55],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-276_jpg.rf.5b9b7b3063a3bccf2e408ab2b4596233.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 740,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [344, 226, 154, 55],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [331, 264, 93, 42],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [89, 239, 232, 80],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-289_jpg.rf.5b2a09d17f8d223ba03751a44808da33.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 741,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [60, 274, 375, 213],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [94, 241, 375, 100],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-122_jpg.rf.5c50c4534f1bbe285c5c1a16ffba4fc1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 742,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [155, 197, 236, 78],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [7, 195, 117, 57],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [133, 135, 255, 101],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [31, 233, 154, 55],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 230, 53, 65],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-68_jpg.rf.5bb563e97a9cab8154e62adf3f0dd707.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 743,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [94, 116, 48, 230],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-39_jpg.rf.5c65ff81da087bed6b128ab72430d004.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 744,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [256, 319, 153, 101],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-157_jpg.rf.5c67ab1811f5a3c3db1865b906360506.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 745,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [291, 200, 192, 133],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [27, 260, 155, 56],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-131_jpg.rf.5ca1e4e89569ae270d2318521fbb44f4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 746,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [286, 167, 76, 41],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-174_jpg.rf.5c95b1cf7339e32cfcaa961cf2bc75d9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 747,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [175, 269, 324, 177],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-145_jpg.rf.5cf102d0c5d04787833ca3f109cda193.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 748,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [217, 237, 144, 41],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-129_jpg.rf.5cd1cd74679a3634fa58247bc4bb0bf8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 749,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [209, 258, 84, 105],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-29_jpg.rf.5ccb5e685340ab0c1f6d85aaf2c9418f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 750,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [62, 314, 172, 168],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-110_jpg.rf.5d2a00cfd5ce7644a76e2f9aedbc05f1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 751,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [310, 155, 37, 44],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-236_jpg.rf.5ca413a12addfb91251ed0b18edbb50d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 752,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 115, 420, 286],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-87_jpg.rf.5e562026477982dd4681e0b1bd932916.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 753,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [232, 176, 78, 75],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-5_jpg.rf.5df11913cb7f86b6b991b6c59ea832b8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 754,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [339, 318, 161, 182],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [92, 243, 42, 37],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [87, 213, 31, 42],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [194, 259, 181, 227],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-93_jpg.rf.5d543979f3c516fdf7d49569461c9641.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 755,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [222, 144, 174, 242],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [48, 327, 175, 169],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-143_jpg.rf.5ecf0bf9c09531b455f2e02823880eb3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 756,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [374, 244, 126, 141],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-78_jpg.rf.5ecdc9a6cf8365e1610b54c5abcc2ffa.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 757,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [269, 265, 40, 31],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [37, 329, 190, 157],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-139_jpg.rf.5f3444837ac28e43def9000ac197852f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 758,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [6, 172, 394, 175],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-162_jpg.rf.59da1a3a91c1e74d85e4ff717683e0b3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 759,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [228, 225, 46, 29],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [290, 181, 139, 240],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [240, 235, 68, 69],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [266, 202, 37, 44],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires2-77_jpg.rf.5ffd13d5881609dc04a13e193176a087.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 760,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 203, 125, 78],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [272, 100, 221, 233],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-226_jpg.rf.60840b0af42f79dbf24ceb90e3ee375d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 761,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [341, 269, 115, 63],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-272_jpg.rf.5faa279ad462da123278def06492babe.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 762,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [33, 84, 349, 317],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-99_jpg.rf.600841ccb4f05b0dcd75ceb99b7a20fd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 763,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [234, 303, 266, 127],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [47, 248, 294, 187],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-187_jpg.rf.5bd4ad80eb7998c82d7a50edc7609544.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 764,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [4, 220, 203, 147],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-150_jpg.rf.60d6f16399a02f92bed364db6bbca907.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 765,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [76, 94, 143, 300],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-99_jpg.rf.60bd1a0487043e641369d10b751dc916.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 766,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 140, 496, 360],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-86_jpg.rf.618ac925cbdf988d85bf0ac93f901a00.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 767,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [273, 295, 15, 44],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [301, 305, 12, 44],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [109, 218, 19, 62],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [99, 252, 14, 28],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [142, 229, 22, 58],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [184, 244, 15, 56],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [229, 278, 29, 55],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [331, 315, 17, 43],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [361, 327, 23, 46],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [389, 221, 59, 168],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-105_jpg.rf.62bbc8c1faba5ad2c75f6d1c239ddd71.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 768,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [74, 425, 63, 40],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [117, 188, 29, 23],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [91, 229, 65, 42],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [144, 375, 130, 91],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-42_jpg.rf.6336a60d0287b7e1d824daf55d808404.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 769,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [117, 260, 59, 158],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [47, 182, 64, 247],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-273_jpg.rf.616406be4ea1f28af3d91ffabfa224b4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 770,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [41, 204, 391, 220],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [227, 52, 40, 24],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-128_jpg.rf.6182a426b1ba3c7ce158aba96a636911.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 771,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [139, 179, 169, 87],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-194_jpg.rf.5deaa291ea3cc3c1ebc299b51f056396.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 772,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [129, 334, 148, 112],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [235, 272, 108, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-50_jpg.rf.63a197ff9b957125dbaa21700afc6e92.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 773,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 188, 33, 82],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [282, 206, 104, 131],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [238, 189, 89, 56],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [19, 179, 45, 67],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-237_jpg.rf.63aa2df7082065e5d18fd76d7a88e963.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 774,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [6, 161, 190, 82],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-59_jpg.rf.6464908632311dc47b3f77b0f7225694.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 775,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [186, 103, 310, 136],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-174_jpg.rf.650faec97bd7be0cbca25f75b523056f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 776,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [212, 278, 184, 121],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-171_jpg.rf.64a8d8cce7ff8d6a66d3166af903e649.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 777,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [312, 353, 99, 73],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [165, 272, 169, 125],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [127, 242, 84, 62],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-232_jpg.rf.65271306d83d9038c0a81910f4ef2881.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 778,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [20, 181, 174, 86],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-137_jpg.rf.64eeb960cc49964f64fb5d25736201fb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 779,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [179, 168, 111, 120],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-42_jpg.rf.63eff4570fe4c3f40c2a4de88c0fc5a3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 780,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [8, 233, 222, 163],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-38_jpg.rf.65701180a798bba394c4c23e19c7907f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 781,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [60, 300, 188, 126],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [236, 212, 165, 115],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-95_jpg.rf.65a009b316e6d146131caa1af8f6a5b2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 782,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [216, 119, 247, 327],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-185_jpg.rf.668e1f1134f421c6c4bfa41e664d2e42.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 783,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [179, 289, 126, 132],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [49, 378, 168, 83],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-60_jpg.rf.65e54077f8127ee80f0fe4448bde1650.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 784,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [101, 188, 133, 153],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-73_jpg.rf.6664806802dffca0fdbcefa540098197.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 785,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [82, 252, 233, 139],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-165_jpg.rf.6565c9338a0d2fcaf9ded622d19ab501.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 786,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [129, 359, 222, 77],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-96_jpg.rf.66d19b0ce45a599a9aac7c9bdc381539.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 787,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 258, 304, 113],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [304, 261, 161, 60],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-296_jpg.rf.66dcc8f77d2abe9206e619292cff3476.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 788,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [97, 243, 155, 42],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [366, 284, 134, 39],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-270_jpg.rf.693a13547e627c6fce65fde42dafc4bd.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 789,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [3, 178, 449, 123],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-9_jpg.rf.65f6741ebb2fb4f2fa904536d563b0e1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 790,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [185, 173, 315, 250],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-275_jpg.rf.68a080ea0a3ab7680891e16d43f4d42f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 791,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 147, 276, 132],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-74_jpg.rf.67b47e763105de2c2b07c694080ca300.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 792,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 309, 402, 175],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-133_jpg.rf.6a4d3bc5991fcc082db54e3871430066.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 793,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 239, 255, 257],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [132, 142, 191, 212],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-140_jpg.rf.6a220f38f02bec13eb39cba6fe1ae45e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 794,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [127, 190, 98, 151],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-51_jpg.rf.67e2671b6df42d7fa33f8c42d3653ded.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 795,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [191, 74, 214, 97],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [135, 175, 339, 127],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-162_jpg.rf.6ac2353a2c5f2081574adca74c2794ff.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 796,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [220, 110, 74, 303],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [288, 262, 25, 104],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-80_jpg.rf.6ab689b862a52d754bb9d824c0cc1043.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 797,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [62, 106, 342, 150],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-40_jpg.rf.6aa82a96c0621ea4e1a004f976654d80.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 798,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [63, 162, 199, 185],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-10_jpg.rf.6a5502928eb083f58a535c3a7610b06a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 799,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [201, 220, 185, 104],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-84_jpg.rf.6afdcde0b04bae1dbd84bc4bb4965dca.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 800,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [9, 103, 272, 288],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-21_jpg.rf.6ab11c812674467e8094652b1c7172cf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 801,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [43, 350, 211, 83],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [232, 354, 235, 110],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-61_jpg.rf.6b43884ac4d54a29845396817257d6cc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 802,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 333, 29, 61],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [101, 317, 17, 55],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [297, 358, 16, 44],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [366, 365, 15, 58],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [175, 304, 26, 67],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [310, 346, 19, 63],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [325, 363, 20, 51],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [394, 255, 34, 97],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [266, 352, 17, 52],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [115, 290, 19, 67],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [145, 297, 25, 65],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-78_jpg.rf.6b7dae5fb01243d5d6f2e94149f101c3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 803,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [41, 211, 434, 89],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-183_jpg.rf.6b67e54aaf8626ab1067d85b9e88431f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 804,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [26, 185, 300, 238],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [356, 178, 100, 53],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-127_jpg.rf.6af01291917dd50723d25f08ed2aee5f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 805,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [36, 142, 101, 268],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-62_jpg.rf.6bc0fcb71e394f0f664c1eeac1717de3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 806,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [9, 66, 206, 184],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-86_jpg.rf.6bd1f6410d3d57b7f06a29fa3033f23b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 807,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [213, 294, 84, 71],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-97_jpg.rf.6be9588cad4110618466902120259353.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 808,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [250, 254, 122, 94],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-68_jpg.rf.6c811cae2b69a1ecd5788a45989ffdef.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 809,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [221, 116, 235, 64],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-101_jpg.rf.6df4c7283e335d77bf875e4b42132591.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 810,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [217, 233, 40, 135],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-45_jpg.rf.6d24b3ca482cd015757488dc217d4a61.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 811,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [154, 187, 19, 31],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [74, 165, 23, 47],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [224, 125, 168, 210],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [78, 217, 241, 87],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [419, 150, 31, 68],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-114_jpg.rf.6c7934dd08c958abb0772d18bcd50e95.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 812,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 243, 292, 247],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [259, 235, 124, 38],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-73_jpg.rf.6e3121b4210bb2543f5294c0581ac8c7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 813,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 90, 500, 349],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-120_jpg.rf.6d1c1bbc6873eed853a70f7dc456c7e2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 814,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [169, 154, 49, 214],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-154_jpg.rf.6e820d752fb5071e01d09f0b6aea0134.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 815,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [224, 50, 169, 152],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-20_jpg.rf.6dcd984ab23d854ab27066ebba2551ec.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 816,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [71, 362, 198, 52],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-195_jpg.rf.6d27a7a15053d643587eced0f0bb7e7a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 817,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [38, 380, 91, 78],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-46_jpg.rf.6e7907af5ffdd81dc3a3fada708e7eab.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 818,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [350, 408, 25, 61],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [379, 431, 18, 41],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [304, 365, 37, 96],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-92_jpg.rf.6f7df7cb00841a7501ec2050f2d879a0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 819,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [52, 106, 391, 174],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-75_jpg.rf.6f134a07641f91db7ac37a7c50754ad0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 820,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 204, 27, 23],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [86, 216, 57, 49],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [99, 254, 151, 157],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-24_jpg.rf.6f1e45a5b420d5fc2d20d6ab510b7a09.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 821,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [88, 469, 28, 17],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [183, 55, 122, 443],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [436, 346, 40, 98],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [61, 469, 31, 21],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-302_jpg.rf.6f6a568fc0d2e6d2790a9c1e95c78d40.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 822,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [336, 210, 164, 96],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [91, 269, 341, 230],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [413, 152, 70, 78],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-165_jpg.rf.6f4077e8ba29030a5aecdef10b578b22.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 823,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [153, 249, 347, 132],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-24_jpg.rf.6f6f3434861cdff299beb806d0fe4710.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 824,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [137, 79, 245, 194],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-73_jpg.rf.6fffb3383ee25d970be9701d65b488d1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 825,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 135, 211, 56],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-57_jpg.rf.6ffb578c80c1222726144c919bbb6bac.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 826,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [256, 224, 232, 137],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-104_jpg.rf.6f42b1f138c5972caf2b50c78c1818e2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 827,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [217, 181, 72, 173],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-177_jpg.rf.704e2b06ed6f4934db08aaec8374e34d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 828,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [350, 293, 133, 92],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-19_jpg.rf.6f88e94386fae0c806d52e94803b1434.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 829,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 50, 172, 201],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [218, 173, 126, 63],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-134_jpg.rf.6fc2c19abd6faa758b89bf31c6b11031.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 830,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [246, 253, 169, 133],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [140, 217, 151, 110],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-203_jpg.rf.7006068b111c73d549851508976c0932.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 831,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [156, 259, 35, 148],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [191, 212, 38, 163],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [231, 274, 26, 100],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-30_jpg.rf.7031d9d819b9e7e8f292a17fa4d85015.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 832,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [43, 43, 255, 444],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks2-3_jpg.rf.7067a4d389deeb761b0a745308ea7ff1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 833,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [249, 197, 98, 182],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-126_jpg.rf.71ae979579fc53ea93adb82ad7f177ce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 834,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [94, 378, 164, 61],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [328, 225, 121, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [233, 314, 191, 58],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [148, 322, 51, 117],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-83_jpg.rf.708d1cb7b6dd0a70117edc98470d5afa.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 835,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [110, 207, 252, 200],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [22, 203, 95, 86],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-12_jpg.rf.70c771258cb21aa8007c40181c9082de.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 836,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [91, 53, 174, 185],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-183_jpg.rf.71cdc1d35e84279ac6b37b1c33c12fa0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 837,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [32, 72, 425, 296],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-58_jpg.rf.723c1b2e2c1e4f9e73f87dbb771feb0f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 838,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [185, 333, 260, 130],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-80_jpg.rf.71e6989947a650f293d2823317f0ca07.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 839,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [290, 200, 137, 298],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-134_jpg.rf.71e7fd63a0e5e21e7638ffedddeed330.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 840,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [164, 98, 58, 34],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [9, 236, 225, 173],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-69_jpg.rf.71e16f05dfbd1418ab820bf6168b9b7d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 841,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [301, 333, 22, 62],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [284, 322, 23, 80],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [336, 350, 13, 36],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [263, 360, 13, 28],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-67_jpg.rf.72544ba3dfc98671bf1ff5aba15f528d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 842,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [87, 171, 62, 185],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-21_jpg.rf.723911bc9d382ca56678d3f66935033d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 843,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 363, 197, 137],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [133, 245, 219, 185],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-109_jpg.rf.726b3bdaa7e65079fa1f3af896fb689a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 844,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 147, 260, 66],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [469, 104, 9, 36],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [99, 89, 166, 188],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-62_jpg.rf.727459b800f2e07c79dc67910ed21b3b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 845,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [56, 118, 125, 317],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-117_jpg.rf.741a58ca6883155ffb8e73746ff97e31.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 846,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [246, 292, 71, 54],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [291, 200, 167, 107],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-178_jpg.rf.73c555a46b78910dac735b2b4f12cd58.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 847,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [135, 239, 281, 116],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 202, 174, 124],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-99_jpg.rf.74dbb421a0197c9a5cbbd28b6b3dea52.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 848,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [126, 222, 134, 114],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [203, 288, 173, 119],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [372, 290, 125, 142],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-52_jpg.rf.7588b20231ba00840470c93a9388ad79.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 849,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [303, 119, 86, 365],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-167_jpg.rf.767612090259bf7dc1f14883e24f6360.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 850,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [155, 128, 76, 336],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-165_jpg.rf.7336df229a7b26d4263303477d51dd76.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 851,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [221, 256, 70, 208],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-107_jpg.rf.76baf54b94fd90456ddaf8e6c9f117c9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 852,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [65, 305, 76, 67],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [54, 279, 38, 44],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-78_jpg.rf.7703294dc8c09a612757253d1e319ed4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 853,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [270, 305, 18, 116],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [72, 273, 30, 127],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [193, 261, 29, 122],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [238, 254, 25, 131],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [316, 415, 13, 75],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [295, 344, 17, 122],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-14_jpg.rf.7691c4d03fd954a645ef80c4aea17ff0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 854,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [259, 156, 92, 60],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-227_jpg.rf.78351a838c23ecc9e8a911999d5e2934.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 855,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [54, 421, 138, 78],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [130, 318, 145, 115],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-116_jpg.rf.78a6860c4c3794d5dd365c4b99a7cfa6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 856,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [125, 191, 369, 267],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-22_jpg.rf.78ee5773252414657e8fc2269734492d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 857,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [65, 267, 435, 233],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-159_jpg.rf.78c9bf3e0ffa4250a93189d153c0f6bc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 858,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [238, 208, 243, 208],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-64_jpg.rf.7883040f404a9eeb6aab309425a52c4a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 859,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 233, 500, 187],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-80_jpg.rf.78e91b5c98011394fc193445f4120a88.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 860,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 235, 454, 258],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-120_jpg.rf.79a932f0bfa0ce0a3f12d29a07c1f3d6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 861,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [285, 287, 198, 128],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-135_jpg.rf.7a20a68f0cd69d4a2433a26e0e911db8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 862,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [63, 286, 318, 91],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [386, 219, 104, 154],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-239_jpg.rf.7a46729dba410797d17e578df8fcd707.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 863,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [51, 349, 146, 99],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 337, 109, 163],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [83, 116, 38, 50],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-128_jpg.rf.751c5962ef405624585622bdae654670.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 864,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [202, 326, 239, 49],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-148_jpg.rf.7a33fa5ac436e538ec833dcc4bbcccf0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 865,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [108, 223, 265, 190],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-57_jpg.rf.795b3d393dd49ddcc23c173db161ed13.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 866,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [272, 274, 144, 77],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [195, 209, 119, 96],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-182_jpg.rf.7afcf878a3a7a93b6a74bade9a3aa21b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 867,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [95, 111, 309, 84],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-82_jpg.rf.7affc3eb54dcb68657cf49a0419e324c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 868,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [75, 110, 425, 277],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-37_jpg.rf.7b050fc1e660f0497162b829eb836796.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 869,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [4, 353, 496, 138],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-151_jpg.rf.7b09cb7291b67793b998654b4e3fd6f9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 870,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [323, 47, 148, 171],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [11, 22, 306, 309],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-200_jpg.rf.7b1bd98e04970ae73f53951157e5cfb4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 871,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [349, 110, 101, 142],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-13_jpg.rf.7b26e8c307b205ed6a2bbfd58e1718da.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 872,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [40, 301, 148, 40],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-222_jpg.rf.7c35d9db98601da46b855f9ede2e8322.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 873,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [66, 222, 354, 192],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-66_jpg.rf.7b6dadb8d440f61c04749446081f1bc1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 874,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [16, 133, 249, 216],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-63_jpg.rf.7bf2c31268116696f013e476f56f02c2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 875,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [306, 68, 129, 108],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-74_jpg.rf.7c28452d0f309f4c2f827d4dcee925b4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 876,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 162, 420, 95],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-49_jpg.rf.7c045d78b485dfe7661797898a05bb92.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 877,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [166, 178, 26, 238],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-108_jpg.rf.7bb72bb4bd8e5fb849ddc6e49bf6c218.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 878,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [356, 176, 75, 297],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-18_jpg.rf.7c0d8b6b13ee946a4b54249b25ffbc32.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 879,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [182, 116, 132, 231],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [180, 51, 250, 175],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-60_jpg.rf.7c176f9f925e6e74b677db757ca26b9a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 880,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [259, 129, 65, 85],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [183, 314, 104, 134],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-47_jpg.rf.7c34b12e2d0ab0b040fc5c0febfc6ba8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 881,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [88, 18, 412, 244],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-209_jpg.rf.7cc76797ccf032f8f96b884ece55153b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 882,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [57, 405, 122, 69],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-175_jpg.rf.7de81b80f783f9345183c3b426c3def7.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 883,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [231, 135, 38, 195],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [265, 199, 50, 197],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-194_jpg.rf.7da4746a7a55382224aa6978c9cd2578.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 884,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [39, 161, 269, 233],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-288_jpg.rf.7f00cca5ca92225860c683f8d39d102d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 885,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [12, 246, 431, 128],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-4_jpg.rf.7edbdb99fc57854af804d770ca01eaf3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 886,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [281, 325, 166, 71],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-29_jpg.rf.7d2f7972f5149fd1920ba330de3e87f8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 887,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [260, 311, 145, 48],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [147, 311, 80, 31],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-7_jpg.rf.7eac78b414ff6b4d0cbff88227644970.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 888,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [124, 178, 218, 112],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-167_jpg.rf.7efc5774bbe3badf34467f0059795a87.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 889,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [113, 311, 262, 141],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-141_jpg.rf.7fede9d2974ec5a840b9d8a96838958f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 890,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [190, 184, 281, 161],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [37, 167, 155, 111],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-176_jpg.rf.7d4104ea10e2150b6ab133a291700cb3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 891,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [178, 162, 50, 126],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-59_jpg.rf.80615e4b303b3a2ff2b30cbdfe2e89a9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 892,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 322, 319, 178],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-22_jpg.rf.80694a758054966d59209cd30b93235c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 893,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [11, 76, 115, 116],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [221, 331, 130, 67],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [186, 0, 146, 180],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-203_jpg.rf.8149df946cdf31ae46c95676127adc42.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 894,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [9, 208, 266, 74],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-166_jpg.rf.813d1fff4abab118a50c15808cd744ce.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 895,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [177, 293, 251, 100],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [66, 59, 180, 50],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-188_jpg.rf.8003f8d2f83ac3fcea268264d5c7b719.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 896,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [57, 58, 112, 239],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-141_jpg.rf.808a4ab103d8efb4c2a0d86c13ebeffa.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 897,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [212, 242, 128, 46],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-85_jpg.rf.819212a221dad32ad5d62a39be614fb6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 898,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [332, 171, 168, 136],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-298_jpg.rf.82269590ae51c9bfd2eb5187e4e261a2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 899,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [242, 249, 256, 204],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-127_jpg.rf.80e38351f36c04781451e6705b74876b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 900,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [261, 135, 220, 222],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-32_jpg.rf.827af337fe06d5ad738c5d05882b7c85.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 901,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [151, 177, 337, 99],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-129_jpg.rf.8208faf0a5b34c3a854f89ec49a670e1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 902,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 337, 268, 163],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [271, 343, 229, 101],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [72, 321, 214, 133],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-139_jpg.rf.82b465e176df494a167abb21aac241b5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 903,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [176, 103, 216, 107],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [427, 115, 73, 54],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-231_jpg.rf.84826c04a36a7e7823be0fcdebb41f49.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 904,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [247, 199, 208, 121],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-102_jpg.rf.84983416a5558dc06866f7ff84d56120.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 905,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [258, 275, 88, 197],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [148, 276, 35, 104],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-267_jpg.rf.7ffe68c9fd765aa2beca48e45667dd4e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 906,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 279, 321, 195],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [281, 266, 219, 137],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-231_jpg.rf.84a34dd4a99e273c155ea281c62ba469.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 907,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [247, 240, 216, 125],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-187_jpg.rf.84c48eb59a7dcf351fee52abbb5c6a02.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 908,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [119, 155, 115, 184],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-305_jpg.rf.8213a2ac9cde8fd4c918d90effddd395.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 909,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [3, 307, 433, 114],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-38_jpg.rf.84c6b33331168b9d7a99abd7a5deac03.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 910,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [43, 306, 122, 161],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-122_jpg.rf.84ec6cf7c436a4b4365afab3678ac325.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 911,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [2, 232, 227, 260],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [182, 234, 282, 153],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-109_jpg.rf.84f04d996a66b75781323ba40d49f137.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 912,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [24, 115, 160, 115],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 226, 99, 154],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-120_jpg.rf.84ed7542ebbdae0dff322e60f3905d71.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 913,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [127, 215, 123, 125],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-161_jpg.rf.85df123b7cd2b38b12fd8e1dbe84e8a6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 914,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [98, 62, 81, 70],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-10_jpg.rf.869574f805778c8a78fe7eaccec9c447.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 915,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [301, 247, 161, 78],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-115_jpg.rf.85768de79757d14146dc5d4c7bfd23af.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 916,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [315, 379, 107, 57],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [218, 290, 283, 168],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [199, 262, 78, 47],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [423, 194, 76, 63],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-96_jpg.rf.86c455085ca23cc4b2ef61191056cee1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 917,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [45, 278, 428, 209],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-76_jpg.rf.86d164648b8597d72cd487445ad67da6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 918,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 266, 401, 234],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-119_jpg.rf.87776757d782cea45a9ba483b7186ba5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 919,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [77, 312, 163, 152],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [347, 268, 152, 96],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [248, 285, 103, 89],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-65_jpg.rf.8752a8cfffab2180ec0e3c898854db6d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 920,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [170, 260, 313, 240],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-133_jpg.rf.88254ad69e3b60b3617efb396ce1f0f5.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 921,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [378, 359, 72, 55],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [455, 381, 45, 41],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [184, 251, 92, 161],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 289, 158, 121],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-151_jpg.rf.8761a913d0f7a61c87a8a65f1d33920d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 922,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [141, 265, 130, 71],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [227, 310, 156, 107],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [120, 297, 109, 59],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-180_jpg.rf.884e19fdc7e8c25a3efe6dd06b0b0515.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 923,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [174, 198, 53, 282],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-164_jpg.rf.88f11bf3291c49bd39c495f5574d1daa.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 924,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [36, 82, 415, 140],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-27_jpg.rf.8879323f12e72292eacbc469063a5a1d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 925,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [175, 334, 166, 49],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-67_jpg.rf.8905c655c394c1f515c40293c6f0ec86.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 926,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [199, 139, 125, 88],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-116_jpg.rf.89959f1c15d205dee29614b6ab691486.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 927,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 334, 244, 164],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-105_jpg.rf.8984022cc45a971389104056d7ed88cf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 928,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [179, 313, 224, 176],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-200_jpg.rf.88fabcc8aa883a87900a4c3cee04d240.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 929,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [202, 299, 147, 89],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-40_jpg.rf.89227c727debfa0f3542946b88b5910f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 930,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 251, 64, 164],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-11_jpg.rf.89a8800ffa0bf01fa62ff593513062ff.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 931,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 194, 286, 203],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-151_jpg.rf.89dbc403cc7e49c02e1e10553afdcbca.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 932,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [42, 94, 349, 176],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-157_jpg.rf.8510d44d3708fe6237b28d98c6816931.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 933,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [68, 233, 300, 195],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-61_jpg.rf.8a002134a92c95c8da1060013d5f5817.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 934,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [127, 233, 250, 194],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-32_jpg.rf.89e2b9a5d8430a87436c9be180d4c9eb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 935,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [48, 136, 99, 82],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-169_jpg.rf.8a242da229fdc770b2458821c0773d08.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 936,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [148, 237, 68, 208],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-104_jpg.rf.8a5b5744a916eaced0d1478679610fdf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 937,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [327, 260, 173, 82],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-214_jpg.rf.8ae744a5300ffa08998fd71ee95fd6ba.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 938,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [193, 14, 208, 108],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [1, 345, 305, 155],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-113_jpg.rf.8a5d998cc71ca747999b1ea8a447e562.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 939,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [191, 81, 246, 233],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [108, 240, 11, 51],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-131_jpg.rf.8b7927ce22ed75c810cd2d3f845bcb4b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 940,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [81, 213, 304, 202],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-221_jpg.rf.8b7975e366aa1ae52c12d4a06a74d67d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 941,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [214, 251, 121, 63],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-123_jpg.rf.8b09b90b6a42c013dd286b4a86db779b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 942,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 328, 235, 100],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [145, 357, 271, 115],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-66_jpg.rf.8bb6ee2759b546d690cff3c165708fc8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 943,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [472, 271, 28, 22],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [227, 268, 179, 172],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [398, 300, 61, 48],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [457, 291, 43, 50],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-149_jpg.rf.8bec3df10039814d871f1d70f7057414.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 944,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [273, 315, 219, 98],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [125, 322, 265, 178],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-20_jpg.rf.8c14cf69a6d8efc3bf356960723d8287.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 945,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [454, 36, 46, 73],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [241, 272, 90, 52],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [334, 137, 41, 44],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [346, 294, 94, 101],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-89_jpg.rf.8c38203733bb705e8212246011571b3d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 946,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [58, 298, 123, 59],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [222, 249, 89, 49],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [304, 248, 129, 75],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-113_jpg.rf.8c200ef4a201c40fb8b750085ccab868.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 947,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [216, 197, 25, 113],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [184, 215, 32, 91],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [125, 244, 20, 49],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-135_jpg.rf.8cbe805edec440e478a544e3a6c0560f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 948,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [342, 148, 131, 125],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [176, 149, 257, 221],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [129, 158, 147, 98],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-15_jpg.rf.8bce7ca4f5ff53dca6131bb589565c74.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 949,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [74, 166, 162, 60],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-8_jpg.rf.8b5bac8d69dd76d1c49fc81549b38aa0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 950,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [102, 83, 290, 130],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-65_jpg.rf.8d2ebcdc40835ff559402e2f17f47e38.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 951,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [245, 60, 212, 213],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-109_jpg.rf.8e9c5fe44959db7157534e6ebb24c92b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 952,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [122, 221, 316, 143],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 293, 95, 84],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [162, 155, 130, 63],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-290_jpg.rf.8e31566d2eefdf4e592cbe71714a0b3e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 953,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [13, 270, 312, 161],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-12_jpg.rf.8f4d029f14ae04c08aa984d9da29fc1c.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 954,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [19, 206, 163, 77],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-106_jpg.rf.8ec1190fd89c319dd52a86fedf24906e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 955,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [138, 174, 22, 94],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [184, 188, 92, 98],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [303, 103, 191, 217],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [102, 267, 83, 97],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-223_jpg.rf.8ee9f6e27fb5755543d6ed125db9e9cf.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 956,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [106, 252, 251, 145],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-110_jpg.rf.8f7ade3a6e1b69a5a890a732e88544e6.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 957,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [50, 246, 375, 134],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-137_jpg.rf.8f9f407bc0d158e8ca57d2fd94488f81.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 958,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [336, 105, 69, 62],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [258, 181, 85, 97],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-197_jpg.rf.8d9d2675cbcd46b77021978c6588a128.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 959,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [83, 61, 46, 267],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [152, 63, 44, 272],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-159_jpg.rf.906086ba65322b6b4b016386eb446623.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 960,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [104, 186, 303, 217],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-196_jpg.rf.8fc11a901140f5e1dbcfa1743915e1c1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 961,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [111, 295, 143, 111],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [29, 178, 153, 127],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-124_jpg.rf.91307dd5c21505d2bee3d3f6411d6c17.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 962,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [8, 214, 443, 94],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [14, 68, 134, 239],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-153_jpg.rf.915c3ba770f90f87f8af21f75864f3b3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 963,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [317, 192, 118, 90],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [101, 179, 193, 99],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-165_jpg.rf.900078407dd18cf5f71570efb853e391.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 964,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [282, 367, 121, 80],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-284_jpg.rf.9041c37264e734309d696e7598e2871a.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 965,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [181, 203, 296, 146],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [169, 215, 111, 43],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-88_jpg.rf.90821cbb167502a8cba5d20a78432a43.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 966,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [342, 246, 18, 61],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [383, 245, 14, 40],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-121_jpg.rf.8b940a50111bde63f6e2d86984f023a3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 967,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [161, 119, 92, 106],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-225_jpg.rf.926e773ab26199fe5016004347ed2f75.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 968,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [37, 242, 343, 171],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-114_jpg.rf.9166e3e274719745ba00d2c3dfc95755.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 969,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [401, 275, 50, 42],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [267, 204, 172, 110],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [47, 115, 307, 185],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-60_jpg.rf.9231b509df627225c20dcf7985ac91a2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 970,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [63, 262, 126, 52],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [296, 290, 204, 125],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [154, 274, 142, 73],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-31_jpg.rf.92d0adbac750c68ed1a97a4fb31329b2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 971,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [40, 104, 461, 163],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-112_jpg.rf.92c571ebad6cff5e77299ed75bfec244.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 972,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [121, 207, 335, 163],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-84_jpg.rf.929a3bebf2a926c5f64f8aab0e827f31.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 973,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [118, 247, 172, 136],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [156, 124, 197, 173],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-51_jpg.rf.92f08a8bac16746f4d3428c0eabe38cc.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 974,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [186, 232, 52, 155],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [340, 150, 89, 237],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-266_jpg.rf.9335266b57c74526dabdb031f1876c58.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 975,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [145, 264, 355, 227],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 246, 145, 150],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 405, 136, 95],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-177_jpg.rf.933d239b490e484e599475ff02c6832d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 976,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [169, 310, 159, 104],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [0, 340, 229, 114],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-4_jpg.rf.93665a05e835a43b8da53bd29853c65b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 977,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 112, 500, 205],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-166_jpg.rf.93f5f393dab21727d4589300c75bfcb8.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 978,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [194, 200, 226, 190],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [292, 164, 145, 64],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-35_jpg.rf.93808c8e1d9601b7e98d5a57035d84b0.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 979,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [39, 154, 418, 116],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-98_jpg.rf.936b9c5854ade9d7a9f9a7ad16218217.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 980,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 245, 428, 190],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-195_jpg.rf.93aab9ff91b1d2a4de3d767896a06bd3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 981,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [235, 251, 38, 170],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-173_jpg.rf.94092e54a0c22d29f52570a86eae5cf2.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 982,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [342, 141, 118, 68],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-145_jpg.rf.950c64f5e26846711e94606e7857269b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 983,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [163, 245, 73, 159],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-62_jpg.rf.9553a0bf1bde61cb4e0174e877623157.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 984,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [166, 252, 334, 74],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-166_jpg.rf.9652473290cba210ad396c267f0d3e0b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 985,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [307, 196, 121, 140],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-144_jpg.rf.934ee61abdbf696fe73a1c58f558283d.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 986,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [248, 122, 142, 167],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [79, 79, 130, 132],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [165, 210, 40, 76],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-158_jpg.rf.92756496eb3c54cf8b382cdb6f5beaf9.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 987,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [202, 162, 179, 125],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/towers-126_jpg.rf.95b068ec17b4611bd5fe8064cbaa7fbb.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 988,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 279, 49, 157],\n    'category_id': 5,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/constructionMat-70_jpg.rf.9688b8cea2e20fa6b545581148067b86.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 989,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [161, 191, 152, 73],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters2-33_jpg.rf.9664f64be141aef3243424c69108198e.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 990,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [227, 264, 173, 67],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-140_jpg.rf.96970a1e7ff6a9679f68cc4835b734e3.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 991,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [156, 116, 73, 176],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [13, 10, 146, 219],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard2-25_jpg.rf.9665558117d81227a9dcd770e1355aa1.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 992,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [15, 45, 243, 154],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-46_jpg.rf.97295a8092a44f1100c8b8763bf16973.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 993,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [222, 90, 153, 100],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-16_jpg.rf.9696f88c608b7d7af6aecd333068508b.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 994,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [54, 149, 74, 26],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [245, 190, 206, 151],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [72, 165, 85, 30],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n   {'iscrowd': 0,\n    'bbox': [32, 144, 57, 25],\n    'category_id': 3,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/bricks-141_jpg.rf.97e5ab78a5d6603d09ced9dd15c4e353.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 995,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [172, 328, 164, 76],\n    'category_id': 2,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-78_jpg.rf.96cdf441b824d4e3eb6854329ac6d7a4.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 996,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [57, 88, 95, 99],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/streetLitters-111_jpg.rf.98586f972d89606486103bdd4725ce66.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 997,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [83, 241, 417, 153],\n    'category_id': 4,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/wires-53_jpg.rf.972e47cdee425eb42e697cdb301af835.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 998,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [1, 109, 192, 228],\n    'category_id': 6,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n {'file_name': '/kaggle/input/vispol/dhaka-streets-coco/train/billboard-20_jpg.rf.95424c9adc09469fcdacbbb7a428036f.jpg',\n  'height': 500,\n  'width': 500,\n  'image_id': 999,\n  'annotations': [{'iscrowd': 0,\n    'bbox': [0, 176, 280, 303],\n    'category_id': 1,\n    'bbox_mode': <BoxMode.XYWH_ABS: 1>}]},\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.evaluation import COCOEvaluator\n\nclass CocoTrainer(DefaultTrainer):\n\n  @classmethod\n  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n\n    if output_folder is None:\n        os.makedirs(\"coco_eval\", exist_ok=True)\n        output_folder = \"coco_eval\"\n\n    return COCOEvaluator(dataset_name, cfg, False, output_folder)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:50.166904Z","iopub.execute_input":"2022-12-06T14:51:50.167505Z","iopub.status.idle":"2022-12-06T14:51:50.174377Z","shell.execute_reply.started":"2022-12-06T14:51:50.167464Z","shell.execute_reply":"2022-12-06T14:51:50.173439Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\n\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"my_dataset_train\",)\ncfg.DATASETS.TEST = ('my_dataset_val',)\n\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 8\ncfg.SOLVER.BASE_LR =0.00025  \n\n\ncfg.SOLVER.MAX_ITER = 14000 #adjust up if val mAP is still rising, adjust down if overfit\ncfg.SOLVER.STEPS = [] \n\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\n\n\ncfg.TEST.EVAL_PERIOD = 140\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = CocoTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:51:50.177614Z","iopub.execute_input":"2022-12-06T14:51:50.178198Z","iopub.status.idle":"2022-12-06T19:47:48.943710Z","shell.execute_reply.started":"2022-12-06T14:51:50.178166Z","shell.execute_reply":"2022-12-06T19:47:48.942682Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[32m[12/06 14:51:54 d2.engine.defaults]: \u001b[0mModel:\nGeneralizedRCNN(\n  (backbone): FPN(\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (top_block): LastLevelMaxPool()\n    (bottom_up): ResNet(\n      (stem): BasicStem(\n        (conv1): Conv2d(\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n      )\n      (res2): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n      )\n      (res3): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n      )\n      (res4): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (4): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (5): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (6): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (7): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (8): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (9): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (10): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (11): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (12): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (13): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (14): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (15): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (16): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (17): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (18): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (19): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (20): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (21): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (22): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n      )\n      (res5): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n      )\n    )\n  )\n  (proposal_generator): RPN(\n    (rpn_head): StandardRPNHead(\n      (conv): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n        (activation): ReLU()\n      )\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (anchor_generator): DefaultAnchorGenerator(\n      (cell_anchors): BufferList()\n    )\n  )\n  (roi_heads): StandardROIHeads(\n    (box_pooler): ROIPooler(\n      (level_poolers): ModuleList(\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n      )\n    )\n    (box_head): FastRCNNConvFCHead(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc_relu1): ReLU()\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n      (fc_relu2): ReLU()\n    )\n    (box_predictor): FastRCNNOutputLayers(\n      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n    )\n  )\n)\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 14:51:54 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 14:51:54 d2.data.datasets.coco]: \u001b[0mLoaded 1117 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/train/_annotations.coco.json\n\u001b[32m[12/06 14:51:54 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1117 images left.\n\u001b[32m[12/06 14:51:54 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n| pollutants | 0            | 0          | 215          | 1          | 256          |\n|     2      | 405          | 3          | 363          | 4          | 327          |\n|     5      | 192          |            |              |            |              |\n|   total    | 1758         |            |              |            |              |\u001b[0m\n\u001b[32m[12/06 14:51:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[12/06 14:51:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n\u001b[32m[12/06 14:51:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 14:51:54 d2.data.common]: \u001b[0mSerializing 1117 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 14:51:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n","output_type":"stream"},{"name":"stderr","text":"model_final_f6e8b1.pkl: 243MB [00:03, 70.3MB/s]                              \n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[12/06 14:52:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:2227.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[12/06 14:52:34 d2.utils.events]: \u001b[0m eta: 4:19:46  iter: 19  total_loss: 2.332  loss_cls: 2.082  loss_box_reg: 0.1053  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.01325  time: 1.1131  data_time: 0.1109  lr: 4.9953e-06  max_mem: 8018M\n\u001b[32m[12/06 14:52:56 d2.utils.events]: \u001b[0m eta: 4:21:29  iter: 39  total_loss: 2.254  loss_cls: 1.959  loss_box_reg: 0.1218  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.01398  time: 1.1184  data_time: 0.1016  lr: 9.9903e-06  max_mem: 8018M\n\u001b[32m[12/06 14:53:18 d2.utils.events]: \u001b[0m eta: 4:21:10  iter: 59  total_loss: 1.902  loss_cls: 1.694  loss_box_reg: 0.09777  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.01259  time: 1.1132  data_time: 0.0921  lr: 1.4985e-05  max_mem: 8018M\n\u001b[32m[12/06 14:53:40 d2.utils.events]: \u001b[0m eta: 4:21:12  iter: 79  total_loss: 1.477  loss_cls: 1.298  loss_box_reg: 0.09696  loss_rpn_cls: 0.09768  loss_rpn_loc: 0.01176  time: 1.1138  data_time: 0.0949  lr: 1.998e-05  max_mem: 8018M\n\u001b[32m[12/06 14:54:02 d2.utils.events]: \u001b[0m eta: 4:20:31  iter: 99  total_loss: 1.134  loss_cls: 0.9149  loss_box_reg: 0.0853  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.01447  time: 1.1109  data_time: 0.0958  lr: 2.4975e-05  max_mem: 8018M\n\u001b[32m[12/06 14:54:25 d2.utils.events]: \u001b[0m eta: 4:20:17  iter: 119  total_loss: 0.8571  loss_cls: 0.5688  loss_box_reg: 0.1374  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.01233  time: 1.1132  data_time: 0.0990  lr: 2.997e-05  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 14:54:47 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 14:54:47 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 14:54:47 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n| pollutants | 0            | 0          | 53           | 1          | 49           |\n|     2      | 93           | 3          | 88           | 4          | 68           |\n|     5      | 44           |            |              |            |              |\n|   total    | 395          |            |              |            |              |\u001b[0m\n\u001b[32m[12/06 14:54:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 14:54:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 14:54:47 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 14:54:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 14:54:47 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 14:54:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 14:54:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 14:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0631 s/iter. Eval: 0.0003 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 14:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0637 s/iter. Eval: 0.0003 s/iter. Total: 0.0656 s/iter. ETA=0:00:12\n\u001b[32m[12/06 14:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0017 s/iter. Inference: 0.0662 s/iter. Eval: 0.0003 s/iter. Total: 0.0683 s/iter. ETA=0:00:08\n\u001b[32m[12/06 14:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0017 s/iter. Inference: 0.0652 s/iter. Eval: 0.0003 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 14:55:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.512467 (0.067564 s / iter per device, on 1 devices)\n\u001b[32m[12/06 14:55:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065238 s / iter per device, on 1 devices)\n\u001b[32m[12/06 14:55:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 14:55:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 14:55:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.03s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.94s).\nAccumulating evaluation results...\nDONE (t=0.33s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.016\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n\u001b[32m[12/06 14:55:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 0.004 | 0.013  | 0.003  | 0.000 | 0.000 | 0.028 |\n\u001b[32m[12/06 14:55:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP    | category   | AP    | category   | AP    |\n|:-----------|:------|:-----------|:------|:-----------|:------|\n| pollutants | nan   | 0          | 0.009 | 1          | 0.000 |\n| 2          | 0.016 | 3          | 0.001 | 4          | 0.001 |\n| 5          | 0.000 |            |       |            |       |\n\u001b[32m[12/06 14:55:08 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 14:55:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 14:55:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 14:55:08 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0044,0.0128,0.0034,0.0000,0.0001,0.0282\n\u001b[32m[12/06 14:55:08 d2.utils.events]: \u001b[0m eta: 4:19:55  iter: 139  total_loss: 0.6432  loss_cls: 0.4108  loss_box_reg: 0.1341  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.01176  time: 1.1111  data_time: 0.0901  lr: 3.4965e-05  max_mem: 8018M\n\u001b[32m[12/06 14:55:30 d2.utils.events]: \u001b[0m eta: 4:19:48  iter: 159  total_loss: 0.5834  loss_cls: 0.314  loss_box_reg: 0.1521  loss_rpn_cls: 0.0846  loss_rpn_loc: 0.01238  time: 1.1126  data_time: 0.0988  lr: 3.996e-05  max_mem: 8018M\n\u001b[32m[12/06 14:55:52 d2.utils.events]: \u001b[0m eta: 4:19:38  iter: 179  total_loss: 0.5281  loss_cls: 0.2953  loss_box_reg: 0.1619  loss_rpn_cls: 0.07681  loss_rpn_loc: 0.01084  time: 1.1116  data_time: 0.0936  lr: 4.4955e-05  max_mem: 8018M\n\u001b[32m[12/06 14:56:14 d2.utils.events]: \u001b[0m eta: 4:19:23  iter: 199  total_loss: 0.6712  loss_cls: 0.3597  loss_box_reg: 0.2198  loss_rpn_cls: 0.07405  loss_rpn_loc: 0.01325  time: 1.1112  data_time: 0.0934  lr: 4.995e-05  max_mem: 8018M\n\u001b[32m[12/06 14:56:37 d2.utils.events]: \u001b[0m eta: 4:19:15  iter: 219  total_loss: 0.5476  loss_cls: 0.2954  loss_box_reg: 0.1811  loss_rpn_cls: 0.05063  loss_rpn_loc: 0.01485  time: 1.1141  data_time: 0.0966  lr: 5.4945e-05  max_mem: 8018M\n\u001b[32m[12/06 14:56:59 d2.utils.events]: \u001b[0m eta: 4:19:03  iter: 239  total_loss: 0.5569  loss_cls: 0.3029  loss_box_reg: 0.211  loss_rpn_cls: 0.04726  loss_rpn_loc: 0.009718  time: 1.1141  data_time: 0.0934  lr: 5.994e-05  max_mem: 8018M\n\u001b[32m[12/06 14:57:22 d2.utils.events]: \u001b[0m eta: 4:18:49  iter: 259  total_loss: 0.5712  loss_cls: 0.296  loss_box_reg: 0.2206  loss_rpn_cls: 0.05186  loss_rpn_loc: 0.01176  time: 1.1140  data_time: 0.0972  lr: 6.4935e-05  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 14:57:45 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 14:57:45 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 14:57:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 14:57:45 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 14:57:45 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 14:57:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 14:57:45 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 14:57:45 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 14:57:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 14:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 14:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 84/279. Dataloading: 0.0024 s/iter. Inference: 0.0660 s/iter. Eval: 0.0003 s/iter. Total: 0.0688 s/iter. ETA=0:00:13\n\u001b[32m[12/06 14:57:56 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0021 s/iter. Inference: 0.0647 s/iter. Eval: 0.0003 s/iter. Total: 0.0671 s/iter. ETA=0:00:07\n\u001b[32m[12/06 14:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 237/279. Dataloading: 0.0020 s/iter. Inference: 0.0645 s/iter. Eval: 0.0003 s/iter. Total: 0.0668 s/iter. ETA=0:00:02\n\u001b[32m[12/06 14:58:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.469655 (0.067408 s / iter per device, on 1 devices)\n\u001b[32m[12/06 14:58:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064613 s / iter per device, on 1 devices)\n\u001b[32m[12/06 14:58:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 14:58:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 14:58:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.62s).\nAccumulating evaluation results...\nDONE (t=0.25s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.119\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n\u001b[32m[12/06 14:58:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 0.265 | 0.704  | 0.136  | 0.000 | 0.031 | 0.553 |\n\u001b[32m[12/06 14:58:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP    | category   | AP    | category   | AP    |\n|:-----------|:------|:-----------|:------|:-----------|:------|\n| pollutants | nan   | 0          | 0.103 | 1          | 0.349 |\n| 2          | 0.945 | 3          | 0.025 | 4          | 0.168 |\n| 5          | 0.001 |            |       |            |       |\n\u001b[32m[12/06 14:58:05 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 14:58:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 14:58:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 14:58:05 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2653,0.7044,0.1364,0.0000,0.0305,0.5526\n\u001b[32m[12/06 14:58:05 d2.utils.events]: \u001b[0m eta: 4:18:34  iter: 279  total_loss: 0.5467  loss_cls: 0.2853  loss_box_reg: 0.2245  loss_rpn_cls: 0.0394  loss_rpn_loc: 0.009647  time: 1.1158  data_time: 0.0966  lr: 6.993e-05  max_mem: 8018M\n\u001b[32m[12/06 14:58:28 d2.utils.events]: \u001b[0m eta: 4:18:27  iter: 299  total_loss: 0.6323  loss_cls: 0.3299  loss_box_reg: 0.2501  loss_rpn_cls: 0.03815  loss_rpn_loc: 0.01089  time: 1.1174  data_time: 0.0932  lr: 7.4925e-05  max_mem: 8018M\n\u001b[32m[12/06 14:58:50 d2.utils.events]: \u001b[0m eta: 4:18:16  iter: 319  total_loss: 0.6306  loss_cls: 0.3208  loss_box_reg: 0.2577  loss_rpn_cls: 0.0484  loss_rpn_loc: 0.01163  time: 1.1177  data_time: 0.0945  lr: 7.992e-05  max_mem: 8018M\n\u001b[32m[12/06 14:59:13 d2.utils.events]: \u001b[0m eta: 4:18:01  iter: 339  total_loss: 0.6158  loss_cls: 0.3192  loss_box_reg: 0.2461  loss_rpn_cls: 0.03894  loss_rpn_loc: 0.01206  time: 1.1187  data_time: 0.0969  lr: 8.4915e-05  max_mem: 8018M\n\u001b[32m[12/06 14:59:35 d2.utils.events]: \u001b[0m eta: 4:17:50  iter: 359  total_loss: 0.5716  loss_cls: 0.2942  loss_box_reg: 0.2455  loss_rpn_cls: 0.0306  loss_rpn_loc: 0.008896  time: 1.1198  data_time: 0.0954  lr: 8.991e-05  max_mem: 8018M\n\u001b[32m[12/06 14:59:57 d2.utils.events]: \u001b[0m eta: 4:17:30  iter: 379  total_loss: 0.6502  loss_cls: 0.3191  loss_box_reg: 0.2832  loss_rpn_cls: 0.03129  loss_rpn_loc: 0.009792  time: 1.1187  data_time: 0.0899  lr: 9.4905e-05  max_mem: 8018M\n\u001b[32m[12/06 15:00:20 d2.utils.events]: \u001b[0m eta: 4:17:14  iter: 399  total_loss: 0.6035  loss_cls: 0.3034  loss_box_reg: 0.2733  loss_rpn_cls: 0.02719  loss_rpn_loc: 0.01095  time: 1.1194  data_time: 0.0950  lr: 9.99e-05  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:00:43 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:00:43 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:00:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:00:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:00:43 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:00:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:00:43 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:00:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:00:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:00:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0636 s/iter. Eval: 0.0003 s/iter. Total: 0.0652 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:00:49 d2.evaluation.evaluator]: \u001b[0mInference done 84/279. Dataloading: 0.0023 s/iter. Inference: 0.0657 s/iter. Eval: 0.0003 s/iter. Total: 0.0684 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:00:54 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0020 s/iter. Inference: 0.0652 s/iter. Eval: 0.0003 s/iter. Total: 0.0676 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:00:59 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0020 s/iter. Inference: 0.0652 s/iter. Eval: 0.0003 s/iter. Total: 0.0677 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.496081 (0.067504 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:01:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064960 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:01:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:01:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:01:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.50s).\nAccumulating evaluation results...\nDONE (t=0.31s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.247\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.115\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n\u001b[32m[12/06 15:01:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 2.486 | 5.960  | 1.306  | 0.000 | 0.638 | 4.042 |\n\u001b[32m[12/06 15:01:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP    | category   | AP    | category   | AP    |\n|:-----------|:------|:-----------|:------|:-----------|:------|\n| pollutants | nan   | 0          | 0.260 | 1          | 3.282 |\n| 2          | 5.009 | 3          | 0.405 | 4          | 5.954 |\n| 5          | 0.003 |            |       |            |       |\n\u001b[32m[12/06 15:01:03 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:01:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:01:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:01:03 d2.evaluation.testing]: \u001b[0mcopypaste: 2.4856,5.9601,1.3057,0.0000,0.6375,4.0422\n\u001b[32m[12/06 15:01:03 d2.utils.events]: \u001b[0m eta: 4:17:01  iter: 419  total_loss: 0.6893  loss_cls: 0.3272  loss_box_reg: 0.2931  loss_rpn_cls: 0.03183  loss_rpn_loc: 0.009901  time: 1.1206  data_time: 0.0946  lr: 0.0001049  max_mem: 8018M\n\u001b[32m[12/06 15:01:26 d2.utils.events]: \u001b[0m eta: 4:16:39  iter: 439  total_loss: 0.6037  loss_cls: 0.3032  loss_box_reg: 0.2616  loss_rpn_cls: 0.03266  loss_rpn_loc: 0.01044  time: 1.1206  data_time: 0.0978  lr: 0.00010989  max_mem: 8018M\n\u001b[32m[12/06 15:01:48 d2.utils.events]: \u001b[0m eta: 4:16:22  iter: 459  total_loss: 0.6642  loss_cls: 0.3256  loss_box_reg: 0.2872  loss_rpn_cls: 0.03399  loss_rpn_loc: 0.009846  time: 1.1208  data_time: 0.0917  lr: 0.00011489  max_mem: 8018M\n\u001b[32m[12/06 15:02:11 d2.utils.events]: \u001b[0m eta: 4:16:06  iter: 479  total_loss: 0.6502  loss_cls: 0.3209  loss_box_reg: 0.2938  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.008412  time: 1.1209  data_time: 0.0932  lr: 0.00011988  max_mem: 8018M\n\u001b[32m[12/06 15:02:33 d2.utils.events]: \u001b[0m eta: 4:15:49  iter: 499  total_loss: 0.6406  loss_cls: 0.3142  loss_box_reg: 0.29  loss_rpn_cls: 0.02847  loss_rpn_loc: 0.01186  time: 1.1215  data_time: 0.0948  lr: 0.00012488  max_mem: 8018M\n\u001b[32m[12/06 15:02:56 d2.utils.events]: \u001b[0m eta: 4:15:33  iter: 519  total_loss: 0.5639  loss_cls: 0.2732  loss_box_reg: 0.2709  loss_rpn_cls: 0.0251  loss_rpn_loc: 0.009752  time: 1.1220  data_time: 0.0990  lr: 0.00012987  max_mem: 8018M\n\u001b[32m[12/06 15:03:18 d2.utils.events]: \u001b[0m eta: 4:15:17  iter: 539  total_loss: 0.6393  loss_cls: 0.3012  loss_box_reg: 0.3004  loss_rpn_cls: 0.02835  loss_rpn_loc: 0.01202  time: 1.1219  data_time: 0.0934  lr: 0.00013487  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:03:41 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:03:41 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:03:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:03:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:03:41 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:03:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:03:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:03:41 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:03:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0036 s/iter. Inference: 0.0671 s/iter. Eval: 0.0003 s/iter. Total: 0.0710 s/iter. ETA=0:00:19\n\u001b[32m[12/06 15:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0017 s/iter. Inference: 0.0639 s/iter. Eval: 0.0003 s/iter. Total: 0.0660 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 155/279. Dataloading: 0.0018 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0700 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 230/279. Dataloading: 0.0018 s/iter. Inference: 0.0669 s/iter. Eval: 0.0003 s/iter. Total: 0.0691 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:04:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.805350 (0.068633 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:04:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.066261 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:04:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:04:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:04:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.62s).\nAccumulating evaluation results...\nDONE (t=0.28s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.195\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.360\n\u001b[32m[12/06 15:04:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n| 8.772 | 19.466 | 5.222  | 0.000 | 5.541 | 11.215 |\n\u001b[32m[12/06 15:04:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP    | category   | AP    | category   | AP     |\n|:-----------|:------|:-----------|:------|:-----------|:-------|\n| pollutants | nan   | 0          | 0.717 | 1          | 13.515 |\n| 2          | 7.731 | 3          | 1.498 | 4          | 29.156 |\n| 5          | 0.013 |            |       |            |        |\n\u001b[32m[12/06 15:04:01 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:04:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:04:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:04:01 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7715,19.4665,5.2218,0.0000,5.5414,11.2148\n\u001b[32m[12/06 15:04:01 d2.utils.events]: \u001b[0m eta: 4:14:58  iter: 559  total_loss: 0.6284  loss_cls: 0.2998  loss_box_reg: 0.3046  loss_rpn_cls: 0.02482  loss_rpn_loc: 0.01176  time: 1.1221  data_time: 0.0913  lr: 0.00013986  max_mem: 8018M\n\u001b[32m[12/06 15:04:24 d2.utils.events]: \u001b[0m eta: 4:14:39  iter: 579  total_loss: 0.654  loss_cls: 0.3063  loss_box_reg: 0.2849  loss_rpn_cls: 0.0261  loss_rpn_loc: 0.01159  time: 1.1221  data_time: 0.0920  lr: 0.00014486  max_mem: 8018M\n\u001b[32m[12/06 15:04:47 d2.utils.events]: \u001b[0m eta: 4:14:22  iter: 599  total_loss: 0.6414  loss_cls: 0.2936  loss_box_reg: 0.3095  loss_rpn_cls: 0.02903  loss_rpn_loc: 0.01061  time: 1.1228  data_time: 0.0888  lr: 0.00014985  max_mem: 8018M\n\u001b[32m[12/06 15:05:09 d2.utils.events]: \u001b[0m eta: 4:14:04  iter: 619  total_loss: 0.5437  loss_cls: 0.2556  loss_box_reg: 0.262  loss_rpn_cls: 0.0206  loss_rpn_loc: 0.008654  time: 1.1227  data_time: 0.0921  lr: 0.00015485  max_mem: 8018M\n\u001b[32m[12/06 15:05:32 d2.utils.events]: \u001b[0m eta: 4:13:41  iter: 639  total_loss: 0.59  loss_cls: 0.2599  loss_box_reg: 0.2861  loss_rpn_cls: 0.02261  loss_rpn_loc: 0.008215  time: 1.1227  data_time: 0.0986  lr: 0.00015984  max_mem: 8018M\n\u001b[32m[12/06 15:05:54 d2.utils.events]: \u001b[0m eta: 4:13:21  iter: 659  total_loss: 0.5426  loss_cls: 0.2458  loss_box_reg: 0.2788  loss_rpn_cls: 0.02156  loss_rpn_loc: 0.009132  time: 1.1230  data_time: 0.0878  lr: 0.00016484  max_mem: 8018M\n\u001b[32m[12/06 15:06:17 d2.utils.events]: \u001b[0m eta: 4:13:00  iter: 679  total_loss: 0.6419  loss_cls: 0.2844  loss_box_reg: 0.3102  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.01001  time: 1.1232  data_time: 0.0968  lr: 0.00016983  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:06:40 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:06:40 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:06:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:06:40 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:06:40 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:06:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:06:40 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:06:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:06:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0634 s/iter. Eval: 0.0003 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0632 s/iter. Eval: 0.0003 s/iter. Total: 0.0650 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0003 s/iter. Total: 0.0662 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0016 s/iter. Inference: 0.0639 s/iter. Eval: 0.0003 s/iter. Total: 0.0659 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:06:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.417473 (0.067217 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:06:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064805 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:06:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:06:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:06:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=1.11s).\nAccumulating evaluation results...\nDONE (t=0.29s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n\u001b[32m[12/06 15:07:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n|:------:|:------:|:------:|:-----:|:------:|:------:|\n| 14.386 | 33.751 | 6.611  | 0.289 | 10.175 | 16.469 |\n\u001b[32m[12/06 15:07:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP    | category   | AP     |\n|:-----------|:-------|:-----------|:------|:-----------|:-------|\n| pollutants | nan    | 0          | 7.482 | 1          | 21.743 |\n| 2          | 13.771 | 3          | 7.519 | 4          | 35.664 |\n| 5          | 0.140  |            |       |            |        |\n\u001b[32m[12/06 15:07:00 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:07:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:07:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:07:00 d2.evaluation.testing]: \u001b[0mcopypaste: 14.3863,33.7511,6.6113,0.2885,10.1745,16.4691\n\u001b[32m[12/06 15:07:00 d2.utils.events]: \u001b[0m eta: 4:12:42  iter: 699  total_loss: 0.5921  loss_cls: 0.2607  loss_box_reg: 0.3091  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.00917  time: 1.1235  data_time: 0.0976  lr: 0.00017483  max_mem: 8018M\n\u001b[32m[12/06 15:07:23 d2.utils.events]: \u001b[0m eta: 4:12:23  iter: 719  total_loss: 0.6781  loss_cls: 0.2981  loss_box_reg: 0.3456  loss_rpn_cls: 0.02624  loss_rpn_loc: 0.01145  time: 1.1243  data_time: 0.0900  lr: 0.00017982  max_mem: 8018M\n\u001b[32m[12/06 15:07:46 d2.utils.events]: \u001b[0m eta: 4:12:01  iter: 739  total_loss: 0.5599  loss_cls: 0.2361  loss_box_reg: 0.2881  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.009301  time: 1.1243  data_time: 0.0970  lr: 0.00018482  max_mem: 8018M\n\u001b[32m[12/06 15:08:09 d2.utils.events]: \u001b[0m eta: 4:11:45  iter: 759  total_loss: 0.5442  loss_cls: 0.2399  loss_box_reg: 0.2925  loss_rpn_cls: 0.0179  loss_rpn_loc: 0.007765  time: 1.1249  data_time: 0.0957  lr: 0.00018981  max_mem: 8018M\n\u001b[32m[12/06 15:08:31 d2.utils.events]: \u001b[0m eta: 4:11:22  iter: 779  total_loss: 0.5442  loss_cls: 0.2326  loss_box_reg: 0.2894  loss_rpn_cls: 0.0166  loss_rpn_loc: 0.009436  time: 1.1248  data_time: 0.0901  lr: 0.00019481  max_mem: 8018M\n\u001b[32m[12/06 15:08:54 d2.utils.events]: \u001b[0m eta: 4:11:00  iter: 799  total_loss: 0.5456  loss_cls: 0.2201  loss_box_reg: 0.2736  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.01035  time: 1.1247  data_time: 0.0894  lr: 0.0001998  max_mem: 8018M\n\u001b[32m[12/06 15:09:16 d2.utils.events]: \u001b[0m eta: 4:10:37  iter: 819  total_loss: 0.5855  loss_cls: 0.2474  loss_box_reg: 0.3097  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.009205  time: 1.1245  data_time: 0.0953  lr: 0.0002048  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:09:39 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:09:39 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:09:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:09:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:09:39 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:09:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:09:39 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:09:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:09:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:09:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0670 s/iter. Eval: 0.0003 s/iter. Total: 0.0687 s/iter. ETA=0:00:18\n\u001b[32m[12/06 15:09:45 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0018 s/iter. Inference: 0.0645 s/iter. Eval: 0.0003 s/iter. Total: 0.0667 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:09:50 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0003 s/iter. Total: 0.0663 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:09:55 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0016 s/iter. Inference: 0.0639 s/iter. Eval: 0.0003 s/iter. Total: 0.0659 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:09:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.232833 (0.066543 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:09:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064245 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:09:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:09:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:09:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.65s).\nAccumulating evaluation results...\nDONE (t=0.26s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.455\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.098\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.148\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.389\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n\u001b[32m[12/06 15:09:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n|:------:|:------:|:------:|:-----:|:------:|:------:|\n| 19.324 | 45.531 | 9.800  | 0.673 | 14.833 | 21.502 |\n\u001b[32m[12/06 15:09:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 15.034 | 1          | 29.068 |\n| 2          | 20.109 | 3          | 11.181 | 4          | 38.075 |\n| 5          | 2.476  |            |        |            |        |\n\u001b[32m[12/06 15:09:59 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:09:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:09:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:09:59 d2.evaluation.testing]: \u001b[0mcopypaste: 19.3240,45.5314,9.7998,0.6733,14.8327,21.5025\n\u001b[32m[12/06 15:09:59 d2.utils.events]: \u001b[0m eta: 4:10:18  iter: 839  total_loss: 0.5731  loss_cls: 0.2209  loss_box_reg: 0.3192  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.008589  time: 1.1249  data_time: 0.0918  lr: 0.00020979  max_mem: 8018M\n\u001b[32m[12/06 15:10:21 d2.utils.events]: \u001b[0m eta: 4:09:59  iter: 859  total_loss: 0.5258  loss_cls: 0.2016  loss_box_reg: 0.2908  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.007775  time: 1.1252  data_time: 0.0926  lr: 0.00021479  max_mem: 8018M\n\u001b[32m[12/06 15:10:44 d2.utils.events]: \u001b[0m eta: 4:09:40  iter: 879  total_loss: 0.5259  loss_cls: 0.2048  loss_box_reg: 0.31  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.009491  time: 1.1256  data_time: 0.0929  lr: 0.00021978  max_mem: 8018M\n\u001b[32m[12/06 15:11:07 d2.utils.events]: \u001b[0m eta: 4:09:21  iter: 899  total_loss: 0.5381  loss_cls: 0.211  loss_box_reg: 0.3107  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.009841  time: 1.1257  data_time: 0.0911  lr: 0.00022478  max_mem: 8018M\n\u001b[32m[12/06 15:11:30 d2.utils.events]: \u001b[0m eta: 4:09:00  iter: 919  total_loss: 0.5264  loss_cls: 0.1982  loss_box_reg: 0.2835  loss_rpn_cls: 0.02224  loss_rpn_loc: 0.01045  time: 1.1259  data_time: 0.0938  lr: 0.00022977  max_mem: 8018M\n\u001b[32m[12/06 15:11:52 d2.utils.events]: \u001b[0m eta: 4:08:36  iter: 939  total_loss: 0.4747  loss_cls: 0.1513  loss_box_reg: 0.2891  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.00906  time: 1.1253  data_time: 0.0919  lr: 0.00023477  max_mem: 8018M\n\u001b[32m[12/06 15:12:15 d2.utils.events]: \u001b[0m eta: 4:08:16  iter: 959  total_loss: 0.4759  loss_cls: 0.1553  loss_box_reg: 0.2831  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.0108  time: 1.1257  data_time: 0.0933  lr: 0.00023976  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:12:37 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:12:37 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:12:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:12:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:12:37 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:12:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:12:37 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:12:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:12:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0011 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 79/279. Dataloading: 0.0028 s/iter. Inference: 0.0696 s/iter. Eval: 0.0003 s/iter. Total: 0.0728 s/iter. ETA=0:00:14\n\u001b[32m[12/06 15:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 156/279. Dataloading: 0.0022 s/iter. Inference: 0.0664 s/iter. Eval: 0.0003 s/iter. Total: 0.0689 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 231/279. Dataloading: 0.0020 s/iter. Inference: 0.0659 s/iter. Eval: 0.0003 s/iter. Total: 0.0683 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:12:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.618259 (0.067950 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:12:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065462 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:12:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:12:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:12:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.83s).\nAccumulating evaluation results...\nDONE (t=0.20s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.546\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.435\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n\u001b[32m[12/06 15:12:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n|:------:|:------:|:------:|:-----:|:------:|:------:|\n| 25.601 | 54.595 | 19.964 | 0.757 | 20.118 | 28.286 |\n\u001b[32m[12/06 15:12:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 15.497 | 1          | 44.148 |\n| 2          | 30.480 | 3          | 13.671 | 4          | 45.736 |\n| 5          | 4.076  |            |        |            |        |\n\u001b[32m[12/06 15:12:57 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:12:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:12:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:12:57 d2.evaluation.testing]: \u001b[0mcopypaste: 25.6012,54.5954,19.9638,0.7574,20.1179,28.2857\n\u001b[32m[12/06 15:12:57 d2.utils.events]: \u001b[0m eta: 4:07:53  iter: 979  total_loss: 0.4782  loss_cls: 0.1564  loss_box_reg: 0.2826  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.009121  time: 1.1255  data_time: 0.0896  lr: 0.00024476  max_mem: 8018M\n\u001b[32m[12/06 15:13:20 d2.utils.events]: \u001b[0m eta: 4:07:33  iter: 999  total_loss: 0.4645  loss_cls: 0.1405  loss_box_reg: 0.2849  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.008916  time: 1.1259  data_time: 0.0983  lr: 0.00024975  max_mem: 8018M\n\u001b[32m[12/06 15:13:42 d2.utils.events]: \u001b[0m eta: 4:07:13  iter: 1019  total_loss: 0.4551  loss_cls: 0.1503  loss_box_reg: 0.274  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.01118  time: 1.1253  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:14:05 d2.utils.events]: \u001b[0m eta: 4:06:54  iter: 1039  total_loss: 0.4097  loss_cls: 0.1284  loss_box_reg: 0.258  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.009716  time: 1.1253  data_time: 0.0966  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:14:27 d2.utils.events]: \u001b[0m eta: 4:06:37  iter: 1059  total_loss: 0.423  loss_cls: 0.139  loss_box_reg: 0.2572  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.01221  time: 1.1253  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:14:50 d2.utils.events]: \u001b[0m eta: 4:06:18  iter: 1079  total_loss: 0.3844  loss_cls: 0.1318  loss_box_reg: 0.2475  loss_rpn_cls: 0.009365  loss_rpn_loc: 0.009375  time: 1.1258  data_time: 0.0963  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:15:13 d2.utils.events]: \u001b[0m eta: 4:05:58  iter: 1099  total_loss: 0.4448  loss_cls: 0.1493  loss_box_reg: 0.2649  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.01032  time: 1.1260  data_time: 0.0885  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:15:36 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:15:36 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:15:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:15:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:15:36 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:15:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:15:36 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:15:36 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:15:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0053 s/iter. Inference: 0.0700 s/iter. Eval: 0.0003 s/iter. Total: 0.0756 s/iter. ETA=0:00:20\n\u001b[32m[12/06 15:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0020 s/iter. Inference: 0.0653 s/iter. Eval: 0.0003 s/iter. Total: 0.0677 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0018 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0666 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0021 s/iter. Inference: 0.0658 s/iter. Eval: 0.0003 s/iter. Total: 0.0682 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:15:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.600113 (0.067884 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:15:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065373 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:15:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:15:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:15:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.46s).\nAccumulating evaluation results...\nDONE (t=0.16s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.601\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n\u001b[32m[12/06 15:15:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n|:------:|:------:|:------:|:-----:|:------:|:------:|\n| 32.844 | 60.108 | 31.942 | 5.333 | 22.989 | 36.707 |\n\u001b[32m[12/06 15:15:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 20.106 | 1          | 59.863 |\n| 2          | 36.686 | 3          | 20.079 | 4          | 55.280 |\n| 5          | 5.051  |            |        |            |        |\n\u001b[32m[12/06 15:15:55 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:15:55 d2.evaluation.testing]: \u001b[0mcopypaste: 32.8442,60.1082,31.9417,5.3333,22.9889,36.7069\n\u001b[32m[12/06 15:15:55 d2.utils.events]: \u001b[0m eta: 4:05:40  iter: 1119  total_loss: 0.3876  loss_cls: 0.1249  loss_box_reg: 0.2401  loss_rpn_cls: 0.0097  loss_rpn_loc: 0.009872  time: 1.1260  data_time: 0.0957  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:16:18 d2.utils.events]: \u001b[0m eta: 4:05:20  iter: 1139  total_loss: 0.4464  loss_cls: 0.1413  loss_box_reg: 0.2742  loss_rpn_cls: 0.008686  loss_rpn_loc: 0.009729  time: 1.1262  data_time: 0.0877  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:16:41 d2.utils.events]: \u001b[0m eta: 4:05:00  iter: 1159  total_loss: 0.4079  loss_cls: 0.1378  loss_box_reg: 0.2414  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01069  time: 1.1262  data_time: 0.0955  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:17:03 d2.utils.events]: \u001b[0m eta: 4:04:40  iter: 1179  total_loss: 0.4186  loss_cls: 0.1356  loss_box_reg: 0.2588  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.009685  time: 1.1264  data_time: 0.0956  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:17:26 d2.utils.events]: \u001b[0m eta: 4:04:17  iter: 1199  total_loss: 0.3309  loss_cls: 0.1024  loss_box_reg: 0.2029  loss_rpn_cls: 0.006789  loss_rpn_loc: 0.007153  time: 1.1263  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:17:49 d2.utils.events]: \u001b[0m eta: 4:03:56  iter: 1219  total_loss: 0.4017  loss_cls: 0.1265  loss_box_reg: 0.2401  loss_rpn_cls: 0.009244  loss_rpn_loc: 0.008745  time: 1.1265  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:18:11 d2.utils.events]: \u001b[0m eta: 4:03:34  iter: 1239  total_loss: 0.373  loss_cls: 0.1182  loss_box_reg: 0.2311  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.007039  time: 1.1264  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:18:34 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:18:34 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:18:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:18:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:18:34 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:18:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:18:34 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:18:34 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:18:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0016 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0657 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0017 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0017 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:18:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.156594 (0.066265 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:18:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064097 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:18:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:18:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:18:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.44s).\nAccumulating evaluation results...\nDONE (t=0.15s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.364\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585\n\u001b[32m[12/06 15:18:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 35.517 | 64.105 | 36.366 | 16.020 | 23.456 | 39.264 |\n\u001b[32m[12/06 15:18:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 31.336 | 1          | 61.298 |\n| 2          | 35.758 | 3          | 23.239 | 4          | 54.377 |\n| 5          | 7.093  |            |        |            |        |\n\u001b[32m[12/06 15:18:53 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:18:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:18:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:18:53 d2.evaluation.testing]: \u001b[0mcopypaste: 35.5169,64.1052,36.3663,16.0198,23.4561,39.2637\n\u001b[32m[12/06 15:18:53 d2.utils.events]: \u001b[0m eta: 4:03:14  iter: 1259  total_loss: 0.3574  loss_cls: 0.111  loss_box_reg: 0.2271  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.008309  time: 1.1268  data_time: 0.0962  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:19:16 d2.utils.events]: \u001b[0m eta: 4:02:54  iter: 1279  total_loss: 0.3428  loss_cls: 0.1119  loss_box_reg: 0.2232  loss_rpn_cls: 0.00946  loss_rpn_loc: 0.007627  time: 1.1269  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:19:39 d2.utils.events]: \u001b[0m eta: 4:02:32  iter: 1299  total_loss: 0.3767  loss_cls: 0.119  loss_box_reg: 0.2338  loss_rpn_cls: 0.009014  loss_rpn_loc: 0.007668  time: 1.1270  data_time: 0.0962  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:20:02 d2.utils.events]: \u001b[0m eta: 4:02:13  iter: 1319  total_loss: 0.3846  loss_cls: 0.1316  loss_box_reg: 0.2209  loss_rpn_cls: 0.009004  loss_rpn_loc: 0.009419  time: 1.1273  data_time: 0.0961  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:20:24 d2.utils.events]: \u001b[0m eta: 4:01:46  iter: 1339  total_loss: 0.3522  loss_cls: 0.1158  loss_box_reg: 0.2222  loss_rpn_cls: 0.008142  loss_rpn_loc: 0.008613  time: 1.1273  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:20:47 d2.utils.events]: \u001b[0m eta: 4:01:23  iter: 1359  total_loss: 0.3622  loss_cls: 0.1194  loss_box_reg: 0.2154  loss_rpn_cls: 0.008785  loss_rpn_loc: 0.007251  time: 1.1271  data_time: 0.0967  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:21:09 d2.utils.events]: \u001b[0m eta: 4:01:03  iter: 1379  total_loss: 0.3588  loss_cls: 0.1243  loss_box_reg: 0.2185  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.008196  time: 1.1271  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:21:32 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:21:32 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:21:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:21:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:21:32 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:21:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:21:32 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:21:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:21:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0027 s/iter. Inference: 0.0667 s/iter. Eval: 0.0002 s/iter. Total: 0.0697 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 156/279. Dataloading: 0.0024 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0692 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0021 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:21:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.591906 (0.067854 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:21:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065234 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:21:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:21:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:21:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.34s).\nAccumulating evaluation results...\nDONE (t=0.13s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.686\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.386\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592\n\u001b[32m[12/06 15:21:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n|:------:|:------:|:------:|:-----:|:------:|:------:|\n| 38.988 | 68.577 | 38.614 | 9.020 | 27.710 | 41.867 |\n\u001b[32m[12/06 15:21:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 36.461 | 1          | 65.509 |\n| 2          | 38.687 | 3          | 24.007 | 4          | 57.357 |\n| 5          | 11.906 |            |        |            |        |\n\u001b[32m[12/06 15:21:51 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:21:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:21:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:21:51 d2.evaluation.testing]: \u001b[0mcopypaste: 38.9877,68.5769,38.6136,9.0198,27.7102,41.8668\n\u001b[32m[12/06 15:21:51 d2.utils.events]: \u001b[0m eta: 4:00:38  iter: 1399  total_loss: 0.3394  loss_cls: 0.1069  loss_box_reg: 0.2187  loss_rpn_cls: 0.00794  loss_rpn_loc: 0.008614  time: 1.1271  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:22:14 d2.utils.events]: \u001b[0m eta: 4:00:14  iter: 1419  total_loss: 0.3484  loss_cls: 0.1222  loss_box_reg: 0.2086  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.008632  time: 1.1270  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:22:36 d2.utils.events]: \u001b[0m eta: 3:59:49  iter: 1439  total_loss: 0.3536  loss_cls: 0.1169  loss_box_reg: 0.2228  loss_rpn_cls: 0.007172  loss_rpn_loc: 0.006475  time: 1.1269  data_time: 0.0876  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:22:59 d2.utils.events]: \u001b[0m eta: 3:59:28  iter: 1459  total_loss: 0.3387  loss_cls: 0.1143  loss_box_reg: 0.2009  loss_rpn_cls: 0.007494  loss_rpn_loc: 0.007349  time: 1.1269  data_time: 0.0951  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:23:21 d2.utils.events]: \u001b[0m eta: 3:59:06  iter: 1479  total_loss: 0.3692  loss_cls: 0.118  loss_box_reg: 0.2363  loss_rpn_cls: 0.006202  loss_rpn_loc: 0.00928  time: 1.1269  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:23:44 d2.utils.events]: \u001b[0m eta: 3:58:41  iter: 1499  total_loss: 0.3153  loss_cls: 0.1079  loss_box_reg: 0.205  loss_rpn_cls: 0.006404  loss_rpn_loc: 0.008657  time: 1.1270  data_time: 0.0958  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:24:06 d2.utils.events]: \u001b[0m eta: 3:58:16  iter: 1519  total_loss: 0.3311  loss_cls: 0.1066  loss_box_reg: 0.2111  loss_rpn_cls: 0.007955  loss_rpn_loc: 0.006795  time: 1.1269  data_time: 0.0877  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:24:29 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:24:29 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:24:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:24:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:24:29 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:24:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:24:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:24:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:24:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:24:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0648 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:24:35 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0655 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0017 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0019 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0671 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:24:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.545500 (0.067684 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:24:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065217 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:24:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:24:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:24:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.54s).\nAccumulating evaluation results...\nDONE (t=0.12s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.713\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.389\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n\u001b[32m[12/06 15:24:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 40.810 | 71.252 | 40.497 | 15.010 | 29.042 | 44.106 |\n\u001b[32m[12/06 15:24:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 40.542 | 1          | 66.344 |\n| 2          | 39.681 | 3          | 24.083 | 4          | 59.133 |\n| 5          | 15.078 |            |        |            |        |\n\u001b[32m[12/06 15:24:49 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:24:49 d2.evaluation.testing]: \u001b[0mcopypaste: 40.8100,71.2520,40.4971,15.0099,29.0422,44.1063\n\u001b[32m[12/06 15:24:49 d2.utils.events]: \u001b[0m eta: 3:57:53  iter: 1539  total_loss: 0.337  loss_cls: 0.1153  loss_box_reg: 0.2088  loss_rpn_cls: 0.007196  loss_rpn_loc: 0.007244  time: 1.1269  data_time: 0.0963  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:25:12 d2.utils.events]: \u001b[0m eta: 3:57:31  iter: 1559  total_loss: 0.3528  loss_cls: 0.121  loss_box_reg: 0.2183  loss_rpn_cls: 0.006372  loss_rpn_loc: 0.007281  time: 1.1270  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:25:34 d2.utils.events]: \u001b[0m eta: 3:57:12  iter: 1579  total_loss: 0.3708  loss_cls: 0.1206  loss_box_reg: 0.2282  loss_rpn_cls: 0.007849  loss_rpn_loc: 0.008292  time: 1.1271  data_time: 0.0894  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:25:57 d2.utils.events]: \u001b[0m eta: 3:56:49  iter: 1599  total_loss: 0.3247  loss_cls: 0.1014  loss_box_reg: 0.205  loss_rpn_cls: 0.008003  loss_rpn_loc: 0.00766  time: 1.1272  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:26:20 d2.utils.events]: \u001b[0m eta: 3:56:29  iter: 1619  total_loss: 0.3376  loss_cls: 0.1046  loss_box_reg: 0.2066  loss_rpn_cls: 0.005534  loss_rpn_loc: 0.007749  time: 1.1274  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:26:42 d2.utils.events]: \u001b[0m eta: 3:56:06  iter: 1639  total_loss: 0.3416  loss_cls: 0.1111  loss_box_reg: 0.209  loss_rpn_cls: 0.007878  loss_rpn_loc: 0.008061  time: 1.1272  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:27:05 d2.utils.events]: \u001b[0m eta: 3:55:44  iter: 1659  total_loss: 0.3702  loss_cls: 0.1152  loss_box_reg: 0.2316  loss_rpn_cls: 0.006726  loss_rpn_loc: 0.008718  time: 1.1273  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:27:27 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:27:27 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:27:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:27:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:27:27 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:27:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:27:27 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:27:27 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:27:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0019 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0018 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0018 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:27:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.294810 (0.066769 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:27:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064505 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:27:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:27:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:27:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.30s).\nAccumulating evaluation results...\nDONE (t=0.13s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.398\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n\u001b[32m[12/06 15:27:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 41.268 | 72.028 | 40.209 | 12.880 | 29.273 | 44.620 |\n\u001b[32m[12/06 15:27:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.899 | 1          | 67.123 |\n| 2          | 39.009 | 3          | 25.249 | 4          | 55.835 |\n| 5          | 16.492 |            |        |            |        |\n\u001b[32m[12/06 15:27:47 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:27:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:27:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:27:47 d2.evaluation.testing]: \u001b[0mcopypaste: 41.2680,72.0277,40.2090,12.8802,29.2725,44.6204\n\u001b[32m[12/06 15:27:47 d2.utils.events]: \u001b[0m eta: 3:55:21  iter: 1679  total_loss: 0.3423  loss_cls: 0.1097  loss_box_reg: 0.2043  loss_rpn_cls: 0.007711  loss_rpn_loc: 0.007569  time: 1.1272  data_time: 0.0964  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:28:09 d2.utils.events]: \u001b[0m eta: 3:54:56  iter: 1699  total_loss: 0.3153  loss_cls: 0.1102  loss_box_reg: 0.194  loss_rpn_cls: 0.008505  loss_rpn_loc: 0.008031  time: 1.1272  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:28:32 d2.utils.events]: \u001b[0m eta: 3:54:32  iter: 1719  total_loss: 0.3308  loss_cls: 0.1041  loss_box_reg: 0.2194  loss_rpn_cls: 0.005325  loss_rpn_loc: 0.008054  time: 1.1272  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:28:55 d2.utils.events]: \u001b[0m eta: 3:54:11  iter: 1739  total_loss: 0.3209  loss_cls: 0.09289  loss_box_reg: 0.2042  loss_rpn_cls: 0.006454  loss_rpn_loc: 0.00642  time: 1.1273  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:29:17 d2.utils.events]: \u001b[0m eta: 3:53:43  iter: 1759  total_loss: 0.3418  loss_cls: 0.1039  loss_box_reg: 0.1968  loss_rpn_cls: 0.006582  loss_rpn_loc: 0.007606  time: 1.1270  data_time: 0.0866  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:29:40 d2.utils.events]: \u001b[0m eta: 3:53:23  iter: 1779  total_loss: 0.3626  loss_cls: 0.1273  loss_box_reg: 0.2101  loss_rpn_cls: 0.00526  loss_rpn_loc: 0.008375  time: 1.1274  data_time: 0.0966  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:30:02 d2.utils.events]: \u001b[0m eta: 3:53:00  iter: 1799  total_loss: 0.337  loss_cls: 0.1075  loss_box_reg: 0.2037  loss_rpn_cls: 0.007496  loss_rpn_loc: 0.008581  time: 1.1274  data_time: 0.0957  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:30:25 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:30:25 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:30:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:30:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:30:25 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:30:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:30:25 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:30:25 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:30:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 80/279. Dataloading: 0.0033 s/iter. Inference: 0.0690 s/iter. Eval: 0.0003 s/iter. Total: 0.0726 s/iter. ETA=0:00:14\n\u001b[32m[12/06 15:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0024 s/iter. Inference: 0.0662 s/iter. Eval: 0.0002 s/iter. Total: 0.0689 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 232/279. Dataloading: 0.0022 s/iter. Inference: 0.0659 s/iter. Eval: 0.0002 s/iter. Total: 0.0684 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:30:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.670716 (0.068141 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:30:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065505 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:30:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.26s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.406\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.582\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n\u001b[32m[12/06 15:30:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.205 | 74.628 | 41.299 | 14.616 | 31.042 | 46.295 |\n\u001b[32m[12/06 15:30:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.874 | 1          | 67.472 |\n| 2          | 40.240 | 3          | 28.175 | 4          | 57.907 |\n| 5          | 19.560 |            |        |            |        |\n\u001b[32m[12/06 15:30:44 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:30:44 d2.evaluation.testing]: \u001b[0mcopypaste: 43.2046,74.6279,41.2993,14.6161,31.0423,46.2954\n\u001b[32m[12/06 15:30:44 d2.utils.events]: \u001b[0m eta: 3:52:37  iter: 1819  total_loss: 0.3285  loss_cls: 0.1023  loss_box_reg: 0.2061  loss_rpn_cls: 0.007792  loss_rpn_loc: 0.00839  time: 1.1273  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:31:07 d2.utils.events]: \u001b[0m eta: 3:52:13  iter: 1839  total_loss: 0.3037  loss_cls: 0.09547  loss_box_reg: 0.2054  loss_rpn_cls: 0.006869  loss_rpn_loc: 0.00747  time: 1.1273  data_time: 0.0936  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:31:29 d2.utils.events]: \u001b[0m eta: 3:51:50  iter: 1859  total_loss: 0.3177  loss_cls: 0.101  loss_box_reg: 0.2045  loss_rpn_cls: 0.004191  loss_rpn_loc: 0.007034  time: 1.1272  data_time: 0.0905  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:31:52 d2.utils.events]: \u001b[0m eta: 3:51:26  iter: 1879  total_loss: 0.3377  loss_cls: 0.1034  loss_box_reg: 0.2201  loss_rpn_cls: 0.005898  loss_rpn_loc: 0.007225  time: 1.1271  data_time: 0.0911  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:32:14 d2.utils.events]: \u001b[0m eta: 3:51:01  iter: 1899  total_loss: 0.3174  loss_cls: 0.1018  loss_box_reg: 0.2029  loss_rpn_cls: 0.005151  loss_rpn_loc: 0.007545  time: 1.1272  data_time: 0.0978  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:32:37 d2.utils.events]: \u001b[0m eta: 3:50:38  iter: 1919  total_loss: 0.3423  loss_cls: 0.102  loss_box_reg: 0.2198  loss_rpn_cls: 0.006492  loss_rpn_loc: 0.008278  time: 1.1273  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:33:00 d2.utils.events]: \u001b[0m eta: 3:50:15  iter: 1939  total_loss: 0.3059  loss_cls: 0.09702  loss_box_reg: 0.2002  loss_rpn_cls: 0.004141  loss_rpn_loc: 0.007047  time: 1.1273  data_time: 0.0894  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:33:22 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:33:22 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:33:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:33:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:33:22 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:33:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:33:23 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:33:23 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:33:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0056 s/iter. Inference: 0.0741 s/iter. Eval: 0.0004 s/iter. Total: 0.0801 s/iter. ETA=0:00:21\n\u001b[32m[12/06 15:33:29 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0020 s/iter. Inference: 0.0649 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0019 s/iter. Inference: 0.0649 s/iter. Eval: 0.0002 s/iter. Total: 0.0671 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 228/279. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:33:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.955695 (0.069181 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:33:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.066304 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:33:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:33:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:33:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.28s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.416\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.590\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n\u001b[32m[12/06 15:33:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 42.418 | 72.850 | 41.286 | 16.340 | 29.617 | 46.091 |\n\u001b[32m[12/06 15:33:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.455 | 1          | 67.010 |\n| 2          | 38.646 | 3          | 28.793 | 4          | 57.247 |\n| 5          | 19.358 |            |        |            |        |\n\u001b[32m[12/06 15:33:42 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:33:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:33:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:33:42 d2.evaluation.testing]: \u001b[0mcopypaste: 42.4183,72.8501,41.2858,16.3403,29.6167,46.0913\n\u001b[32m[12/06 15:33:42 d2.utils.events]: \u001b[0m eta: 3:49:53  iter: 1959  total_loss: 0.3638  loss_cls: 0.1141  loss_box_reg: 0.2177  loss_rpn_cls: 0.008329  loss_rpn_loc: 0.008284  time: 1.1274  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:34:05 d2.utils.events]: \u001b[0m eta: 3:49:33  iter: 1979  total_loss: 0.2867  loss_cls: 0.09259  loss_box_reg: 0.1917  loss_rpn_cls: 0.004714  loss_rpn_loc: 0.006319  time: 1.1275  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:34:27 d2.utils.events]: \u001b[0m eta: 3:49:07  iter: 1999  total_loss: 0.2949  loss_cls: 0.08768  loss_box_reg: 0.1869  loss_rpn_cls: 0.003989  loss_rpn_loc: 0.007533  time: 1.1273  data_time: 0.0947  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:34:50 d2.utils.events]: \u001b[0m eta: 3:48:47  iter: 2019  total_loss: 0.3126  loss_cls: 0.09313  loss_box_reg: 0.1953  loss_rpn_cls: 0.005303  loss_rpn_loc: 0.006484  time: 1.1275  data_time: 0.0979  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:35:13 d2.utils.events]: \u001b[0m eta: 3:48:22  iter: 2039  total_loss: 0.3351  loss_cls: 0.1034  loss_box_reg: 0.2137  loss_rpn_cls: 0.00572  loss_rpn_loc: 0.007297  time: 1.1275  data_time: 0.0938  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:35:36 d2.utils.events]: \u001b[0m eta: 3:47:59  iter: 2059  total_loss: 0.3487  loss_cls: 0.1107  loss_box_reg: 0.2261  loss_rpn_cls: 0.005089  loss_rpn_loc: 0.007735  time: 1.1276  data_time: 0.0921  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:35:58 d2.utils.events]: \u001b[0m eta: 3:47:33  iter: 2079  total_loss: 0.2969  loss_cls: 0.09124  loss_box_reg: 0.1947  loss_rpn_cls: 0.004252  loss_rpn_loc: 0.007218  time: 1.1275  data_time: 0.0972  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:36:20 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:36:20 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:36:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:36:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:36:20 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:36:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:36:20 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:36:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:36:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0017 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:36:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.155996 (0.066263 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:36:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064095 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:36:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:36:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:36:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.31s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.453\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.422\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n\u001b[32m[12/06 15:36:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.109 | 74.284 | 45.310 | 14.570 | 30.768 | 46.618 |\n\u001b[32m[12/06 15:36:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.495 | 1          | 66.858 |\n| 2          | 38.886 | 3          | 27.747 | 4          | 57.947 |\n| 5          | 22.721 |            |        |            |        |\n\u001b[32m[12/06 15:36:40 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:36:40 d2.evaluation.testing]: \u001b[0mcopypaste: 43.1088,74.2843,45.3101,14.5703,30.7677,46.6183\n\u001b[32m[12/06 15:36:40 d2.utils.events]: \u001b[0m eta: 3:47:11  iter: 2099  total_loss: 0.3229  loss_cls: 0.09899  loss_box_reg: 0.2033  loss_rpn_cls: 0.006983  loss_rpn_loc: 0.007122  time: 1.1274  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:37:02 d2.utils.events]: \u001b[0m eta: 3:46:49  iter: 2119  total_loss: 0.315  loss_cls: 0.103  loss_box_reg: 0.1966  loss_rpn_cls: 0.004808  loss_rpn_loc: 0.006447  time: 1.1274  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:37:25 d2.utils.events]: \u001b[0m eta: 3:46:26  iter: 2139  total_loss: 0.2804  loss_cls: 0.09244  loss_box_reg: 0.1764  loss_rpn_cls: 0.004719  loss_rpn_loc: 0.008253  time: 1.1276  data_time: 0.1027  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:37:48 d2.utils.events]: \u001b[0m eta: 3:46:04  iter: 2159  total_loss: 0.2752  loss_cls: 0.09174  loss_box_reg: 0.1793  loss_rpn_cls: 0.004024  loss_rpn_loc: 0.006539  time: 1.1278  data_time: 0.0980  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:38:10 d2.utils.events]: \u001b[0m eta: 3:45:39  iter: 2179  total_loss: 0.2916  loss_cls: 0.08699  loss_box_reg: 0.1882  loss_rpn_cls: 0.0048  loss_rpn_loc: 0.007007  time: 1.1276  data_time: 0.0872  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:38:33 d2.utils.events]: \u001b[0m eta: 3:45:15  iter: 2199  total_loss: 0.3273  loss_cls: 0.09996  loss_box_reg: 0.2083  loss_rpn_cls: 0.004984  loss_rpn_loc: 0.00712  time: 1.1275  data_time: 0.0996  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:38:55 d2.utils.events]: \u001b[0m eta: 3:44:53  iter: 2219  total_loss: 0.305  loss_cls: 0.1029  loss_box_reg: 0.2002  loss_rpn_cls: 0.007512  loss_rpn_loc: 0.007928  time: 1.1276  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:39:18 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:39:18 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:39:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:39:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:39:18 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:39:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:39:18 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:39:18 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:39:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:39:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:39:24 d2.evaluation.evaluator]: \u001b[0mInference done 82/279. Dataloading: 0.0023 s/iter. Inference: 0.0681 s/iter. Eval: 0.0002 s/iter. Total: 0.0707 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:39:29 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0022 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0690 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0021 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:39:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.622424 (0.067965 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:39:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065393 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:39:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:39:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:39:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.25s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.44s).\nAccumulating evaluation results...\nDONE (t=0.16s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.417\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.420\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.590\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n\u001b[32m[12/06 15:39:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.653 | 77.223 | 41.709 | 15.260 | 31.378 | 48.017 |\n\u001b[32m[12/06 15:39:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 47.158 | 1          | 67.479 |\n| 2          | 39.904 | 3          | 30.200 | 4          | 57.573 |\n| 5          | 25.605 |            |        |            |        |\n\u001b[32m[12/06 15:39:38 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:39:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:39:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:39:38 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6531,77.2229,41.7090,15.2599,31.3782,48.0169\n\u001b[32m[12/06 15:39:38 d2.utils.events]: \u001b[0m eta: 3:44:31  iter: 2239  total_loss: 0.2785  loss_cls: 0.08881  loss_box_reg: 0.1869  loss_rpn_cls: 0.00422  loss_rpn_loc: 0.006179  time: 1.1275  data_time: 0.0946  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:40:00 d2.utils.events]: \u001b[0m eta: 3:44:06  iter: 2259  total_loss: 0.2989  loss_cls: 0.1013  loss_box_reg: 0.1877  loss_rpn_cls: 0.006164  loss_rpn_loc: 0.0061  time: 1.1275  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:40:23 d2.utils.events]: \u001b[0m eta: 3:43:46  iter: 2279  total_loss: 0.2858  loss_cls: 0.09256  loss_box_reg: 0.1818  loss_rpn_cls: 0.003321  loss_rpn_loc: 0.005176  time: 1.1276  data_time: 0.0951  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:40:46 d2.utils.events]: \u001b[0m eta: 3:43:23  iter: 2299  total_loss: 0.2989  loss_cls: 0.0943  loss_box_reg: 0.1962  loss_rpn_cls: 0.003742  loss_rpn_loc: 0.006627  time: 1.1278  data_time: 0.0911  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:41:09 d2.utils.events]: \u001b[0m eta: 3:42:58  iter: 2319  total_loss: 0.2891  loss_cls: 0.09519  loss_box_reg: 0.1804  loss_rpn_cls: 0.004073  loss_rpn_loc: 0.007104  time: 1.1278  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:41:31 d2.utils.events]: \u001b[0m eta: 3:42:38  iter: 2339  total_loss: 0.299  loss_cls: 0.08812  loss_box_reg: 0.1866  loss_rpn_cls: 0.005607  loss_rpn_loc: 0.00778  time: 1.1277  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:41:54 d2.utils.events]: \u001b[0m eta: 3:42:15  iter: 2359  total_loss: 0.3063  loss_cls: 0.09133  loss_box_reg: 0.1798  loss_rpn_cls: 0.004788  loss_rpn_loc: 0.008251  time: 1.1277  data_time: 0.0903  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:42:17 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:42:17 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:42:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:42:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:42:17 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:42:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:42:17 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:42:17 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:42:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0020 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0020 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0020 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0675 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:42:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.577668 (0.067802 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:42:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065228 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:42:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:42:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:42:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.24s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.421\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n\u001b[32m[12/06 15:42:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.109 | 75.588 | 43.793 | 12.648 | 31.661 | 47.467 |\n\u001b[32m[12/06 15:42:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.277 | 1          | 66.716 |\n| 2          | 40.330 | 3          | 30.941 | 4          | 58.746 |\n| 5          | 23.647 |            |        |            |        |\n\u001b[32m[12/06 15:42:36 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:42:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:42:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:42:36 d2.evaluation.testing]: \u001b[0mcopypaste: 44.1094,75.5879,43.7931,12.6478,31.6610,47.4668\n\u001b[32m[12/06 15:42:36 d2.utils.events]: \u001b[0m eta: 3:41:52  iter: 2379  total_loss: 0.3169  loss_cls: 0.1015  loss_box_reg: 0.1973  loss_rpn_cls: 0.004682  loss_rpn_loc: 0.006774  time: 1.1279  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:42:59 d2.utils.events]: \u001b[0m eta: 3:41:29  iter: 2399  total_loss: 0.2593  loss_cls: 0.07989  loss_box_reg: 0.1691  loss_rpn_cls: 0.004699  loss_rpn_loc: 0.006187  time: 1.1278  data_time: 0.0874  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:43:21 d2.utils.events]: \u001b[0m eta: 3:41:06  iter: 2419  total_loss: 0.2846  loss_cls: 0.08546  loss_box_reg: 0.182  loss_rpn_cls: 0.004408  loss_rpn_loc: 0.006959  time: 1.1278  data_time: 0.0904  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:43:44 d2.utils.events]: \u001b[0m eta: 3:40:46  iter: 2439  total_loss: 0.2737  loss_cls: 0.08588  loss_box_reg: 0.1767  loss_rpn_cls: 0.004325  loss_rpn_loc: 0.006905  time: 1.1280  data_time: 0.0974  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:44:07 d2.utils.events]: \u001b[0m eta: 3:40:24  iter: 2459  total_loss: 0.2845  loss_cls: 0.0994  loss_box_reg: 0.1785  loss_rpn_cls: 0.005546  loss_rpn_loc: 0.006644  time: 1.1281  data_time: 0.0964  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:44:30 d2.utils.events]: \u001b[0m eta: 3:40:02  iter: 2479  total_loss: 0.2878  loss_cls: 0.08462  loss_box_reg: 0.1886  loss_rpn_cls: 0.003585  loss_rpn_loc: 0.007425  time: 1.1281  data_time: 0.0882  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:44:52 d2.utils.events]: \u001b[0m eta: 3:39:40  iter: 2499  total_loss: 0.282  loss_cls: 0.09185  loss_box_reg: 0.1897  loss_rpn_cls: 0.003651  loss_rpn_loc: 0.006182  time: 1.1282  data_time: 0.0989  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:45:15 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:45:15 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:45:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:45:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:45:15 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:45:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:45:15 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:45:15 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:45:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:45:21 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0019 s/iter. Inference: 0.0656 s/iter. Eval: 0.0003 s/iter. Total: 0.0679 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:45:26 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0645 s/iter. Eval: 0.0003 s/iter. Total: 0.0666 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:45:31 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0018 s/iter. Inference: 0.0648 s/iter. Eval: 0.0003 s/iter. Total: 0.0670 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:45:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.380647 (0.067083 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:45:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064706 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:45:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:45:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:45:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.25s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.426\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.419\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.280\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n\u001b[32m[12/06 15:45:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.666 | 76.875 | 42.604 | 15.855 | 32.232 | 48.225 |\n\u001b[32m[12/06 15:45:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.499 | 1          | 67.110 |\n| 2          | 40.403 | 3          | 29.102 | 4          | 58.212 |\n| 5          | 26.670 |            |        |            |        |\n\u001b[32m[12/06 15:45:34 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:45:34 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6660,76.8751,42.6039,15.8551,32.2324,48.2249\n\u001b[32m[12/06 15:45:34 d2.utils.events]: \u001b[0m eta: 3:39:17  iter: 2519  total_loss: 0.2738  loss_cls: 0.08189  loss_box_reg: 0.184  loss_rpn_cls: 0.004563  loss_rpn_loc: 0.006332  time: 1.1280  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:45:57 d2.utils.events]: \u001b[0m eta: 3:38:54  iter: 2539  total_loss: 0.3055  loss_cls: 0.09238  loss_box_reg: 0.189  loss_rpn_cls: 0.00539  loss_rpn_loc: 0.009062  time: 1.1281  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:46:19 d2.utils.events]: \u001b[0m eta: 3:38:31  iter: 2559  total_loss: 0.2943  loss_cls: 0.08967  loss_box_reg: 0.1993  loss_rpn_cls: 0.003522  loss_rpn_loc: 0.007233  time: 1.1281  data_time: 0.0998  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:46:42 d2.utils.events]: \u001b[0m eta: 3:38:09  iter: 2579  total_loss: 0.2546  loss_cls: 0.08156  loss_box_reg: 0.1528  loss_rpn_cls: 0.005032  loss_rpn_loc: 0.005959  time: 1.1282  data_time: 0.0961  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:47:05 d2.utils.events]: \u001b[0m eta: 3:37:46  iter: 2599  total_loss: 0.266  loss_cls: 0.07909  loss_box_reg: 0.1769  loss_rpn_cls: 0.003177  loss_rpn_loc: 0.006652  time: 1.1282  data_time: 0.0915  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:47:27 d2.utils.events]: \u001b[0m eta: 3:37:21  iter: 2619  total_loss: 0.3133  loss_cls: 0.09355  loss_box_reg: 0.1992  loss_rpn_cls: 0.003914  loss_rpn_loc: 0.006817  time: 1.1281  data_time: 0.0946  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:47:50 d2.utils.events]: \u001b[0m eta: 3:36:58  iter: 2639  total_loss: 0.3064  loss_cls: 0.0962  loss_box_reg: 0.1993  loss_rpn_cls: 0.00388  loss_rpn_loc: 0.006937  time: 1.1282  data_time: 0.0987  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:48:13 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:48:13 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:48:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:48:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:48:13 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:48:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:48:13 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:48:13 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:48:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0019 s/iter. Inference: 0.0656 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0018 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0671 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0019 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:48:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.401328 (0.067158 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:48:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064780 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:48:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:48:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:48:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.24s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.431\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.601\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n\u001b[32m[12/06 15:48:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.469 | 76.782 | 44.731 | 13.596 | 33.556 | 48.686 |\n\u001b[32m[12/06 15:48:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 47.086 | 1          | 69.046 |\n| 2          | 40.219 | 3          | 31.278 | 4          | 58.303 |\n| 5          | 26.885 |            |        |            |        |\n\u001b[32m[12/06 15:48:32 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:48:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:48:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:48:32 d2.evaluation.testing]: \u001b[0mcopypaste: 45.4695,76.7816,44.7310,13.5959,33.5564,48.6856\n\u001b[32m[12/06 15:48:32 d2.utils.events]: \u001b[0m eta: 3:36:37  iter: 2659  total_loss: 0.2559  loss_cls: 0.08081  loss_box_reg: 0.1606  loss_rpn_cls: 0.002426  loss_rpn_loc: 0.007035  time: 1.1283  data_time: 0.0967  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:48:54 d2.utils.events]: \u001b[0m eta: 3:36:13  iter: 2679  total_loss: 0.2495  loss_cls: 0.08859  loss_box_reg: 0.1524  loss_rpn_cls: 0.003365  loss_rpn_loc: 0.005889  time: 1.1282  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:49:17 d2.utils.events]: \u001b[0m eta: 3:35:51  iter: 2699  total_loss: 0.3015  loss_cls: 0.09375  loss_box_reg: 0.1955  loss_rpn_cls: 0.003863  loss_rpn_loc: 0.006892  time: 1.1282  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:49:40 d2.utils.events]: \u001b[0m eta: 3:35:29  iter: 2719  total_loss: 0.2835  loss_cls: 0.08951  loss_box_reg: 0.1788  loss_rpn_cls: 0.00365  loss_rpn_loc: 0.007624  time: 1.1282  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:50:02 d2.utils.events]: \u001b[0m eta: 3:35:07  iter: 2739  total_loss: 0.2526  loss_cls: 0.07213  loss_box_reg: 0.1727  loss_rpn_cls: 0.002638  loss_rpn_loc: 0.005594  time: 1.1282  data_time: 0.0936  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:50:25 d2.utils.events]: \u001b[0m eta: 3:34:47  iter: 2759  total_loss: 0.2892  loss_cls: 0.08951  loss_box_reg: 0.1901  loss_rpn_cls: 0.002531  loss_rpn_loc: 0.005866  time: 1.1284  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:50:47 d2.utils.events]: \u001b[0m eta: 3:34:22  iter: 2779  total_loss: 0.2671  loss_cls: 0.07839  loss_box_reg: 0.1707  loss_rpn_cls: 0.004909  loss_rpn_loc: 0.00635  time: 1.1283  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:51:10 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:51:10 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:51:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:51:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:51:10 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:51:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:51:10 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:51:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:51:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0031 s/iter. Inference: 0.0712 s/iter. Eval: 0.0003 s/iter. Total: 0.0757 s/iter. ETA=0:00:20\n\u001b[32m[12/06 15:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:12\n\u001b[32m[12/06 15:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0021 s/iter. Inference: 0.0658 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:51:26 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0021 s/iter. Inference: 0.0656 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:51:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.573017 (0.067785 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:51:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065256 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:51:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:51:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:51:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.27s).\nAccumulating evaluation results...\nDONE (t=0.12s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.436\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n\u001b[32m[12/06 15:51:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.144 | 77.394 | 43.849 | 13.919 | 32.298 | 48.856 |\n\u001b[32m[12/06 15:51:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.835 | 1          | 67.088 |\n| 2          | 40.173 | 3          | 31.934 | 4          | 58.717 |\n| 5          | 26.119 |            |        |            |        |\n\u001b[32m[12/06 15:51:29 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:51:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:51:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:51:30 d2.evaluation.testing]: \u001b[0mcopypaste: 45.1442,77.3939,43.8494,13.9190,32.2982,48.8561\n\u001b[32m[12/06 15:51:30 d2.utils.events]: \u001b[0m eta: 3:33:59  iter: 2799  total_loss: 0.2624  loss_cls: 0.08732  loss_box_reg: 0.1741  loss_rpn_cls: 0.002502  loss_rpn_loc: 0.006882  time: 1.1282  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:51:52 d2.utils.events]: \u001b[0m eta: 3:33:37  iter: 2819  total_loss: 0.2492  loss_cls: 0.07007  loss_box_reg: 0.1622  loss_rpn_cls: 0.003335  loss_rpn_loc: 0.006441  time: 1.1281  data_time: 0.0881  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:52:14 d2.utils.events]: \u001b[0m eta: 3:33:14  iter: 2839  total_loss: 0.2967  loss_cls: 0.09122  loss_box_reg: 0.1719  loss_rpn_cls: 0.002584  loss_rpn_loc: 0.006034  time: 1.1281  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:52:37 d2.utils.events]: \u001b[0m eta: 3:32:51  iter: 2859  total_loss: 0.2463  loss_cls: 0.07255  loss_box_reg: 0.1554  loss_rpn_cls: 0.00337  loss_rpn_loc: 0.006101  time: 1.1282  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:52:59 d2.utils.events]: \u001b[0m eta: 3:32:27  iter: 2879  total_loss: 0.2754  loss_cls: 0.08407  loss_box_reg: 0.1898  loss_rpn_cls: 0.003448  loss_rpn_loc: 0.007182  time: 1.1280  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:53:21 d2.utils.events]: \u001b[0m eta: 3:32:04  iter: 2899  total_loss: 0.26  loss_cls: 0.08059  loss_box_reg: 0.1694  loss_rpn_cls: 0.003525  loss_rpn_loc: 0.006717  time: 1.1278  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:53:44 d2.utils.events]: \u001b[0m eta: 3:31:40  iter: 2919  total_loss: 0.288  loss_cls: 0.08377  loss_box_reg: 0.1678  loss_rpn_cls: 0.003661  loss_rpn_loc: 0.00666  time: 1.1278  data_time: 0.0964  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:54:06 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:54:06 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:54:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:54:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:54:06 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:54:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:54:06 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:54:06 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:54:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0042 s/iter. Inference: 0.0766 s/iter. Eval: 0.0003 s/iter. Total: 0.0811 s/iter. ETA=0:00:21\n\u001b[32m[12/06 15:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0021 s/iter. Inference: 0.0659 s/iter. Eval: 0.0002 s/iter. Total: 0.0683 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0019 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:07\n\u001b[32m[12/06 15:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0020 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0676 s/iter. ETA=0:00:02\n\u001b[32m[12/06 15:54:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.479383 (0.067443 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:54:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064929 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:54:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:54:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:54:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.23s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.423\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n\u001b[32m[12/06 15:54:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.960 | 77.448 | 43.646 | 13.500 | 32.586 | 48.576 |\n\u001b[32m[12/06 15:54:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.785 | 1          | 68.694 |\n| 2          | 39.438 | 3          | 31.231 | 4          | 59.216 |\n| 5          | 26.397 |            |        |            |        |\n\u001b[32m[12/06 15:54:25 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:54:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:54:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:54:25 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9601,77.4485,43.6459,13.5000,32.5860,48.5761\n\u001b[32m[12/06 15:54:25 d2.utils.events]: \u001b[0m eta: 3:31:18  iter: 2939  total_loss: 0.2739  loss_cls: 0.0861  loss_box_reg: 0.1736  loss_rpn_cls: 0.002566  loss_rpn_loc: 0.006957  time: 1.1276  data_time: 0.0971  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:54:47 d2.utils.events]: \u001b[0m eta: 3:30:53  iter: 2959  total_loss: 0.2966  loss_cls: 0.08814  loss_box_reg: 0.1815  loss_rpn_cls: 0.002301  loss_rpn_loc: 0.007909  time: 1.1275  data_time: 0.0959  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:55:10 d2.utils.events]: \u001b[0m eta: 3:30:29  iter: 2979  total_loss: 0.2489  loss_cls: 0.07755  loss_box_reg: 0.1582  loss_rpn_cls: 0.003036  loss_rpn_loc: 0.00689  time: 1.1275  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:55:33 d2.utils.events]: \u001b[0m eta: 3:30:07  iter: 2999  total_loss: 0.229  loss_cls: 0.06294  loss_box_reg: 0.1577  loss_rpn_cls: 0.001342  loss_rpn_loc: 0.006438  time: 1.1275  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:55:55 d2.utils.events]: \u001b[0m eta: 3:29:44  iter: 3019  total_loss: 0.2509  loss_cls: 0.07478  loss_box_reg: 0.1654  loss_rpn_cls: 0.00161  loss_rpn_loc: 0.005416  time: 1.1275  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:56:18 d2.utils.events]: \u001b[0m eta: 3:29:22  iter: 3039  total_loss: 0.2892  loss_cls: 0.08923  loss_box_reg: 0.1916  loss_rpn_cls: 0.003347  loss_rpn_loc: 0.006907  time: 1.1276  data_time: 0.1017  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:56:41 d2.utils.events]: \u001b[0m eta: 3:29:01  iter: 3059  total_loss: 0.2929  loss_cls: 0.08608  loss_box_reg: 0.1865  loss_rpn_cls: 0.003091  loss_rpn_loc: 0.006974  time: 1.1277  data_time: 0.0979  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:57:03 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 15:57:03 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 15:57:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 15:57:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 15:57:03 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 15:57:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 15:57:03 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:57:03 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 15:57:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 15:57:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 15:57:09 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0025 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0692 s/iter. ETA=0:00:13\n\u001b[32m[12/06 15:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0023 s/iter. Inference: 0.0662 s/iter. Eval: 0.0002 s/iter. Total: 0.0687 s/iter. ETA=0:00:08\n\u001b[32m[12/06 15:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0020 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0676 s/iter. ETA=0:00:03\n\u001b[32m[12/06 15:57:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.463031 (0.067383 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:57:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064912 s / iter per device, on 1 devices)\n\u001b[32m[12/06 15:57:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 15:57:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 15:57:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.45s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.434\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.434\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.632\n\u001b[32m[12/06 15:57:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.315 | 76.518 | 43.393 | 14.000 | 32.883 | 47.842 |\n\u001b[32m[12/06 15:57:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.455 | 1          | 67.025 |\n| 2          | 39.552 | 3          | 29.736 | 4          | 58.503 |\n| 5          | 24.621 |            |        |            |        |\n\u001b[32m[12/06 15:57:23 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 15:57:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 15:57:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 15:57:23 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3153,76.5177,43.3932,14.0000,32.8829,47.8421\n\u001b[32m[12/06 15:57:23 d2.utils.events]: \u001b[0m eta: 3:28:38  iter: 3079  total_loss: 0.24  loss_cls: 0.06972  loss_box_reg: 0.1598  loss_rpn_cls: 0.002759  loss_rpn_loc: 0.007803  time: 1.1276  data_time: 0.0861  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:57:46 d2.utils.events]: \u001b[0m eta: 3:28:16  iter: 3099  total_loss: 0.2645  loss_cls: 0.07607  loss_box_reg: 0.1696  loss_rpn_cls: 0.002383  loss_rpn_loc: 0.006414  time: 1.1277  data_time: 0.0979  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:58:08 d2.utils.events]: \u001b[0m eta: 3:27:53  iter: 3119  total_loss: 0.2321  loss_cls: 0.06657  loss_box_reg: 0.1526  loss_rpn_cls: 0.002645  loss_rpn_loc: 0.006714  time: 1.1277  data_time: 0.0897  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:58:31 d2.utils.events]: \u001b[0m eta: 3:27:29  iter: 3139  total_loss: 0.2646  loss_cls: 0.07879  loss_box_reg: 0.1736  loss_rpn_cls: 0.002262  loss_rpn_loc: 0.006314  time: 1.1277  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:58:53 d2.utils.events]: \u001b[0m eta: 3:27:05  iter: 3159  total_loss: 0.2289  loss_cls: 0.06757  loss_box_reg: 0.1483  loss_rpn_cls: 0.003344  loss_rpn_loc: 0.006004  time: 1.1277  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:59:16 d2.utils.events]: \u001b[0m eta: 3:26:43  iter: 3179  total_loss: 0.2425  loss_cls: 0.07814  loss_box_reg: 0.1613  loss_rpn_cls: 0.002459  loss_rpn_loc: 0.005896  time: 1.1276  data_time: 0.0996  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 15:59:38 d2.utils.events]: \u001b[0m eta: 3:26:20  iter: 3199  total_loss: 0.2644  loss_cls: 0.07869  loss_box_reg: 0.1739  loss_rpn_cls: 0.003181  loss_rpn_loc: 0.006558  time: 1.1276  data_time: 0.0883  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:00:01 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:00:01 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:00:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:00:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:00:01 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:00:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:00:01 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:00:01 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:00:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0651 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0018 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0019 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0676 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:00:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.489473 (0.067480 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:00:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065093 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:00:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:00:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:00:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.39s).\nAccumulating evaluation results...\nDONE (t=0.14s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.429\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.436\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.596\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.596\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n\u001b[32m[12/06 16:00:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.653 | 75.229 | 42.914 | 14.000 | 32.761 | 48.176 |\n\u001b[32m[12/06 16:00:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.212 | 1          | 67.970 |\n| 2          | 38.715 | 3          | 30.918 | 4          | 58.769 |\n| 5          | 26.336 |            |        |            |        |\n\u001b[32m[12/06 16:00:21 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:00:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:00:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:00:21 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6533,75.2288,42.9138,14.0000,32.7611,48.1764\n\u001b[32m[12/06 16:00:21 d2.utils.events]: \u001b[0m eta: 3:25:58  iter: 3219  total_loss: 0.2527  loss_cls: 0.07073  loss_box_reg: 0.1636  loss_rpn_cls: 0.00302  loss_rpn_loc: 0.007448  time: 1.1277  data_time: 0.0945  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:00:43 d2.utils.events]: \u001b[0m eta: 3:25:34  iter: 3239  total_loss: 0.2346  loss_cls: 0.07116  loss_box_reg: 0.1644  loss_rpn_cls: 0.002547  loss_rpn_loc: 0.006732  time: 1.1277  data_time: 0.0896  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:01:06 d2.utils.events]: \u001b[0m eta: 3:25:12  iter: 3259  total_loss: 0.2345  loss_cls: 0.06749  loss_box_reg: 0.1611  loss_rpn_cls: 0.003298  loss_rpn_loc: 0.006022  time: 1.1277  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:01:28 d2.utils.events]: \u001b[0m eta: 3:24:48  iter: 3279  total_loss: 0.2365  loss_cls: 0.06712  loss_box_reg: 0.1558  loss_rpn_cls: 0.003098  loss_rpn_loc: 0.006207  time: 1.1277  data_time: 0.0992  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:01:51 d2.utils.events]: \u001b[0m eta: 3:24:25  iter: 3299  total_loss: 0.234  loss_cls: 0.06251  loss_box_reg: 0.1674  loss_rpn_cls: 0.002464  loss_rpn_loc: 0.005829  time: 1.1277  data_time: 0.0959  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:02:13 d2.utils.events]: \u001b[0m eta: 3:24:02  iter: 3319  total_loss: 0.2446  loss_cls: 0.0704  loss_box_reg: 0.1616  loss_rpn_cls: 0.002879  loss_rpn_loc: 0.006783  time: 1.1276  data_time: 0.0872  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:02:36 d2.utils.events]: \u001b[0m eta: 3:23:37  iter: 3339  total_loss: 0.2825  loss_cls: 0.0873  loss_box_reg: 0.1821  loss_rpn_cls: 0.002432  loss_rpn_loc: 0.006191  time: 1.1277  data_time: 0.1018  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:02:58 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:02:58 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:02:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:02:58 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:02:58 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:02:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:02:58 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:02:58 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:02:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0656 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0019 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:03:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.307114 (0.066814 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:03:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064496 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:03:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:03:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:03:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.446\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.604\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n\u001b[32m[12/06 16:03:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.803 | 76.381 | 45.104 | 15.333 | 31.750 | 49.833 |\n\u001b[32m[12/06 16:03:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 47.815 | 1          | 68.770 |\n| 2          | 38.927 | 3          | 30.233 | 4          | 59.673 |\n| 5          | 29.401 |            |        |            |        |\n\u001b[32m[12/06 16:03:17 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:03:17 d2.evaluation.testing]: \u001b[0mcopypaste: 45.8033,76.3813,45.1036,15.3333,31.7498,49.8333\n\u001b[32m[12/06 16:03:17 d2.utils.events]: \u001b[0m eta: 3:23:15  iter: 3359  total_loss: 0.2704  loss_cls: 0.07706  loss_box_reg: 0.1686  loss_rpn_cls: 0.001465  loss_rpn_loc: 0.006522  time: 1.1276  data_time: 0.0936  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:03:40 d2.utils.events]: \u001b[0m eta: 3:22:51  iter: 3379  total_loss: 0.2364  loss_cls: 0.06934  loss_box_reg: 0.1571  loss_rpn_cls: 0.00241  loss_rpn_loc: 0.006721  time: 1.1276  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:04:02 d2.utils.events]: \u001b[0m eta: 3:22:29  iter: 3399  total_loss: 0.2496  loss_cls: 0.07603  loss_box_reg: 0.1634  loss_rpn_cls: 0.001879  loss_rpn_loc: 0.00592  time: 1.1276  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:04:25 d2.utils.events]: \u001b[0m eta: 3:22:07  iter: 3419  total_loss: 0.2144  loss_cls: 0.06608  loss_box_reg: 0.1385  loss_rpn_cls: 0.001486  loss_rpn_loc: 0.004846  time: 1.1276  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:04:48 d2.utils.events]: \u001b[0m eta: 3:21:43  iter: 3439  total_loss: 0.2851  loss_cls: 0.08543  loss_box_reg: 0.1872  loss_rpn_cls: 0.003297  loss_rpn_loc: 0.007555  time: 1.1276  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:05:10 d2.utils.events]: \u001b[0m eta: 3:21:20  iter: 3459  total_loss: 0.2286  loss_cls: 0.0687  loss_box_reg: 0.1544  loss_rpn_cls: 0.002604  loss_rpn_loc: 0.005917  time: 1.1275  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:05:32 d2.utils.events]: \u001b[0m eta: 3:20:54  iter: 3479  total_loss: 0.1919  loss_cls: 0.05703  loss_box_reg: 0.1293  loss_rpn_cls: 0.001704  loss_rpn_loc: 0.00444  time: 1.1274  data_time: 0.0897  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:05:54 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:05:54 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:05:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:05:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:05:54 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:05:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:05:54 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:05:54 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:05:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 81/279. Dataloading: 0.0028 s/iter. Inference: 0.0682 s/iter. Eval: 0.0002 s/iter. Total: 0.0713 s/iter. ETA=0:00:14\n\u001b[32m[12/06 16:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 154/279. Dataloading: 0.0023 s/iter. Inference: 0.0676 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 230/279. Dataloading: 0.0022 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0689 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:06:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.919744 (0.069050 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:06:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.066314 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:06:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:06:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:06:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.416\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.431\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n\u001b[32m[12/06 16:06:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.924 | 76.132 | 41.590 | 12.429 | 32.739 | 47.668 |\n\u001b[32m[12/06 16:06:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.076 | 1          | 67.431 |\n| 2          | 36.723 | 3          | 29.802 | 4          | 59.485 |\n| 5          | 26.026 |            |        |            |        |\n\u001b[32m[12/06 16:06:14 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:06:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:06:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:06:14 d2.evaluation.testing]: \u001b[0mcopypaste: 43.9239,76.1320,41.5902,12.4286,32.7387,47.6684\n\u001b[32m[12/06 16:06:14 d2.utils.events]: \u001b[0m eta: 3:20:30  iter: 3499  total_loss: 0.2383  loss_cls: 0.06429  loss_box_reg: 0.1601  loss_rpn_cls: 0.002557  loss_rpn_loc: 0.005571  time: 1.1273  data_time: 0.0868  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:06:37 d2.utils.events]: \u001b[0m eta: 3:20:07  iter: 3519  total_loss: 0.2122  loss_cls: 0.05882  loss_box_reg: 0.1494  loss_rpn_cls: 0.002038  loss_rpn_loc: 0.006174  time: 1.1272  data_time: 0.0966  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:06:59 d2.utils.events]: \u001b[0m eta: 3:19:44  iter: 3539  total_loss: 0.2947  loss_cls: 0.0832  loss_box_reg: 0.191  loss_rpn_cls: 0.001914  loss_rpn_loc: 0.007404  time: 1.1273  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:07:22 d2.utils.events]: \u001b[0m eta: 3:19:21  iter: 3559  total_loss: 0.2657  loss_cls: 0.07081  loss_box_reg: 0.1897  loss_rpn_cls: 0.002887  loss_rpn_loc: 0.005722  time: 1.1273  data_time: 0.0970  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:07:45 d2.utils.events]: \u001b[0m eta: 3:19:00  iter: 3579  total_loss: 0.1959  loss_cls: 0.05987  loss_box_reg: 0.1254  loss_rpn_cls: 0.002327  loss_rpn_loc: 0.005193  time: 1.1274  data_time: 0.0945  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:08:08 d2.utils.events]: \u001b[0m eta: 3:18:39  iter: 3599  total_loss: 0.2129  loss_cls: 0.05769  loss_box_reg: 0.1513  loss_rpn_cls: 0.001894  loss_rpn_loc: 0.004506  time: 1.1276  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:08:31 d2.utils.events]: \u001b[0m eta: 3:18:16  iter: 3619  total_loss: 0.2174  loss_cls: 0.06457  loss_box_reg: 0.1535  loss_rpn_cls: 0.001926  loss_rpn_loc: 0.005266  time: 1.1276  data_time: 0.0879  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:08:54 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:08:54 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:08:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:08:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:08:54 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:08:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:08:54 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:08:54 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:08:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 82/279. Dataloading: 0.0023 s/iter. Inference: 0.0681 s/iter. Eval: 0.0002 s/iter. Total: 0.0707 s/iter. ETA=0:00:13\n\u001b[32m[12/06 16:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0019 s/iter. Inference: 0.0659 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 228/279. Dataloading: 0.0023 s/iter. Inference: 0.0669 s/iter. Eval: 0.0002 s/iter. Total: 0.0695 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:09:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.933162 (0.069099 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:09:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.066357 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:09:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:09:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:09:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n\u001b[32m[12/06 16:09:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.123 | 77.473 | 44.323 | 13.867 | 32.932 | 48.654 |\n\u001b[32m[12/06 16:09:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.992 | 1          | 68.921 |\n| 2          | 38.359 | 3          | 30.632 | 4          | 60.524 |\n| 5          | 29.310 |            |        |            |        |\n\u001b[32m[12/06 16:09:13 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: 45.1230,77.4734,44.3229,13.8667,32.9322,48.6544\n\u001b[32m[12/06 16:09:13 d2.utils.events]: \u001b[0m eta: 3:17:55  iter: 3639  total_loss: 0.2239  loss_cls: 0.05991  loss_box_reg: 0.1531  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006014  time: 1.1277  data_time: 0.0978  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:09:36 d2.utils.events]: \u001b[0m eta: 3:17:31  iter: 3659  total_loss: 0.2158  loss_cls: 0.06222  loss_box_reg: 0.1446  loss_rpn_cls: 0.001683  loss_rpn_loc: 0.005495  time: 1.1277  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:09:58 d2.utils.events]: \u001b[0m eta: 3:17:08  iter: 3679  total_loss: 0.2014  loss_cls: 0.05582  loss_box_reg: 0.1372  loss_rpn_cls: 0.001902  loss_rpn_loc: 0.005582  time: 1.1276  data_time: 0.0922  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:10:21 d2.utils.events]: \u001b[0m eta: 3:16:45  iter: 3699  total_loss: 0.2546  loss_cls: 0.07393  loss_box_reg: 0.1725  loss_rpn_cls: 0.001679  loss_rpn_loc: 0.007164  time: 1.1276  data_time: 0.0987  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:10:43 d2.utils.events]: \u001b[0m eta: 3:16:21  iter: 3719  total_loss: 0.2259  loss_cls: 0.06414  loss_box_reg: 0.1496  loss_rpn_cls: 0.002017  loss_rpn_loc: 0.005084  time: 1.1276  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:11:05 d2.utils.events]: \u001b[0m eta: 3:15:56  iter: 3739  total_loss: 0.2504  loss_cls: 0.07372  loss_box_reg: 0.1692  loss_rpn_cls: 0.002033  loss_rpn_loc: 0.006717  time: 1.1275  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:11:28 d2.utils.events]: \u001b[0m eta: 3:15:32  iter: 3759  total_loss: 0.2085  loss_cls: 0.07178  loss_box_reg: 0.1421  loss_rpn_cls: 0.002204  loss_rpn_loc: 0.006387  time: 1.1276  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:11:51 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:11:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:11:51 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:11:51 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:11:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:11:51 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:11:51 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:11:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0020 s/iter. Inference: 0.0658 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:13\n\u001b[32m[12/06 16:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0019 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0020 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0674 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:12:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.428377 (0.067257 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:12:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064769 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:12:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:12:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:12:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.424\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.436\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n\u001b[32m[12/06 16:12:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.825 | 76.093 | 42.405 | 17.000 | 30.021 | 49.065 |\n\u001b[32m[12/06 16:12:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 47.381 | 1          | 66.612 |\n| 2          | 38.119 | 3          | 30.042 | 4          | 59.046 |\n| 5          | 27.750 |            |        |            |        |\n\u001b[32m[12/06 16:12:11 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:12:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:12:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:12:11 d2.evaluation.testing]: \u001b[0mcopypaste: 44.8248,76.0933,42.4054,17.0000,30.0209,49.0648\n\u001b[32m[12/06 16:12:11 d2.utils.events]: \u001b[0m eta: 3:15:12  iter: 3779  total_loss: 0.2193  loss_cls: 0.06322  loss_box_reg: 0.1456  loss_rpn_cls: 0.002421  loss_rpn_loc: 0.005322  time: 1.1277  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:12:33 d2.utils.events]: \u001b[0m eta: 3:14:49  iter: 3799  total_loss: 0.2206  loss_cls: 0.06438  loss_box_reg: 0.1503  loss_rpn_cls: 0.001292  loss_rpn_loc: 0.005794  time: 1.1278  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:12:56 d2.utils.events]: \u001b[0m eta: 3:14:27  iter: 3819  total_loss: 0.2361  loss_cls: 0.07042  loss_box_reg: 0.1497  loss_rpn_cls: 0.003075  loss_rpn_loc: 0.005852  time: 1.1277  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:13:18 d2.utils.events]: \u001b[0m eta: 3:14:04  iter: 3839  total_loss: 0.2116  loss_cls: 0.05897  loss_box_reg: 0.1454  loss_rpn_cls: 0.002261  loss_rpn_loc: 0.005005  time: 1.1277  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:13:40 d2.utils.events]: \u001b[0m eta: 3:13:40  iter: 3859  total_loss: 0.2202  loss_cls: 0.06437  loss_box_reg: 0.1492  loss_rpn_cls: 0.001618  loss_rpn_loc: 0.005649  time: 1.1276  data_time: 0.0881  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:14:02 d2.utils.events]: \u001b[0m eta: 3:13:17  iter: 3879  total_loss: 0.2273  loss_cls: 0.06753  loss_box_reg: 0.1576  loss_rpn_cls: 0.001831  loss_rpn_loc: 0.006907  time: 1.1274  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:14:25 d2.utils.events]: \u001b[0m eta: 3:12:55  iter: 3899  total_loss: 0.2165  loss_cls: 0.0598  loss_box_reg: 0.1426  loss_rpn_cls: 0.00216  loss_rpn_loc: 0.005931  time: 1.1275  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:14:48 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:14:48 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:14:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:14:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:14:48 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:14:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:14:48 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:14:48 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:14:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0017 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0655 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 79/279. Dataloading: 0.0029 s/iter. Inference: 0.0701 s/iter. Eval: 0.0002 s/iter. Total: 0.0733 s/iter. ETA=0:00:14\n\u001b[32m[12/06 16:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 155/279. Dataloading: 0.0023 s/iter. Inference: 0.0671 s/iter. Eval: 0.0002 s/iter. Total: 0.0697 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 229/279. Dataloading: 0.0022 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0690 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.789281 (0.068574 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065941 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:15:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:15:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:15:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.44s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.485\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.436\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n\u001b[32m[12/06 16:15:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.168 | 77.023 | 42.322 | 17.167 | 33.958 | 48.543 |\n\u001b[32m[12/06 16:15:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.630 | 1          | 67.478 |\n| 2          | 38.628 | 3          | 31.412 | 4          | 58.961 |\n| 5          | 28.899 |            |        |            |        |\n\u001b[32m[12/06 16:15:08 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:15:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:15:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:15:08 d2.evaluation.testing]: \u001b[0mcopypaste: 45.1680,77.0227,42.3222,17.1667,33.9578,48.5429\n\u001b[32m[12/06 16:15:08 d2.utils.events]: \u001b[0m eta: 3:12:33  iter: 3919  total_loss: 0.2136  loss_cls: 0.06084  loss_box_reg: 0.1465  loss_rpn_cls: 0.001944  loss_rpn_loc: 0.005522  time: 1.1275  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:15:30 d2.utils.events]: \u001b[0m eta: 3:12:10  iter: 3939  total_loss: 0.2017  loss_cls: 0.05759  loss_box_reg: 0.1376  loss_rpn_cls: 0.001698  loss_rpn_loc: 0.006413  time: 1.1276  data_time: 0.0960  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:15:53 d2.utils.events]: \u001b[0m eta: 3:11:48  iter: 3959  total_loss: 0.2098  loss_cls: 0.05666  loss_box_reg: 0.1396  loss_rpn_cls: 0.001433  loss_rpn_loc: 0.005754  time: 1.1276  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:16:16 d2.utils.events]: \u001b[0m eta: 3:11:26  iter: 3979  total_loss: 0.202  loss_cls: 0.06292  loss_box_reg: 0.1381  loss_rpn_cls: 0.001217  loss_rpn_loc: 0.005515  time: 1.1276  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:16:38 d2.utils.events]: \u001b[0m eta: 3:11:03  iter: 3999  total_loss: 0.211  loss_cls: 0.06202  loss_box_reg: 0.1526  loss_rpn_cls: 0.002363  loss_rpn_loc: 0.005481  time: 1.1276  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:17:01 d2.utils.events]: \u001b[0m eta: 3:10:40  iter: 4019  total_loss: 0.2396  loss_cls: 0.06819  loss_box_reg: 0.158  loss_rpn_cls: 0.00231  loss_rpn_loc: 0.005686  time: 1.1276  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:17:23 d2.utils.events]: \u001b[0m eta: 3:10:15  iter: 4039  total_loss: 0.2318  loss_cls: 0.06472  loss_box_reg: 0.1597  loss_rpn_cls: 0.002608  loss_rpn_loc: 0.006044  time: 1.1276  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:17:46 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:17:46 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:17:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:17:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:17:46 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:17:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:17:46 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:17:46 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:17:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0055 s/iter. Inference: 0.0754 s/iter. Eval: 0.0003 s/iter. Total: 0.0812 s/iter. ETA=0:00:21\n\u001b[32m[12/06 16:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0021 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:13\n\u001b[32m[12/06 16:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0018 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 231/279. Dataloading: 0.0020 s/iter. Inference: 0.0665 s/iter. Eval: 0.0003 s/iter. Total: 0.0689 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:18:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.748124 (0.068424 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:18:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065914 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:18:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:18:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:18:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.458\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.439\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n\u001b[32m[12/06 16:18:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.993 | 76.914 | 45.804 | 18.000 | 34.661 | 49.185 |\n\u001b[32m[12/06 16:18:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 49.236 | 1          | 71.235 |\n| 2          | 38.199 | 3          | 29.319 | 4          | 60.462 |\n| 5          | 27.507 |            |        |            |        |\n\u001b[32m[12/06 16:18:06 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:18:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:18:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:18:06 d2.evaluation.testing]: \u001b[0mcopypaste: 45.9928,76.9137,45.8036,18.0000,34.6612,49.1851\n\u001b[32m[12/06 16:18:06 d2.utils.events]: \u001b[0m eta: 3:09:52  iter: 4059  total_loss: 0.2136  loss_cls: 0.05771  loss_box_reg: 0.1378  loss_rpn_cls: 0.0019  loss_rpn_loc: 0.005665  time: 1.1277  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:18:29 d2.utils.events]: \u001b[0m eta: 3:09:29  iter: 4079  total_loss: 0.1779  loss_cls: 0.05238  loss_box_reg: 0.1213  loss_rpn_cls: 0.001245  loss_rpn_loc: 0.005214  time: 1.1277  data_time: 0.0865  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:18:51 d2.utils.events]: \u001b[0m eta: 3:09:05  iter: 4099  total_loss: 0.2261  loss_cls: 0.06127  loss_box_reg: 0.157  loss_rpn_cls: 0.001048  loss_rpn_loc: 0.005694  time: 1.1278  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:19:14 d2.utils.events]: \u001b[0m eta: 3:08:40  iter: 4119  total_loss: 0.2413  loss_cls: 0.06877  loss_box_reg: 0.1616  loss_rpn_cls: 0.001761  loss_rpn_loc: 0.006477  time: 1.1277  data_time: 0.0888  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:19:37 d2.utils.events]: \u001b[0m eta: 3:08:18  iter: 4139  total_loss: 0.2024  loss_cls: 0.05683  loss_box_reg: 0.132  loss_rpn_cls: 0.00166  loss_rpn_loc: 0.005011  time: 1.1278  data_time: 0.0961  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:19:59 d2.utils.events]: \u001b[0m eta: 3:07:56  iter: 4159  total_loss: 0.2256  loss_cls: 0.0635  loss_box_reg: 0.1557  loss_rpn_cls: 0.001889  loss_rpn_loc: 0.005707  time: 1.1278  data_time: 0.0900  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:20:22 d2.utils.events]: \u001b[0m eta: 3:07:33  iter: 4179  total_loss: 0.2342  loss_cls: 0.06632  loss_box_reg: 0.162  loss_rpn_cls: 0.001251  loss_rpn_loc: 0.006022  time: 1.1278  data_time: 0.0959  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:20:44 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:20:44 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:20:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:20:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:20:44 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:20:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:20:44 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:20:44 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:20:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:20:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0645 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0018 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0018 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:21:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.221111 (0.066500 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:21:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064186 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:21:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:21:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:21:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.433\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.581\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n\u001b[32m[12/06 16:21:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.267 | 76.888 | 44.214 | 16.000 | 32.179 | 48.030 |\n\u001b[32m[12/06 16:21:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.974 | 1          | 68.656 |\n| 2          | 38.269 | 3          | 30.125 | 4          | 58.609 |\n| 5          | 25.971 |            |        |            |        |\n\u001b[32m[12/06 16:21:03 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:21:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:21:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:21:03 d2.evaluation.testing]: \u001b[0mcopypaste: 44.2673,76.8882,44.2136,16.0000,32.1785,48.0301\n\u001b[32m[12/06 16:21:03 d2.utils.events]: \u001b[0m eta: 3:07:09  iter: 4199  total_loss: 0.2086  loss_cls: 0.05846  loss_box_reg: 0.1381  loss_rpn_cls: 0.001498  loss_rpn_loc: 0.0065  time: 1.1277  data_time: 0.0901  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:21:25 d2.utils.events]: \u001b[0m eta: 3:06:45  iter: 4219  total_loss: 0.2078  loss_cls: 0.05941  loss_box_reg: 0.1416  loss_rpn_cls: 0.001436  loss_rpn_loc: 0.00528  time: 1.1277  data_time: 0.0994  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:21:48 d2.utils.events]: \u001b[0m eta: 3:06:23  iter: 4239  total_loss: 0.1827  loss_cls: 0.05105  loss_box_reg: 0.124  loss_rpn_cls: 0.001672  loss_rpn_loc: 0.006319  time: 1.1277  data_time: 0.0969  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:22:11 d2.utils.events]: \u001b[0m eta: 3:05:57  iter: 4259  total_loss: 0.2203  loss_cls: 0.05309  loss_box_reg: 0.1627  loss_rpn_cls: 0.001436  loss_rpn_loc: 0.005579  time: 1.1276  data_time: 0.0958  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:22:32 d2.utils.events]: \u001b[0m eta: 3:05:33  iter: 4279  total_loss: 0.1939  loss_cls: 0.05273  loss_box_reg: 0.1331  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.005847  time: 1.1275  data_time: 0.0866  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:22:55 d2.utils.events]: \u001b[0m eta: 3:05:10  iter: 4299  total_loss: 0.2175  loss_cls: 0.05805  loss_box_reg: 0.1458  loss_rpn_cls: 0.001447  loss_rpn_loc: 0.005221  time: 1.1275  data_time: 0.0931  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:23:18 d2.utils.events]: \u001b[0m eta: 3:04:50  iter: 4319  total_loss: 0.2241  loss_cls: 0.06008  loss_box_reg: 0.1554  loss_rpn_cls: 0.001784  loss_rpn_loc: 0.004769  time: 1.1276  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:23:41 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:23:41 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:23:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:23:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:23:41 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:23:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:23:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:23:41 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:23:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:23:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:23:47 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0023 s/iter. Inference: 0.0669 s/iter. Eval: 0.0002 s/iter. Total: 0.0695 s/iter. ETA=0:00:13\n\u001b[32m[12/06 16:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 156/279. Dataloading: 0.0022 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0020 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:24:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.535182 (0.067647 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:24:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065180 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:24:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:24:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:24:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n\u001b[32m[12/06 16:24:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.926 | 76.028 | 44.976 | 20.000 | 31.867 | 48.815 |\n\u001b[32m[12/06 16:24:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.405 | 1          | 69.362 |\n| 2          | 39.285 | 3          | 29.264 | 4          | 59.291 |\n| 5          | 26.947 |            |        |            |        |\n\u001b[32m[12/06 16:24:00 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:24:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:24:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:24:00 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9256,76.0276,44.9764,20.0000,31.8670,48.8150\n\u001b[32m[12/06 16:24:00 d2.utils.events]: \u001b[0m eta: 3:04:28  iter: 4339  total_loss: 0.1895  loss_cls: 0.05302  loss_box_reg: 0.1372  loss_rpn_cls: 0.001614  loss_rpn_loc: 0.005477  time: 1.1277  data_time: 0.0882  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:24:23 d2.utils.events]: \u001b[0m eta: 3:04:04  iter: 4359  total_loss: 0.207  loss_cls: 0.05912  loss_box_reg: 0.1438  loss_rpn_cls: 0.0008643  loss_rpn_loc: 0.005092  time: 1.1276  data_time: 0.0911  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:24:45 d2.utils.events]: \u001b[0m eta: 3:03:41  iter: 4379  total_loss: 0.1888  loss_cls: 0.0515  loss_box_reg: 0.1266  loss_rpn_cls: 0.001103  loss_rpn_loc: 0.00495  time: 1.1277  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:25:08 d2.utils.events]: \u001b[0m eta: 3:03:17  iter: 4399  total_loss: 0.2032  loss_cls: 0.05508  loss_box_reg: 0.1395  loss_rpn_cls: 0.001743  loss_rpn_loc: 0.007185  time: 1.1277  data_time: 0.0976  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:25:31 d2.utils.events]: \u001b[0m eta: 3:02:52  iter: 4419  total_loss: 0.202  loss_cls: 0.05799  loss_box_reg: 0.1409  loss_rpn_cls: 0.001003  loss_rpn_loc: 0.004587  time: 1.1277  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:25:53 d2.utils.events]: \u001b[0m eta: 3:02:29  iter: 4439  total_loss: 0.1952  loss_cls: 0.04871  loss_box_reg: 0.1383  loss_rpn_cls: 0.001757  loss_rpn_loc: 0.005783  time: 1.1276  data_time: 0.0896  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:26:16 d2.utils.events]: \u001b[0m eta: 3:02:06  iter: 4459  total_loss: 0.2055  loss_cls: 0.06086  loss_box_reg: 0.1344  loss_rpn_cls: 0.0008714  loss_rpn_loc: 0.005688  time: 1.1277  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:26:39 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:26:39 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:26:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:26:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:26:39 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:26:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:26:39 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:26:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:26:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0019 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0020 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0020 s/iter. Inference: 0.0653 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.599869 (0.067883 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:26:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065310 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:26:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:26:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:26:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.19s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.463\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n\u001b[32m[12/06 16:26:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.160 | 76.951 | 46.265 | 16.667 | 33.346 | 50.249 |\n\u001b[32m[12/06 16:26:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.163 | 1          | 68.826 |\n| 2          | 40.956 | 3          | 30.632 | 4          | 60.869 |\n| 5          | 29.514 |            |        |            |        |\n\u001b[32m[12/06 16:26:58 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:26:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:26:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:26:58 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1598,76.9507,46.2652,16.6667,33.3463,50.2490\n\u001b[32m[12/06 16:26:58 d2.utils.events]: \u001b[0m eta: 3:01:44  iter: 4479  total_loss: 0.1924  loss_cls: 0.05189  loss_box_reg: 0.1344  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.005243  time: 1.1277  data_time: 0.0962  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:27:20 d2.utils.events]: \u001b[0m eta: 3:01:21  iter: 4499  total_loss: 0.2095  loss_cls: 0.05454  loss_box_reg: 0.1428  loss_rpn_cls: 0.001041  loss_rpn_loc: 0.006201  time: 1.1277  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:27:43 d2.utils.events]: \u001b[0m eta: 3:00:58  iter: 4519  total_loss: 0.2149  loss_cls: 0.05676  loss_box_reg: 0.1444  loss_rpn_cls: 0.001125  loss_rpn_loc: 0.005703  time: 1.1277  data_time: 0.0971  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:28:05 d2.utils.events]: \u001b[0m eta: 3:00:35  iter: 4539  total_loss: 0.1824  loss_cls: 0.05545  loss_box_reg: 0.1268  loss_rpn_cls: 0.001997  loss_rpn_loc: 0.004906  time: 1.1277  data_time: 0.0993  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:28:28 d2.utils.events]: \u001b[0m eta: 3:00:12  iter: 4559  total_loss: 0.181  loss_cls: 0.05113  loss_box_reg: 0.124  loss_rpn_cls: 0.001187  loss_rpn_loc: 0.004988  time: 1.1276  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:28:51 d2.utils.events]: \u001b[0m eta: 2:59:48  iter: 4579  total_loss: 0.2248  loss_cls: 0.06565  loss_box_reg: 0.1455  loss_rpn_cls: 0.001709  loss_rpn_loc: 0.007605  time: 1.1277  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:29:13 d2.utils.events]: \u001b[0m eta: 2:59:24  iter: 4599  total_loss: 0.2075  loss_cls: 0.05672  loss_box_reg: 0.1469  loss_rpn_cls: 0.001215  loss_rpn_loc: 0.005005  time: 1.1277  data_time: 0.0931  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:29:36 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:29:36 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:29:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:29:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:29:36 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:29:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:29:36 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:29:36 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:29:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:29:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.325536 (0.066882 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:29:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064438 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:29:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:29:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:29:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.445\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n\u001b[32m[12/06 16:29:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.931 | 76.070 | 44.521 | 17.000 | 32.950 | 48.757 |\n\u001b[32m[12/06 16:29:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.011 | 1          | 70.228 |\n| 2          | 39.968 | 3          | 27.774 | 4          | 60.358 |\n| 5          | 27.249 |            |        |            |        |\n\u001b[32m[12/06 16:29:55 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9314,76.0698,44.5210,17.0000,32.9501,48.7573\n\u001b[32m[12/06 16:29:55 d2.utils.events]: \u001b[0m eta: 2:59:01  iter: 4619  total_loss: 0.1747  loss_cls: 0.04439  loss_box_reg: 0.1223  loss_rpn_cls: 0.001386  loss_rpn_loc: 0.004386  time: 1.1277  data_time: 0.0974  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:30:18 d2.utils.events]: \u001b[0m eta: 2:58:37  iter: 4639  total_loss: 0.1967  loss_cls: 0.05458  loss_box_reg: 0.1332  loss_rpn_cls: 0.00131  loss_rpn_loc: 0.005097  time: 1.1277  data_time: 0.0956  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:30:41 d2.utils.events]: \u001b[0m eta: 2:58:15  iter: 4659  total_loss: 0.2039  loss_cls: 0.05446  loss_box_reg: 0.1394  loss_rpn_cls: 0.00148  loss_rpn_loc: 0.005896  time: 1.1278  data_time: 0.1001  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:31:04 d2.utils.events]: \u001b[0m eta: 2:57:53  iter: 4679  total_loss: 0.1813  loss_cls: 0.04956  loss_box_reg: 0.1238  loss_rpn_cls: 0.001204  loss_rpn_loc: 0.005532  time: 1.1279  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:31:26 d2.utils.events]: \u001b[0m eta: 2:57:30  iter: 4699  total_loss: 0.1893  loss_cls: 0.0524  loss_box_reg: 0.128  loss_rpn_cls: 0.00134  loss_rpn_loc: 0.00529  time: 1.1278  data_time: 0.0883  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:31:49 d2.utils.events]: \u001b[0m eta: 2:57:07  iter: 4719  total_loss: 0.1903  loss_cls: 0.05475  loss_box_reg: 0.1279  loss_rpn_cls: 0.001699  loss_rpn_loc: 0.005069  time: 1.1279  data_time: 0.0961  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:32:12 d2.utils.events]: \u001b[0m eta: 2:56:45  iter: 4739  total_loss: 0.1869  loss_cls: 0.0533  loss_box_reg: 0.1309  loss_rpn_cls: 0.0009558  loss_rpn_loc: 0.005654  time: 1.1281  data_time: 0.0986  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:32:35 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:32:35 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:32:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:32:35 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:32:35 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:32:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:32:35 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:32:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:32:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:32:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0026 s/iter. Inference: 0.0798 s/iter. Eval: 0.0003 s/iter. Total: 0.0826 s/iter. ETA=0:00:22\n\u001b[32m[12/06 16:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 84/279. Dataloading: 0.0024 s/iter. Inference: 0.0671 s/iter. Eval: 0.0002 s/iter. Total: 0.0699 s/iter. ETA=0:00:13\n\u001b[32m[12/06 16:32:46 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0021 s/iter. Inference: 0.0658 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0020 s/iter. Inference: 0.0656 s/iter. Eval: 0.0002 s/iter. Total: 0.0679 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.563089 (0.067748 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:32:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065305 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:32:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:32:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:32:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.19s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.449\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n\u001b[32m[12/06 16:32:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.161 | 75.770 | 45.063 | 17.667 | 32.463 | 49.131 |\n\u001b[32m[12/06 16:32:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.187 | 1          | 70.877 |\n| 2          | 39.428 | 3          | 29.432 | 4          | 60.174 |\n| 5          | 25.870 |            |        |            |        |\n\u001b[32m[12/06 16:32:54 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:32:54 d2.evaluation.testing]: \u001b[0mcopypaste: 45.1613,75.7701,45.0628,17.6667,32.4631,49.1313\n\u001b[32m[12/06 16:32:54 d2.utils.events]: \u001b[0m eta: 2:56:22  iter: 4759  total_loss: 0.1983  loss_cls: 0.05401  loss_box_reg: 0.1384  loss_rpn_cls: 0.0008942  loss_rpn_loc: 0.005491  time: 1.1281  data_time: 0.0917  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:33:17 d2.utils.events]: \u001b[0m eta: 2:55:58  iter: 4779  total_loss: 0.179  loss_cls: 0.05085  loss_box_reg: 0.1235  loss_rpn_cls: 0.0009622  loss_rpn_loc: 0.004488  time: 1.1280  data_time: 0.0890  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:33:39 d2.utils.events]: \u001b[0m eta: 2:55:35  iter: 4799  total_loss: 0.2263  loss_cls: 0.06447  loss_box_reg: 0.1539  loss_rpn_cls: 0.00164  loss_rpn_loc: 0.006331  time: 1.1280  data_time: 0.0987  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:34:01 d2.utils.events]: \u001b[0m eta: 2:55:12  iter: 4819  total_loss: 0.1704  loss_cls: 0.04198  loss_box_reg: 0.1186  loss_rpn_cls: 0.001116  loss_rpn_loc: 0.004517  time: 1.1280  data_time: 0.0867  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:34:24 d2.utils.events]: \u001b[0m eta: 2:54:49  iter: 4839  total_loss: 0.1734  loss_cls: 0.04455  loss_box_reg: 0.1198  loss_rpn_cls: 0.001368  loss_rpn_loc: 0.005579  time: 1.1280  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:34:47 d2.utils.events]: \u001b[0m eta: 2:54:27  iter: 4859  total_loss: 0.1816  loss_cls: 0.05081  loss_box_reg: 0.1274  loss_rpn_cls: 0.00082  loss_rpn_loc: 0.005303  time: 1.1280  data_time: 0.0892  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:35:09 d2.utils.events]: \u001b[0m eta: 2:54:04  iter: 4879  total_loss: 0.2085  loss_cls: 0.0524  loss_box_reg: 0.1449  loss_rpn_cls: 0.001221  loss_rpn_loc: 0.006694  time: 1.1280  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:35:32 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:35:32 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:35:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:35:32 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:35:32 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:35:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:35:32 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:35:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:35:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:35:38 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0018 s/iter. Inference: 0.0649 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:35:43 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0666 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0021 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0680 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:35:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.582214 (0.067818 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:35:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065278 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:35:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:35:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:35:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.446\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.450\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n\u001b[32m[12/06 16:35:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.590 | 76.678 | 44.595 | 17.000 | 33.570 | 49.392 |\n\u001b[32m[12/06 16:35:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.229 | 1          | 70.786 |\n| 2          | 40.672 | 3          | 28.423 | 4          | 60.203 |\n| 5          | 27.226 |            |        |            |        |\n\u001b[32m[12/06 16:35:51 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:35:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:35:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:35:51 d2.evaluation.testing]: \u001b[0mcopypaste: 45.5898,76.6784,44.5948,17.0000,33.5704,49.3919\n\u001b[32m[12/06 16:35:51 d2.utils.events]: \u001b[0m eta: 2:53:41  iter: 4899  total_loss: 0.2007  loss_cls: 0.05299  loss_box_reg: 0.1412  loss_rpn_cls: 0.001241  loss_rpn_loc: 0.004999  time: 1.1280  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:36:14 d2.utils.events]: \u001b[0m eta: 2:53:18  iter: 4919  total_loss: 0.1715  loss_cls: 0.04636  loss_box_reg: 0.1215  loss_rpn_cls: 0.0004581  loss_rpn_loc: 0.005265  time: 1.1280  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:36:37 d2.utils.events]: \u001b[0m eta: 2:52:55  iter: 4939  total_loss: 0.1781  loss_cls: 0.05177  loss_box_reg: 0.1216  loss_rpn_cls: 0.0009236  loss_rpn_loc: 0.005473  time: 1.1280  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:36:59 d2.utils.events]: \u001b[0m eta: 2:52:32  iter: 4959  total_loss: 0.1801  loss_cls: 0.05108  loss_box_reg: 0.1242  loss_rpn_cls: 0.001159  loss_rpn_loc: 0.005677  time: 1.1280  data_time: 0.0959  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:37:21 d2.utils.events]: \u001b[0m eta: 2:52:08  iter: 4979  total_loss: 0.2031  loss_cls: 0.05376  loss_box_reg: 0.144  loss_rpn_cls: 0.001801  loss_rpn_loc: 0.007227  time: 1.1280  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:37:45 d2.utils.events]: \u001b[0m eta: 2:51:46  iter: 4999  total_loss: 0.1789  loss_cls: 0.04746  loss_box_reg: 0.1235  loss_rpn_cls: 0.001227  loss_rpn_loc: 0.005155  time: 1.1279  data_time: 0.0874  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:38:07 d2.utils.events]: \u001b[0m eta: 2:51:22  iter: 5019  total_loss: 0.19  loss_cls: 0.05281  loss_box_reg: 0.1348  loss_rpn_cls: 0.0007062  loss_rpn_loc: 0.005034  time: 1.1279  data_time: 0.0982  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:38:30 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:38:30 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:38:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:38:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:38:30 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:38:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:38:30 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:38:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:38:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0078 s/iter. Inference: 0.0670 s/iter. Eval: 0.0003 s/iter. Total: 0.0750 s/iter. ETA=0:00:20\n\u001b[32m[12/06 16:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0020 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0019 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0660 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:38:46 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0018 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:38:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.150020 (0.066241 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:38:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063945 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:38:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:38:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:38:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.16s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.446\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n\u001b[32m[12/06 16:38:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.339 | 76.946 | 44.155 | 17.000 | 32.733 | 49.558 |\n\u001b[32m[12/06 16:38:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.748 | 1          | 70.363 |\n| 2          | 38.743 | 3          | 30.056 | 4          | 58.305 |\n| 5          | 28.819 |            |        |            |        |\n\u001b[32m[12/06 16:38:49 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:38:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:38:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:38:49 d2.evaluation.testing]: \u001b[0mcopypaste: 45.3389,76.9463,44.1549,17.0000,32.7334,49.5583\n\u001b[32m[12/06 16:38:49 d2.utils.events]: \u001b[0m eta: 2:51:00  iter: 5039  total_loss: 0.1904  loss_cls: 0.052  loss_box_reg: 0.129  loss_rpn_cls: 0.001065  loss_rpn_loc: 0.005037  time: 1.1280  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:39:12 d2.utils.events]: \u001b[0m eta: 2:50:36  iter: 5059  total_loss: 0.1925  loss_cls: 0.04741  loss_box_reg: 0.1391  loss_rpn_cls: 0.0007812  loss_rpn_loc: 0.00513  time: 1.1280  data_time: 0.0989  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:39:35 d2.utils.events]: \u001b[0m eta: 2:50:14  iter: 5079  total_loss: 0.164  loss_cls: 0.04558  loss_box_reg: 0.1171  loss_rpn_cls: 0.0006865  loss_rpn_loc: 0.004844  time: 1.1281  data_time: 0.0969  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:39:57 d2.utils.events]: \u001b[0m eta: 2:49:51  iter: 5099  total_loss: 0.174  loss_cls: 0.04976  loss_box_reg: 0.1223  loss_rpn_cls: 0.001063  loss_rpn_loc: 0.005825  time: 1.1281  data_time: 0.0993  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:40:20 d2.utils.events]: \u001b[0m eta: 2:49:28  iter: 5119  total_loss: 0.2047  loss_cls: 0.05671  loss_box_reg: 0.1374  loss_rpn_cls: 0.002068  loss_rpn_loc: 0.00652  time: 1.1281  data_time: 0.0894  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:40:43 d2.utils.events]: \u001b[0m eta: 2:49:05  iter: 5139  total_loss: 0.1621  loss_cls: 0.03885  loss_box_reg: 0.1109  loss_rpn_cls: 0.0008261  loss_rpn_loc: 0.003642  time: 1.1281  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:41:05 d2.utils.events]: \u001b[0m eta: 2:48:41  iter: 5159  total_loss: 0.1926  loss_cls: 0.05312  loss_box_reg: 0.133  loss_rpn_cls: 0.000649  loss_rpn_loc: 0.004931  time: 1.1281  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:41:28 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:41:28 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:41:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:41:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:41:28 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:41:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:41:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0020 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0022 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0669 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0020 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:41:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.207828 (0.066452 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:41:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064025 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:41:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:41:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:41:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.453\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.450\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n\u001b[32m[12/06 16:41:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.384 | 76.968 | 45.264 | 17.000 | 30.667 | 50.237 |\n\u001b[32m[12/06 16:41:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.752 | 1          | 69.151 |\n| 2          | 41.144 | 3          | 27.699 | 4          | 60.659 |\n| 5          | 27.902 |            |        |            |        |\n\u001b[32m[12/06 16:41:47 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: 45.3844,76.9681,45.2638,17.0000,30.6671,50.2366\n\u001b[32m[12/06 16:41:47 d2.utils.events]: \u001b[0m eta: 2:48:18  iter: 5179  total_loss: 0.1683  loss_cls: 0.0434  loss_box_reg: 0.1225  loss_rpn_cls: 0.0008289  loss_rpn_loc: 0.004486  time: 1.1281  data_time: 0.0921  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:42:10 d2.utils.events]: \u001b[0m eta: 2:47:55  iter: 5199  total_loss: 0.1966  loss_cls: 0.05019  loss_box_reg: 0.1375  loss_rpn_cls: 0.0006352  loss_rpn_loc: 0.004909  time: 1.1281  data_time: 0.0990  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:42:32 d2.utils.events]: \u001b[0m eta: 2:47:31  iter: 5219  total_loss: 0.204  loss_cls: 0.05038  loss_box_reg: 0.1479  loss_rpn_cls: 0.001116  loss_rpn_loc: 0.005257  time: 1.1281  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:42:54 d2.utils.events]: \u001b[0m eta: 2:47:07  iter: 5239  total_loss: 0.1784  loss_cls: 0.04586  loss_box_reg: 0.1237  loss_rpn_cls: 0.001075  loss_rpn_loc: 0.005485  time: 1.1280  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:43:17 d2.utils.events]: \u001b[0m eta: 2:46:45  iter: 5259  total_loss: 0.1928  loss_cls: 0.05636  loss_box_reg: 0.1359  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.005497  time: 1.1280  data_time: 0.0936  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:43:39 d2.utils.events]: \u001b[0m eta: 2:46:22  iter: 5279  total_loss: 0.1782  loss_cls: 0.04493  loss_box_reg: 0.1257  loss_rpn_cls: 0.0009978  loss_rpn_loc: 0.006592  time: 1.1280  data_time: 0.0965  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:44:02 d2.utils.events]: \u001b[0m eta: 2:45:59  iter: 5299  total_loss: 0.1899  loss_cls: 0.05289  loss_box_reg: 0.1244  loss_rpn_cls: 0.0009786  loss_rpn_loc: 0.005119  time: 1.1280  data_time: 0.0892  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:44:24 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:44:24 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:44:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:44:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:44:24 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:44:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:44:24 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:44:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:44:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0020 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:44:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.422367 (0.067235 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:44:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064732 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:44:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:44:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:44:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.430\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.426\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n\u001b[32m[12/06 16:44:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.800 | 75.313 | 43.025 | 26.000 | 31.240 | 47.777 |\n\u001b[32m[12/06 16:44:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.504 | 1          | 69.475 |\n| 2          | 39.028 | 3          | 25.700 | 4          | 60.230 |\n| 5          | 24.865 |            |        |            |        |\n\u001b[32m[12/06 16:44:44 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:44:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:44:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:44:44 d2.evaluation.testing]: \u001b[0mcopypaste: 43.8003,75.3125,43.0252,26.0000,31.2403,47.7765\n\u001b[32m[12/06 16:44:44 d2.utils.events]: \u001b[0m eta: 2:45:34  iter: 5319  total_loss: 0.1573  loss_cls: 0.037  loss_box_reg: 0.1096  loss_rpn_cls: 0.0009166  loss_rpn_loc: 0.005491  time: 1.1279  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:45:06 d2.utils.events]: \u001b[0m eta: 2:45:11  iter: 5339  total_loss: 0.1516  loss_cls: 0.04104  loss_box_reg: 0.1052  loss_rpn_cls: 0.0007352  loss_rpn_loc: 0.004281  time: 1.1279  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:45:29 d2.utils.events]: \u001b[0m eta: 2:44:51  iter: 5359  total_loss: 0.1822  loss_cls: 0.0466  loss_box_reg: 0.1245  loss_rpn_cls: 0.001349  loss_rpn_loc: 0.004938  time: 1.1280  data_time: 0.0931  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:45:51 d2.utils.events]: \u001b[0m eta: 2:44:28  iter: 5379  total_loss: 0.1758  loss_cls: 0.04476  loss_box_reg: 0.1257  loss_rpn_cls: 0.001026  loss_rpn_loc: 0.004973  time: 1.1280  data_time: 0.0997  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:46:14 d2.utils.events]: \u001b[0m eta: 2:44:08  iter: 5399  total_loss: 0.1681  loss_cls: 0.04911  loss_box_reg: 0.1139  loss_rpn_cls: 0.0009158  loss_rpn_loc: 0.005216  time: 1.1280  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:46:37 d2.utils.events]: \u001b[0m eta: 2:43:43  iter: 5419  total_loss: 0.1917  loss_cls: 0.05172  loss_box_reg: 0.1365  loss_rpn_cls: 0.0007437  loss_rpn_loc: 0.005399  time: 1.1280  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:46:59 d2.utils.events]: \u001b[0m eta: 2:43:20  iter: 5439  total_loss: 0.1692  loss_cls: 0.04551  loss_box_reg: 0.1164  loss_rpn_cls: 0.001008  loss_rpn_loc: 0.00457  time: 1.1280  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:47:22 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:47:22 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:47:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:47:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:47:22 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:47:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:47:22 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:47:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:47:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0654 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0017 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:47:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.296515 (0.066776 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:47:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064456 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:47:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:47:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:47:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.456\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.447\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.581\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n\u001b[32m[12/06 16:47:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.898 | 76.483 | 45.566 | 17.333 | 32.609 | 49.950 |\n\u001b[32m[12/06 16:47:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.022 | 1          | 69.668 |\n| 2          | 39.434 | 3          | 27.669 | 4          | 61.164 |\n| 5          | 31.432 |            |        |            |        |\n\u001b[32m[12/06 16:47:41 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:47:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:47:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:47:41 d2.evaluation.testing]: \u001b[0mcopypaste: 45.8980,76.4834,45.5664,17.3333,32.6093,49.9503\n\u001b[32m[12/06 16:47:41 d2.utils.events]: \u001b[0m eta: 2:42:56  iter: 5459  total_loss: 0.1703  loss_cls: 0.05075  loss_box_reg: 0.1149  loss_rpn_cls: 0.0007425  loss_rpn_loc: 0.005368  time: 1.1280  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:48:04 d2.utils.events]: \u001b[0m eta: 2:42:34  iter: 5479  total_loss: 0.1872  loss_cls: 0.05585  loss_box_reg: 0.1271  loss_rpn_cls: 0.0005612  loss_rpn_loc: 0.005965  time: 1.1280  data_time: 0.0935  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:48:26 d2.utils.events]: \u001b[0m eta: 2:42:11  iter: 5499  total_loss: 0.1454  loss_cls: 0.03792  loss_box_reg: 0.1051  loss_rpn_cls: 0.0007564  loss_rpn_loc: 0.003871  time: 1.1280  data_time: 0.0972  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:48:49 d2.utils.events]: \u001b[0m eta: 2:41:49  iter: 5519  total_loss: 0.1748  loss_cls: 0.04666  loss_box_reg: 0.1271  loss_rpn_cls: 0.0006311  loss_rpn_loc: 0.004701  time: 1.1281  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:49:11 d2.utils.events]: \u001b[0m eta: 2:41:25  iter: 5539  total_loss: 0.1904  loss_cls: 0.05067  loss_box_reg: 0.135  loss_rpn_cls: 0.000469  loss_rpn_loc: 0.004544  time: 1.1280  data_time: 0.0922  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:49:34 d2.utils.events]: \u001b[0m eta: 2:41:04  iter: 5559  total_loss: 0.1725  loss_cls: 0.04553  loss_box_reg: 0.1197  loss_rpn_cls: 0.0009478  loss_rpn_loc: 0.005072  time: 1.1280  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:49:57 d2.utils.events]: \u001b[0m eta: 2:40:41  iter: 5579  total_loss: 0.1625  loss_cls: 0.04288  loss_box_reg: 0.1108  loss_rpn_cls: 0.0007782  loss_rpn_loc: 0.005422  time: 1.1281  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:50:20 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:50:20 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:50:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:50:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:50:20 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:50:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:50:20 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:50:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:50:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0060 s/iter. Inference: 0.0806 s/iter. Eval: 0.0005 s/iter. Total: 0.0871 s/iter. ETA=0:00:23\n\u001b[32m[12/06 16:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 82/279. Dataloading: 0.0030 s/iter. Inference: 0.0693 s/iter. Eval: 0.0003 s/iter. Total: 0.0726 s/iter. ETA=0:00:14\n\u001b[32m[12/06 16:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0023 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0021 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0679 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:50:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.737303 (0.068384 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:50:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065725 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.426\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n\u001b[32m[12/06 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.780 | 76.399 | 42.609 | 18.000 | 31.939 | 48.795 |\n\u001b[32m[12/06 16:50:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 47.000 | 1          | 70.233 |\n| 2          | 39.172 | 3          | 27.079 | 4          | 60.235 |\n| 5          | 24.961 |            |        |            |        |\n\u001b[32m[12/06 16:50:39 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:50:39 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7802,76.3995,42.6087,18.0000,31.9394,48.7953\n\u001b[32m[12/06 16:50:39 d2.utils.events]: \u001b[0m eta: 2:40:18  iter: 5599  total_loss: 0.1814  loss_cls: 0.04647  loss_box_reg: 0.1308  loss_rpn_cls: 0.001052  loss_rpn_loc: 0.005014  time: 1.1281  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:51:02 d2.utils.events]: \u001b[0m eta: 2:39:55  iter: 5619  total_loss: 0.1535  loss_cls: 0.04047  loss_box_reg: 0.1081  loss_rpn_cls: 0.0005661  loss_rpn_loc: 0.004374  time: 1.1281  data_time: 0.0978  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:51:24 d2.utils.events]: \u001b[0m eta: 2:39:32  iter: 5639  total_loss: 0.1794  loss_cls: 0.04786  loss_box_reg: 0.1286  loss_rpn_cls: 0.0007412  loss_rpn_loc: 0.005013  time: 1.1281  data_time: 0.0902  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:51:47 d2.utils.events]: \u001b[0m eta: 2:39:07  iter: 5659  total_loss: 0.1881  loss_cls: 0.05075  loss_box_reg: 0.1301  loss_rpn_cls: 0.001296  loss_rpn_loc: 0.005465  time: 1.1281  data_time: 0.0897  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:52:10 d2.utils.events]: \u001b[0m eta: 2:38:45  iter: 5679  total_loss: 0.1774  loss_cls: 0.04828  loss_box_reg: 0.1212  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.005035  time: 1.1281  data_time: 0.0981  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:52:33 d2.utils.events]: \u001b[0m eta: 2:38:24  iter: 5699  total_loss: 0.1818  loss_cls: 0.0477  loss_box_reg: 0.122  loss_rpn_cls: 0.0007771  loss_rpn_loc: 0.006768  time: 1.1282  data_time: 0.0958  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:52:55 d2.utils.events]: \u001b[0m eta: 2:38:01  iter: 5719  total_loss: 0.1574  loss_cls: 0.03987  loss_box_reg: 0.1105  loss_rpn_cls: 0.0005519  loss_rpn_loc: 0.003766  time: 1.1282  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:53:18 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:53:18 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:53:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:53:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:53:18 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:53:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:53:18 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:53:18 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:53:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 84/279. Dataloading: 0.0019 s/iter. Inference: 0.0666 s/iter. Eval: 0.0002 s/iter. Total: 0.0687 s/iter. ETA=0:00:13\n\u001b[32m[12/06 16:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0018 s/iter. Inference: 0.0656 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 231/279. Dataloading: 0.0021 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0688 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:53:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.736637 (0.068382 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:53:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065880 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:53:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:53:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:53:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.776\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.457\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n\u001b[32m[12/06 16:53:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.115 | 77.582 | 44.753 | 15.833 | 33.313 | 50.192 |\n\u001b[32m[12/06 16:53:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 47.708 | 1          | 72.064 |\n| 2          | 41.005 | 3          | 27.782 | 4          | 59.072 |\n| 5          | 29.057 |            |        |            |        |\n\u001b[32m[12/06 16:53:37 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:53:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:53:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:53:37 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1146,77.5815,44.7531,15.8333,33.3125,50.1916\n\u001b[32m[12/06 16:53:37 d2.utils.events]: \u001b[0m eta: 2:37:39  iter: 5739  total_loss: 0.1683  loss_cls: 0.04239  loss_box_reg: 0.1172  loss_rpn_cls: 0.0006397  loss_rpn_loc: 0.004974  time: 1.1282  data_time: 0.0947  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:54:00 d2.utils.events]: \u001b[0m eta: 2:37:15  iter: 5759  total_loss: 0.1855  loss_cls: 0.05058  loss_box_reg: 0.1338  loss_rpn_cls: 0.0008438  loss_rpn_loc: 0.006117  time: 1.1282  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:54:22 d2.utils.events]: \u001b[0m eta: 2:36:53  iter: 5779  total_loss: 0.1825  loss_cls: 0.04506  loss_box_reg: 0.129  loss_rpn_cls: 0.0008022  loss_rpn_loc: 0.005363  time: 1.1282  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:54:45 d2.utils.events]: \u001b[0m eta: 2:36:29  iter: 5799  total_loss: 0.1469  loss_cls: 0.04177  loss_box_reg: 0.1023  loss_rpn_cls: 0.0007534  loss_rpn_loc: 0.004565  time: 1.1282  data_time: 0.0977  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:55:08 d2.utils.events]: \u001b[0m eta: 2:36:07  iter: 5819  total_loss: 0.1618  loss_cls: 0.04103  loss_box_reg: 0.1171  loss_rpn_cls: 0.0004958  loss_rpn_loc: 0.00447  time: 1.1282  data_time: 0.0944  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:55:30 d2.utils.events]: \u001b[0m eta: 2:35:42  iter: 5839  total_loss: 0.1803  loss_cls: 0.04774  loss_box_reg: 0.1237  loss_rpn_cls: 0.001267  loss_rpn_loc: 0.004814  time: 1.1281  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:55:52 d2.utils.events]: \u001b[0m eta: 2:35:19  iter: 5859  total_loss: 0.1662  loss_cls: 0.04454  loss_box_reg: 0.1199  loss_rpn_cls: 0.0006656  loss_rpn_loc: 0.004598  time: 1.1281  data_time: 0.0944  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:56:15 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:56:15 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:56:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:56:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:56:15 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:56:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:56:15 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:56:15 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:56:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 16:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0020 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0669 s/iter. ETA=0:00:12\n\u001b[32m[12/06 16:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0021 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:07\n\u001b[32m[12/06 16:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0021 s/iter. Inference: 0.0649 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:02\n\u001b[32m[12/06 16:56:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.419882 (0.067226 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:56:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064688 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:56:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:56:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:56:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624\n\u001b[32m[12/06 16:56:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.550 | 76.628 | 45.993 | 22.000 | 32.790 | 50.573 |\n\u001b[32m[12/06 16:56:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 48.007 | 1          | 72.786 |\n| 2          | 40.319 | 3          | 29.123 | 4          | 59.718 |\n| 5          | 29.348 |            |        |            |        |\n\u001b[32m[12/06 16:56:34 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:56:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:56:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:56:34 d2.evaluation.testing]: \u001b[0mcopypaste: 46.5503,76.6283,45.9927,22.0000,32.7898,50.5726\n\u001b[32m[12/06 16:56:34 d2.utils.events]: \u001b[0m eta: 2:34:56  iter: 5879  total_loss: 0.1615  loss_cls: 0.0396  loss_box_reg: 0.118  loss_rpn_cls: 0.0009272  loss_rpn_loc: 0.004252  time: 1.1281  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:56:57 d2.utils.events]: \u001b[0m eta: 2:34:33  iter: 5899  total_loss: 0.1741  loss_cls: 0.04689  loss_box_reg: 0.1169  loss_rpn_cls: 0.0009283  loss_rpn_loc: 0.005215  time: 1.1282  data_time: 0.0960  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:57:19 d2.utils.events]: \u001b[0m eta: 2:34:09  iter: 5919  total_loss: 0.1654  loss_cls: 0.04451  loss_box_reg: 0.1209  loss_rpn_cls: 0.001065  loss_rpn_loc: 0.004654  time: 1.1281  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:57:42 d2.utils.events]: \u001b[0m eta: 2:33:46  iter: 5939  total_loss: 0.1564  loss_cls: 0.03868  loss_box_reg: 0.1082  loss_rpn_cls: 0.001112  loss_rpn_loc: 0.005784  time: 1.1281  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:58:05 d2.utils.events]: \u001b[0m eta: 2:33:25  iter: 5959  total_loss: 0.1738  loss_cls: 0.04654  loss_box_reg: 0.1226  loss_rpn_cls: 0.001364  loss_rpn_loc: 0.005489  time: 1.1281  data_time: 0.0880  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:58:27 d2.utils.events]: \u001b[0m eta: 2:33:02  iter: 5979  total_loss: 0.157  loss_cls: 0.0406  loss_box_reg: 0.1073  loss_rpn_cls: 0.0007046  loss_rpn_loc: 0.004717  time: 1.1281  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:58:49 d2.utils.events]: \u001b[0m eta: 2:32:39  iter: 5999  total_loss: 0.1566  loss_cls: 0.04341  loss_box_reg: 0.1092  loss_rpn_cls: 0.0004755  loss_rpn_loc: 0.005046  time: 1.1281  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:59:12 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 16:59:12 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 16:59:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 16:59:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 16:59:12 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 16:59:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 16:59:12 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 16:59:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 16:59:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 16:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0030 s/iter. Inference: 0.1088 s/iter. Eval: 0.0003 s/iter. Total: 0.1120 s/iter. ETA=0:00:30\n\u001b[32m[12/06 16:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0021 s/iter. Inference: 0.0706 s/iter. Eval: 0.0003 s/iter. Total: 0.0731 s/iter. ETA=0:00:14\n\u001b[32m[12/06 16:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0019 s/iter. Inference: 0.0673 s/iter. Eval: 0.0002 s/iter. Total: 0.0695 s/iter. ETA=0:00:08\n\u001b[32m[12/06 16:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0020 s/iter. Inference: 0.0666 s/iter. Eval: 0.0002 s/iter. Total: 0.0689 s/iter. ETA=0:00:03\n\u001b[32m[12/06 16:59:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.775015 (0.068522 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:59:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.066090 s / iter per device, on 1 devices)\n\u001b[32m[12/06 16:59:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 16:59:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 16:59:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.781\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.450\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n\u001b[32m[12/06 16:59:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.867 | 78.053 | 46.014 | 15.333 | 32.676 | 50.904 |\n\u001b[32m[12/06 16:59:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.429 | 1          | 70.976 |\n| 2          | 40.727 | 3          | 28.034 | 4          | 62.614 |\n| 5          | 32.424 |            |        |            |        |\n\u001b[32m[12/06 16:59:32 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 16:59:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 16:59:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 16:59:32 d2.evaluation.testing]: \u001b[0mcopypaste: 46.8675,78.0531,46.0142,15.3333,32.6764,50.9038\n\u001b[32m[12/06 16:59:32 d2.utils.events]: \u001b[0m eta: 2:32:18  iter: 6019  total_loss: 0.1562  loss_cls: 0.04045  loss_box_reg: 0.1136  loss_rpn_cls: 0.0006222  loss_rpn_loc: 0.00417  time: 1.1281  data_time: 0.0964  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 16:59:55 d2.utils.events]: \u001b[0m eta: 2:31:54  iter: 6039  total_loss: 0.1643  loss_cls: 0.04115  loss_box_reg: 0.1135  loss_rpn_cls: 0.0006878  loss_rpn_loc: 0.004785  time: 1.1282  data_time: 0.1012  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:00:17 d2.utils.events]: \u001b[0m eta: 2:31:30  iter: 6059  total_loss: 0.186  loss_cls: 0.04545  loss_box_reg: 0.1311  loss_rpn_cls: 0.0006455  loss_rpn_loc: 0.005509  time: 1.1282  data_time: 0.0978  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:00:40 d2.utils.events]: \u001b[0m eta: 2:31:09  iter: 6079  total_loss: 0.1591  loss_cls: 0.04175  loss_box_reg: 0.1043  loss_rpn_cls: 0.0006663  loss_rpn_loc: 0.005176  time: 1.1283  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:01:02 d2.utils.events]: \u001b[0m eta: 2:30:44  iter: 6099  total_loss: 0.1586  loss_cls: 0.03943  loss_box_reg: 0.1141  loss_rpn_cls: 0.0002686  loss_rpn_loc: 0.00423  time: 1.1281  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:01:25 d2.utils.events]: \u001b[0m eta: 2:30:20  iter: 6119  total_loss: 0.1468  loss_cls: 0.04056  loss_box_reg: 0.1041  loss_rpn_cls: 0.0003179  loss_rpn_loc: 0.003987  time: 1.1281  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:01:47 d2.utils.events]: \u001b[0m eta: 2:29:57  iter: 6139  total_loss: 0.169  loss_cls: 0.04727  loss_box_reg: 0.1239  loss_rpn_cls: 0.0007542  loss_rpn_loc: 0.00565  time: 1.1281  data_time: 0.0916  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:02:10 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:02:10 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:02:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:02:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:02:10 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:02:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:02:10 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:02:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:02:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0025 s/iter. Inference: 0.0716 s/iter. Eval: 0.0003 s/iter. Total: 0.0745 s/iter. ETA=0:00:19\n\u001b[32m[12/06 17:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0017 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0019 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0674 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:02:26 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0019 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:02:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.407220 (0.067180 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:02:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064765 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:02:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:02:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:02:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.43s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n\u001b[32m[12/06 17:02:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.327 | 77.053 | 45.975 | 14.000 | 32.781 | 50.930 |\n\u001b[32m[12/06 17:02:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.879 | 1          | 71.643 |\n| 2          | 40.239 | 3          | 30.582 | 4          | 61.209 |\n| 5          | 29.407 |            |        |            |        |\n\u001b[32m[12/06 17:02:30 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:02:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:02:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:02:30 d2.evaluation.testing]: \u001b[0mcopypaste: 46.3266,77.0535,45.9752,14.0000,32.7806,50.9301\n\u001b[32m[12/06 17:02:30 d2.utils.events]: \u001b[0m eta: 2:29:36  iter: 6159  total_loss: 0.1527  loss_cls: 0.03861  loss_box_reg: 0.102  loss_rpn_cls: 0.0006032  loss_rpn_loc: 0.00472  time: 1.1282  data_time: 0.0995  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:02:52 d2.utils.events]: \u001b[0m eta: 2:29:11  iter: 6179  total_loss: 0.1444  loss_cls: 0.03663  loss_box_reg: 0.1007  loss_rpn_cls: 0.001076  loss_rpn_loc: 0.00553  time: 1.1282  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:03:15 d2.utils.events]: \u001b[0m eta: 2:28:49  iter: 6199  total_loss: 0.1651  loss_cls: 0.0429  loss_box_reg: 0.1195  loss_rpn_cls: 0.0008022  loss_rpn_loc: 0.004003  time: 1.1282  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:03:38 d2.utils.events]: \u001b[0m eta: 2:28:27  iter: 6219  total_loss: 0.1703  loss_cls: 0.04609  loss_box_reg: 0.1201  loss_rpn_cls: 0.0008716  loss_rpn_loc: 0.004808  time: 1.1282  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:04:00 d2.utils.events]: \u001b[0m eta: 2:28:04  iter: 6239  total_loss: 0.1536  loss_cls: 0.03964  loss_box_reg: 0.1068  loss_rpn_cls: 0.0004965  loss_rpn_loc: 0.004948  time: 1.1282  data_time: 0.0960  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:04:22 d2.utils.events]: \u001b[0m eta: 2:27:42  iter: 6259  total_loss: 0.1658  loss_cls: 0.04731  loss_box_reg: 0.1169  loss_rpn_cls: 0.0007117  loss_rpn_loc: 0.005312  time: 1.1282  data_time: 0.0902  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:04:45 d2.utils.events]: \u001b[0m eta: 2:27:19  iter: 6279  total_loss: 0.1616  loss_cls: 0.04232  loss_box_reg: 0.1163  loss_rpn_cls: 0.001425  loss_rpn_loc: 0.004507  time: 1.1282  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:05:08 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:05:08 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:05:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:05:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:05:08 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:05:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:05:08 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:05:08 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:05:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0018 s/iter. Inference: 0.0630 s/iter. Eval: 0.0002 s/iter. Total: 0.0650 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0019 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0019 s/iter. Inference: 0.0648 s/iter. Eval: 0.0002 s/iter. Total: 0.0669 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0018 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.196969 (0.066412 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:05:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064156 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:05:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:05:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:05:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.439\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n\u001b[32m[12/06 17:05:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.237 | 74.511 | 43.892 | 19.000 | 30.061 | 48.664 |\n\u001b[32m[12/06 17:05:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.367 | 1          | 70.175 |\n| 2          | 40.358 | 3          | 28.684 | 4          | 58.181 |\n| 5          | 23.656 |            |        |            |        |\n\u001b[32m[12/06 17:05:27 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:05:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:05:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:05:27 d2.evaluation.testing]: \u001b[0mcopypaste: 44.2370,74.5111,43.8916,19.0000,30.0605,48.6644\n\u001b[32m[12/06 17:05:27 d2.utils.events]: \u001b[0m eta: 2:26:57  iter: 6299  total_loss: 0.1551  loss_cls: 0.039  loss_box_reg: 0.1067  loss_rpn_cls: 0.0003794  loss_rpn_loc: 0.00523  time: 1.1282  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:05:49 d2.utils.events]: \u001b[0m eta: 2:26:35  iter: 6319  total_loss: 0.1572  loss_cls: 0.04124  loss_box_reg: 0.1099  loss_rpn_cls: 0.0003778  loss_rpn_loc: 0.005056  time: 1.1282  data_time: 0.0962  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:06:12 d2.utils.events]: \u001b[0m eta: 2:26:12  iter: 6339  total_loss: 0.1437  loss_cls: 0.03449  loss_box_reg: 0.1034  loss_rpn_cls: 0.0003392  loss_rpn_loc: 0.004291  time: 1.1282  data_time: 0.1031  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:06:35 d2.utils.events]: \u001b[0m eta: 2:25:49  iter: 6359  total_loss: 0.1497  loss_cls: 0.0428  loss_box_reg: 0.1041  loss_rpn_cls: 0.001044  loss_rpn_loc: 0.005138  time: 1.1283  data_time: 0.0972  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:06:58 d2.utils.events]: \u001b[0m eta: 2:25:26  iter: 6379  total_loss: 0.1726  loss_cls: 0.0415  loss_box_reg: 0.1176  loss_rpn_cls: 0.0007018  loss_rpn_loc: 0.004508  time: 1.1283  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:07:21 d2.utils.events]: \u001b[0m eta: 2:25:03  iter: 6399  total_loss: 0.1555  loss_cls: 0.03907  loss_box_reg: 0.1104  loss_rpn_cls: 0.000377  loss_rpn_loc: 0.005264  time: 1.1283  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:07:43 d2.utils.events]: \u001b[0m eta: 2:24:41  iter: 6419  total_loss: 0.1531  loss_cls: 0.04045  loss_box_reg: 0.1113  loss_rpn_cls: 0.0008874  loss_rpn_loc: 0.004202  time: 1.1282  data_time: 0.0981  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:08:05 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:08:05 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:08:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:08:05 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:08:05 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:08:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:08:05 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:08:05 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:08:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0043 s/iter. Inference: 0.0771 s/iter. Eval: 0.0003 s/iter. Total: 0.0816 s/iter. ETA=0:00:21\n\u001b[32m[12/06 17:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0022 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0683 s/iter. ETA=0:00:13\n\u001b[32m[12/06 17:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0021 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0679 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0020 s/iter. Inference: 0.0649 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:08:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.568363 (0.067768 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:08:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065240 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:08:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:08:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:08:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.337\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n\u001b[32m[12/06 17:08:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.065 | 76.516 | 45.994 | 16.000 | 33.682 | 49.862 |\n\u001b[32m[12/06 17:08:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.476 | 1          | 71.034 |\n| 2          | 39.918 | 3          | 29.465 | 4          | 61.678 |\n| 5          | 27.817 |            |        |            |        |\n\u001b[32m[12/06 17:08:25 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: 46.0646,76.5163,45.9945,16.0000,33.6824,49.8622\n\u001b[32m[12/06 17:08:25 d2.utils.events]: \u001b[0m eta: 2:24:19  iter: 6439  total_loss: 0.1552  loss_cls: 0.03824  loss_box_reg: 0.1139  loss_rpn_cls: 0.000587  loss_rpn_loc: 0.003873  time: 1.1283  data_time: 0.0884  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:08:48 d2.utils.events]: \u001b[0m eta: 2:23:58  iter: 6459  total_loss: 0.1662  loss_cls: 0.04337  loss_box_reg: 0.1154  loss_rpn_cls: 0.0007392  loss_rpn_loc: 0.005468  time: 1.1283  data_time: 0.1003  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:09:10 d2.utils.events]: \u001b[0m eta: 2:23:34  iter: 6479  total_loss: 0.1606  loss_cls: 0.0421  loss_box_reg: 0.1124  loss_rpn_cls: 0.0008041  loss_rpn_loc: 0.005766  time: 1.1283  data_time: 0.0900  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:09:33 d2.utils.events]: \u001b[0m eta: 2:23:11  iter: 6499  total_loss: 0.1534  loss_cls: 0.03996  loss_box_reg: 0.1139  loss_rpn_cls: 0.0006083  loss_rpn_loc: 0.004159  time: 1.1283  data_time: 0.0898  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:09:56 d2.utils.events]: \u001b[0m eta: 2:22:48  iter: 6519  total_loss: 0.1645  loss_cls: 0.04103  loss_box_reg: 0.1123  loss_rpn_cls: 0.0005559  loss_rpn_loc: 0.005168  time: 1.1283  data_time: 0.0938  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:10:19 d2.utils.events]: \u001b[0m eta: 2:22:25  iter: 6539  total_loss: 0.1516  loss_cls: 0.03869  loss_box_reg: 0.1087  loss_rpn_cls: 0.001453  loss_rpn_loc: 0.004555  time: 1.1284  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:10:41 d2.utils.events]: \u001b[0m eta: 2:22:02  iter: 6559  total_loss: 0.1732  loss_cls: 0.04391  loss_box_reg: 0.1125  loss_rpn_cls: 0.0006103  loss_rpn_loc: 0.004824  time: 1.1284  data_time: 0.0888  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:11:04 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:11:04 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:11:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:11:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:11:04 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:11:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:11:04 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:11:04 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:11:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:11:10 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0018 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:11:15 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0023 s/iter. Inference: 0.0659 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 231/279. Dataloading: 0.0022 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0683 s/iter. ETA=0:00:03\n\u001b[32m[12/06 17:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.625050 (0.067975 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:11:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065331 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:11:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:11:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:11:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n\u001b[32m[12/06 17:11:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.988 | 77.493 | 44.826 | 20.000 | 33.209 | 50.005 |\n\u001b[32m[12/06 17:11:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.395 | 1          | 72.266 |\n| 2          | 39.478 | 3          | 28.960 | 4          | 60.605 |\n| 5          | 29.225 |            |        |            |        |\n\u001b[32m[12/06 17:11:23 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:11:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:11:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:11:23 d2.evaluation.testing]: \u001b[0mcopypaste: 45.9882,77.4928,44.8261,20.0000,33.2090,50.0045\n\u001b[32m[12/06 17:11:23 d2.utils.events]: \u001b[0m eta: 2:21:39  iter: 6579  total_loss: 0.1589  loss_cls: 0.04254  loss_box_reg: 0.1124  loss_rpn_cls: 0.0004219  loss_rpn_loc: 0.005249  time: 1.1284  data_time: 0.0966  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:11:46 d2.utils.events]: \u001b[0m eta: 2:21:14  iter: 6599  total_loss: 0.1447  loss_cls: 0.03855  loss_box_reg: 0.09796  loss_rpn_cls: 0.0006252  loss_rpn_loc: 0.004441  time: 1.1284  data_time: 0.0974  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:12:08 d2.utils.events]: \u001b[0m eta: 2:20:51  iter: 6619  total_loss: 0.1837  loss_cls: 0.04332  loss_box_reg: 0.133  loss_rpn_cls: 0.001875  loss_rpn_loc: 0.005222  time: 1.1284  data_time: 0.0859  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:12:31 d2.utils.events]: \u001b[0m eta: 2:20:28  iter: 6639  total_loss: 0.1484  loss_cls: 0.03835  loss_box_reg: 0.1031  loss_rpn_cls: 0.0002432  loss_rpn_loc: 0.004181  time: 1.1284  data_time: 0.0999  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:12:54 d2.utils.events]: \u001b[0m eta: 2:20:07  iter: 6659  total_loss: 0.1567  loss_cls: 0.03621  loss_box_reg: 0.1143  loss_rpn_cls: 0.0003067  loss_rpn_loc: 0.004837  time: 1.1285  data_time: 0.0970  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:13:16 d2.utils.events]: \u001b[0m eta: 2:19:41  iter: 6679  total_loss: 0.1706  loss_cls: 0.04223  loss_box_reg: 0.1236  loss_rpn_cls: 0.0004711  loss_rpn_loc: 0.004679  time: 1.1284  data_time: 0.0881  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:13:39 d2.utils.events]: \u001b[0m eta: 2:19:18  iter: 6699  total_loss: 0.1618  loss_cls: 0.03935  loss_box_reg: 0.1112  loss_rpn_cls: 0.0005303  loss_rpn_loc: 0.004619  time: 1.1285  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:14:02 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:14:02 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:14:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:14:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:14:02 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:14:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:14:02 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:14:02 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:14:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0651 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0018 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0017 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 237/279. Dataloading: 0.0019 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:14:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.260482 (0.066644 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:14:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064340 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:14:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:14:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:14:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n\u001b[32m[12/06 17:14:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.783 | 77.195 | 45.047 | 17.000 | 32.664 | 49.627 |\n\u001b[32m[12/06 17:14:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.417 | 1          | 71.140 |\n| 2          | 40.251 | 3          | 29.280 | 4          | 60.516 |\n| 5          | 28.094 |            |        |            |        |\n\u001b[32m[12/06 17:14:21 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:14:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:14:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:14:21 d2.evaluation.testing]: \u001b[0mcopypaste: 45.7830,77.1953,45.0465,17.0000,32.6636,49.6267\n\u001b[32m[12/06 17:14:21 d2.utils.events]: \u001b[0m eta: 2:18:55  iter: 6719  total_loss: 0.1473  loss_cls: 0.03599  loss_box_reg: 0.1062  loss_rpn_cls: 0.0007513  loss_rpn_loc: 0.00372  time: 1.1285  data_time: 0.0959  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:14:44 d2.utils.events]: \u001b[0m eta: 2:18:32  iter: 6739  total_loss: 0.1398  loss_cls: 0.0325  loss_box_reg: 0.09673  loss_rpn_cls: 0.0005816  loss_rpn_loc: 0.003797  time: 1.1286  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:15:06 d2.utils.events]: \u001b[0m eta: 2:18:09  iter: 6759  total_loss: 0.1741  loss_cls: 0.04295  loss_box_reg: 0.1232  loss_rpn_cls: 0.0009546  loss_rpn_loc: 0.005861  time: 1.1285  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:15:29 d2.utils.events]: \u001b[0m eta: 2:17:47  iter: 6779  total_loss: 0.1381  loss_cls: 0.03547  loss_box_reg: 0.1015  loss_rpn_cls: 0.0006298  loss_rpn_loc: 0.004617  time: 1.1285  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:15:51 d2.utils.events]: \u001b[0m eta: 2:17:23  iter: 6799  total_loss: 0.1408  loss_cls: 0.03551  loss_box_reg: 0.09826  loss_rpn_cls: 0.0005096  loss_rpn_loc: 0.004238  time: 1.1285  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:16:14 d2.utils.events]: \u001b[0m eta: 2:17:00  iter: 6819  total_loss: 0.1339  loss_cls: 0.03541  loss_box_reg: 0.0954  loss_rpn_cls: 0.0005295  loss_rpn_loc: 0.003729  time: 1.1285  data_time: 0.0901  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:16:37 d2.utils.events]: \u001b[0m eta: 2:16:39  iter: 6839  total_loss: 0.1602  loss_cls: 0.04156  loss_box_reg: 0.1153  loss_rpn_cls: 0.0004954  loss_rpn_loc: 0.005878  time: 1.1285  data_time: 0.0978  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:16:59 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:16:59 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:16:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:16:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:16:59 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:16:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:16:59 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:16:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:16:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0049 s/iter. Inference: 0.0809 s/iter. Eval: 0.0003 s/iter. Total: 0.0860 s/iter. ETA=0:00:23\n\u001b[32m[12/06 17:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0020 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0674 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0018 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0018 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:17:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.264760 (0.066660 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:17:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064382 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:17:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:17:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:17:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.782\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.456\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n\u001b[32m[12/06 17:17:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.974 | 78.208 | 44.706 | 15.000 | 34.397 | 49.751 |\n\u001b[32m[12/06 17:17:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.622 | 1          | 70.238 |\n| 2          | 40.261 | 3          | 28.526 | 4          | 60.206 |\n| 5          | 30.991 |            |        |            |        |\n\u001b[32m[12/06 17:17:19 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:17:19 d2.evaluation.testing]: \u001b[0mcopypaste: 45.9739,78.2076,44.7055,15.0000,34.3966,49.7512\n\u001b[32m[12/06 17:17:19 d2.utils.events]: \u001b[0m eta: 2:16:15  iter: 6859  total_loss: 0.1194  loss_cls: 0.02996  loss_box_reg: 0.08267  loss_rpn_cls: 0.0005831  loss_rpn_loc: 0.003984  time: 1.1285  data_time: 0.0997  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:17:41 d2.utils.events]: \u001b[0m eta: 2:15:53  iter: 6879  total_loss: 0.1562  loss_cls: 0.0395  loss_box_reg: 0.1128  loss_rpn_cls: 0.0008153  loss_rpn_loc: 0.005504  time: 1.1285  data_time: 0.0921  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:18:04 d2.utils.events]: \u001b[0m eta: 2:15:31  iter: 6899  total_loss: 0.1618  loss_cls: 0.04043  loss_box_reg: 0.1163  loss_rpn_cls: 0.0009685  loss_rpn_loc: 0.00411  time: 1.1285  data_time: 0.0960  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:18:26 d2.utils.events]: \u001b[0m eta: 2:15:08  iter: 6919  total_loss: 0.1574  loss_cls: 0.03952  loss_box_reg: 0.1072  loss_rpn_cls: 0.0004808  loss_rpn_loc: 0.004627  time: 1.1285  data_time: 0.0863  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:18:48 d2.utils.events]: \u001b[0m eta: 2:14:46  iter: 6939  total_loss: 0.147  loss_cls: 0.03555  loss_box_reg: 0.106  loss_rpn_cls: 0.0006483  loss_rpn_loc: 0.004686  time: 1.1285  data_time: 0.0973  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:19:11 d2.utils.events]: \u001b[0m eta: 2:14:23  iter: 6959  total_loss: 0.1497  loss_cls: 0.03985  loss_box_reg: 0.104  loss_rpn_cls: 0.0007377  loss_rpn_loc: 0.005245  time: 1.1285  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:19:34 d2.utils.events]: \u001b[0m eta: 2:14:01  iter: 6979  total_loss: 0.1538  loss_cls: 0.04472  loss_box_reg: 0.1056  loss_rpn_cls: 0.0004931  loss_rpn_loc: 0.004381  time: 1.1285  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:19:56 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:19:56 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:19:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:19:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:19:56 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:19:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:19:56 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:19:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:19:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0020 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0021 s/iter. Inference: 0.0658 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0020 s/iter. Inference: 0.0653 s/iter. Eval: 0.0002 s/iter. Total: 0.0676 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:20:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.478795 (0.067441 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:20:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065019 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:20:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:20:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:20:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.582\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624\n\u001b[32m[12/06 17:20:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.542 | 76.356 | 44.970 | 17.000 | 31.633 | 49.777 |\n\u001b[32m[12/06 17:20:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.704 | 1          | 69.487 |\n| 2          | 39.409 | 3          | 26.321 | 4          | 61.329 |\n| 5          | 31.004 |            |        |            |        |\n\u001b[32m[12/06 17:20:16 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:20:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:20:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:20:16 d2.evaluation.testing]: \u001b[0mcopypaste: 45.5424,76.3563,44.9703,17.0000,31.6335,49.7765\n\u001b[32m[12/06 17:20:16 d2.utils.events]: \u001b[0m eta: 2:13:37  iter: 6999  total_loss: 0.1526  loss_cls: 0.0389  loss_box_reg: 0.1117  loss_rpn_cls: 0.0002381  loss_rpn_loc: 0.004029  time: 1.1285  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:20:38 d2.utils.events]: \u001b[0m eta: 2:13:13  iter: 7019  total_loss: 0.1525  loss_cls: 0.04386  loss_box_reg: 0.1048  loss_rpn_cls: 0.0007235  loss_rpn_loc: 0.005681  time: 1.1285  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:21:01 d2.utils.events]: \u001b[0m eta: 2:12:51  iter: 7039  total_loss: 0.1323  loss_cls: 0.03122  loss_box_reg: 0.09496  loss_rpn_cls: 0.0004489  loss_rpn_loc: 0.004726  time: 1.1286  data_time: 0.0976  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:21:24 d2.utils.events]: \u001b[0m eta: 2:12:28  iter: 7059  total_loss: 0.1414  loss_cls: 0.03638  loss_box_reg: 0.102  loss_rpn_cls: 0.0006536  loss_rpn_loc: 0.003933  time: 1.1285  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:21:46 d2.utils.events]: \u001b[0m eta: 2:12:04  iter: 7079  total_loss: 0.1406  loss_cls: 0.03336  loss_box_reg: 0.09783  loss_rpn_cls: 0.0003394  loss_rpn_loc: 0.004177  time: 1.1285  data_time: 0.0908  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:22:09 d2.utils.events]: \u001b[0m eta: 2:11:43  iter: 7099  total_loss: 0.1595  loss_cls: 0.04046  loss_box_reg: 0.1148  loss_rpn_cls: 0.0003495  loss_rpn_loc: 0.004629  time: 1.1285  data_time: 0.0922  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:22:31 d2.utils.events]: \u001b[0m eta: 2:11:20  iter: 7119  total_loss: 0.125  loss_cls: 0.0326  loss_box_reg: 0.0893  loss_rpn_cls: 0.0006321  loss_rpn_loc: 0.004521  time: 1.1285  data_time: 0.0904  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:22:54 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:22:54 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:22:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:22:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:22:54 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:22:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:22:54 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:22:54 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:22:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0017 s/iter. Inference: 0.0636 s/iter. Eval: 0.0002 s/iter. Total: 0.0656 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0019 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:23:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.193004 (0.066398 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:23:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064122 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:23:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:23:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:23:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.763\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.440\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.459\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n\u001b[32m[12/06 17:23:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.620 | 76.307 | 43.999 | 18.667 | 30.910 | 49.052 |\n\u001b[32m[12/06 17:23:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.583 | 1          | 69.692 |\n| 2          | 40.405 | 3          | 27.514 | 4          | 57.336 |\n| 5          | 27.189 |            |        |            |        |\n\u001b[32m[12/06 17:23:13 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:23:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:23:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:23:13 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6198,76.3071,43.9987,18.6667,30.9105,49.0519\n\u001b[32m[12/06 17:23:13 d2.utils.events]: \u001b[0m eta: 2:10:58  iter: 7139  total_loss: 0.1601  loss_cls: 0.03831  loss_box_reg: 0.1146  loss_rpn_cls: 0.0005294  loss_rpn_loc: 0.005243  time: 1.1285  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:23:36 d2.utils.events]: \u001b[0m eta: 2:10:36  iter: 7159  total_loss: 0.1365  loss_cls: 0.03215  loss_box_reg: 0.09523  loss_rpn_cls: 0.0004981  loss_rpn_loc: 0.005229  time: 1.1285  data_time: 0.0971  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:23:58 d2.utils.events]: \u001b[0m eta: 2:10:13  iter: 7179  total_loss: 0.1395  loss_cls: 0.03785  loss_box_reg: 0.09674  loss_rpn_cls: 0.0003802  loss_rpn_loc: 0.004259  time: 1.1285  data_time: 0.0935  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:24:21 d2.utils.events]: \u001b[0m eta: 2:09:50  iter: 7199  total_loss: 0.13  loss_cls: 0.0326  loss_box_reg: 0.09007  loss_rpn_cls: 0.000245  loss_rpn_loc: 0.003959  time: 1.1286  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:24:43 d2.utils.events]: \u001b[0m eta: 2:09:26  iter: 7219  total_loss: 0.1439  loss_cls: 0.03584  loss_box_reg: 0.09779  loss_rpn_cls: 0.0004483  loss_rpn_loc: 0.004507  time: 1.1285  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:25:06 d2.utils.events]: \u001b[0m eta: 2:09:03  iter: 7239  total_loss: 0.1528  loss_cls: 0.03945  loss_box_reg: 0.1041  loss_rpn_cls: 0.0005398  loss_rpn_loc: 0.004381  time: 1.1286  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:25:29 d2.utils.events]: \u001b[0m eta: 2:08:40  iter: 7259  total_loss: 0.136  loss_cls: 0.03821  loss_box_reg: 0.09603  loss_rpn_cls: 0.0007208  loss_rpn_loc: 0.00385  time: 1.1286  data_time: 0.0898  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:25:52 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:25:52 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:25:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:25:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:25:52 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:25:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:25:52 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:25:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:25:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0630 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 89/279. Dataloading: 0.0015 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:26:03 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0016 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:26:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.143493 (0.066217 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:26:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063972 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:26:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:26:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:26:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n\u001b[32m[12/06 17:26:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.946 | 74.771 | 43.778 | 22.000 | 31.748 | 49.056 |\n\u001b[32m[12/06 17:26:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.383 | 1          | 69.242 |\n| 2          | 41.169 | 3          | 27.358 | 4          | 59.781 |\n| 5          | 27.744 |            |        |            |        |\n\u001b[32m[12/06 17:26:11 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:26:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:26:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:26:11 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9461,74.7707,43.7781,22.0000,31.7478,49.0558\n\u001b[32m[12/06 17:26:11 d2.utils.events]: \u001b[0m eta: 2:08:17  iter: 7279  total_loss: 0.1378  loss_cls: 0.0346  loss_box_reg: 0.09939  loss_rpn_cls: 0.0003008  loss_rpn_loc: 0.00412  time: 1.1286  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:26:34 d2.utils.events]: \u001b[0m eta: 2:07:54  iter: 7299  total_loss: 0.1395  loss_cls: 0.03389  loss_box_reg: 0.09795  loss_rpn_cls: 0.0004454  loss_rpn_loc: 0.004107  time: 1.1286  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:26:56 d2.utils.events]: \u001b[0m eta: 2:07:31  iter: 7319  total_loss: 0.1594  loss_cls: 0.04125  loss_box_reg: 0.1079  loss_rpn_cls: 0.0003881  loss_rpn_loc: 0.00489  time: 1.1287  data_time: 0.0882  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:27:19 d2.utils.events]: \u001b[0m eta: 2:07:07  iter: 7339  total_loss: 0.1637  loss_cls: 0.04125  loss_box_reg: 0.1149  loss_rpn_cls: 0.0008122  loss_rpn_loc: 0.005559  time: 1.1287  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:27:41 d2.utils.events]: \u001b[0m eta: 2:06:44  iter: 7359  total_loss: 0.1325  loss_cls: 0.03457  loss_box_reg: 0.09583  loss_rpn_cls: 0.000451  loss_rpn_loc: 0.004088  time: 1.1287  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:28:04 d2.utils.events]: \u001b[0m eta: 2:06:21  iter: 7379  total_loss: 0.1436  loss_cls: 0.0355  loss_box_reg: 0.1001  loss_rpn_cls: 0.0004128  loss_rpn_loc: 0.004757  time: 1.1286  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:28:26 d2.utils.events]: \u001b[0m eta: 2:05:58  iter: 7399  total_loss: 0.1394  loss_cls: 0.03334  loss_box_reg: 0.09288  loss_rpn_cls: 0.0003723  loss_rpn_loc: 0.003693  time: 1.1286  data_time: 0.0869  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:28:49 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:28:49 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:28:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:28:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:28:49 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:28:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:28:49 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:28:49 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:28:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0645 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0016 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0017 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0660 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:29:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.676643 (0.068163 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:29:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065800 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:29:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:29:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:29:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.38s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.582\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n\u001b[32m[12/06 17:29:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.818 | 76.760 | 45.180 | 14.500 | 32.298 | 50.119 |\n\u001b[32m[12/06 17:29:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.514 | 1          | 68.852 |\n| 2          | 40.817 | 3          | 26.591 | 4          | 59.049 |\n| 5          | 33.084 |            |        |            |        |\n\u001b[32m[12/06 17:29:08 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:29:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:29:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:29:08 d2.evaluation.testing]: \u001b[0mcopypaste: 45.8177,76.7597,45.1804,14.5000,32.2978,50.1192\n\u001b[32m[12/06 17:29:08 d2.utils.events]: \u001b[0m eta: 2:05:35  iter: 7419  total_loss: 0.1451  loss_cls: 0.03453  loss_box_reg: 0.1077  loss_rpn_cls: 0.0003747  loss_rpn_loc: 0.004266  time: 1.1286  data_time: 0.0915  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:29:31 d2.utils.events]: \u001b[0m eta: 2:05:13  iter: 7439  total_loss: 0.1413  loss_cls: 0.03335  loss_box_reg: 0.1018  loss_rpn_cls: 0.0003745  loss_rpn_loc: 0.00451  time: 1.1286  data_time: 0.0866  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:29:54 d2.utils.events]: \u001b[0m eta: 2:04:49  iter: 7459  total_loss: 0.1296  loss_cls: 0.03217  loss_box_reg: 0.09445  loss_rpn_cls: 0.0002267  loss_rpn_loc: 0.004078  time: 1.1286  data_time: 0.0951  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:30:17 d2.utils.events]: \u001b[0m eta: 2:04:26  iter: 7479  total_loss: 0.1339  loss_cls: 0.03502  loss_box_reg: 0.09311  loss_rpn_cls: 0.0003641  loss_rpn_loc: 0.004896  time: 1.1287  data_time: 0.0962  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:30:39 d2.utils.events]: \u001b[0m eta: 2:04:02  iter: 7499  total_loss: 0.1278  loss_cls: 0.0343  loss_box_reg: 0.08613  loss_rpn_cls: 0.0003779  loss_rpn_loc: 0.003815  time: 1.1286  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:31:01 d2.utils.events]: \u001b[0m eta: 2:03:39  iter: 7519  total_loss: 0.1638  loss_cls: 0.04655  loss_box_reg: 0.1063  loss_rpn_cls: 0.0008062  loss_rpn_loc: 0.005343  time: 1.1286  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:31:24 d2.utils.events]: \u001b[0m eta: 2:03:16  iter: 7539  total_loss: 0.1434  loss_cls: 0.03584  loss_box_reg: 0.1038  loss_rpn_cls: 0.0003528  loss_rpn_loc: 0.004061  time: 1.1286  data_time: 0.0962  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:31:47 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:31:47 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:31:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:31:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:31:47 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:31:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:31:47 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:31:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:31:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0645 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0019 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:13\n\u001b[32m[12/06 17:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0017 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:32:03 d2.evaluation.evaluator]: \u001b[0mInference done 237/279. Dataloading: 0.0017 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:32:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.227316 (0.066523 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:32:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064361 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:32:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:32:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:32:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.441\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n\u001b[32m[12/06 17:32:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.839 | 76.987 | 44.434 | 14.667 | 31.893 | 49.242 |\n\u001b[32m[12/06 17:32:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.380 | 1          | 68.301 |\n| 2          | 40.648 | 3          | 28.099 | 4          | 60.418 |\n| 5          | 28.190 |            |        |            |        |\n\u001b[32m[12/06 17:32:06 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:32:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:32:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:32:06 d2.evaluation.testing]: \u001b[0mcopypaste: 44.8394,76.9866,44.4340,14.6667,31.8928,49.2419\n\u001b[32m[12/06 17:32:06 d2.utils.events]: \u001b[0m eta: 2:02:53  iter: 7559  total_loss: 0.1237  loss_cls: 0.03381  loss_box_reg: 0.08623  loss_rpn_cls: 0.0004344  loss_rpn_loc: 0.004548  time: 1.1286  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:32:28 d2.utils.events]: \u001b[0m eta: 2:02:29  iter: 7579  total_loss: 0.1417  loss_cls: 0.03581  loss_box_reg: 0.1065  loss_rpn_cls: 0.0005053  loss_rpn_loc: 0.004344  time: 1.1286  data_time: 0.0892  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:32:51 d2.utils.events]: \u001b[0m eta: 2:02:07  iter: 7599  total_loss: 0.1161  loss_cls: 0.02626  loss_box_reg: 0.08688  loss_rpn_cls: 0.0006911  loss_rpn_loc: 0.003564  time: 1.1287  data_time: 0.0931  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:33:13 d2.utils.events]: \u001b[0m eta: 2:01:44  iter: 7619  total_loss: 0.1333  loss_cls: 0.03325  loss_box_reg: 0.09608  loss_rpn_cls: 0.0006717  loss_rpn_loc: 0.004499  time: 1.1286  data_time: 0.0898  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:33:36 d2.utils.events]: \u001b[0m eta: 2:01:21  iter: 7639  total_loss: 0.1274  loss_cls: 0.03311  loss_box_reg: 0.09287  loss_rpn_cls: 0.000258  loss_rpn_loc: 0.003912  time: 1.1287  data_time: 0.0938  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:33:59 d2.utils.events]: \u001b[0m eta: 2:00:57  iter: 7659  total_loss: 0.1292  loss_cls: 0.035  loss_box_reg: 0.09179  loss_rpn_cls: 0.0004374  loss_rpn_loc: 0.004113  time: 1.1287  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:34:21 d2.utils.events]: \u001b[0m eta: 2:00:34  iter: 7679  total_loss: 0.142  loss_cls: 0.03822  loss_box_reg: 0.1013  loss_rpn_cls: 0.0004007  loss_rpn_loc: 0.004642  time: 1.1286  data_time: 0.0871  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:34:44 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:34:44 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:34:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:34:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:34:44 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:34:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:34:44 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:34:44 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:34:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0018 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0021 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0689 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 231/279. Dataloading: 0.0020 s/iter. Inference: 0.0662 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:00:03\n\u001b[32m[12/06 17:35:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.662718 (0.068112 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:35:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065689 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:35:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:35:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:35:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.510\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.449\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n\u001b[32m[12/06 17:35:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.113 | 77.074 | 45.150 | 14.000 | 32.026 | 50.971 |\n\u001b[32m[12/06 17:35:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.358 | 1          | 70.581 |\n| 2          | 41.017 | 3          | 27.985 | 4          | 61.665 |\n| 5          | 31.074 |            |        |            |        |\n\u001b[32m[12/06 17:35:03 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:35:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:35:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:35:03 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1131,77.0743,45.1501,14.0000,32.0260,50.9713\n\u001b[32m[12/06 17:35:03 d2.utils.events]: \u001b[0m eta: 2:00:10  iter: 7699  total_loss: 0.1146  loss_cls: 0.03021  loss_box_reg: 0.082  loss_rpn_cls: 0.0002693  loss_rpn_loc: 0.003475  time: 1.1286  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:35:26 d2.utils.events]: \u001b[0m eta: 1:59:47  iter: 7719  total_loss: 0.1327  loss_cls: 0.03474  loss_box_reg: 0.09101  loss_rpn_cls: 0.0004647  loss_rpn_loc: 0.004252  time: 1.1286  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:35:48 d2.utils.events]: \u001b[0m eta: 1:59:23  iter: 7739  total_loss: 0.1577  loss_cls: 0.0409  loss_box_reg: 0.1124  loss_rpn_cls: 0.0003383  loss_rpn_loc: 0.004313  time: 1.1286  data_time: 0.0870  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:36:11 d2.utils.events]: \u001b[0m eta: 1:58:59  iter: 7759  total_loss: 0.1277  loss_cls: 0.03332  loss_box_reg: 0.09157  loss_rpn_cls: 0.0001953  loss_rpn_loc: 0.004142  time: 1.1286  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:36:34 d2.utils.events]: \u001b[0m eta: 1:58:36  iter: 7779  total_loss: 0.1387  loss_cls: 0.03541  loss_box_reg: 0.09662  loss_rpn_cls: 0.000256  loss_rpn_loc: 0.003973  time: 1.1286  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:36:56 d2.utils.events]: \u001b[0m eta: 1:58:14  iter: 7799  total_loss: 0.1439  loss_cls: 0.03641  loss_box_reg: 0.1041  loss_rpn_cls: 0.0006197  loss_rpn_loc: 0.004598  time: 1.1286  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:37:19 d2.utils.events]: \u001b[0m eta: 1:57:51  iter: 7819  total_loss: 0.1497  loss_cls: 0.03589  loss_box_reg: 0.1012  loss_rpn_cls: 0.0004592  loss_rpn_loc: 0.004544  time: 1.1286  data_time: 0.0911  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:37:41 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:37:41 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:37:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:37:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:37:41 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:37:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:37:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:37:41 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:37:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0651 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0016 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0017 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:38:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.186546 (0.066374 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:38:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064234 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:38:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:38:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:38:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.455\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.454\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.583\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n\u001b[32m[12/06 17:38:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.853 | 77.305 | 45.472 | 18.000 | 31.671 | 50.223 |\n\u001b[32m[12/06 17:38:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.143 | 1          | 70.374 |\n| 2          | 40.393 | 3          | 28.115 | 4          | 61.502 |\n| 5          | 29.589 |            |        |            |        |\n\u001b[32m[12/06 17:38:00 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:38:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:38:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:38:00 d2.evaluation.testing]: \u001b[0mcopypaste: 45.8527,77.3046,45.4725,18.0000,31.6707,50.2230\n\u001b[32m[12/06 17:38:00 d2.utils.events]: \u001b[0m eta: 1:57:28  iter: 7839  total_loss: 0.1268  loss_cls: 0.02947  loss_box_reg: 0.08933  loss_rpn_cls: 0.0002357  loss_rpn_loc: 0.003996  time: 1.1286  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:38:23 d2.utils.events]: \u001b[0m eta: 1:57:05  iter: 7859  total_loss: 0.1233  loss_cls: 0.03204  loss_box_reg: 0.09048  loss_rpn_cls: 0.0002115  loss_rpn_loc: 0.003525  time: 1.1286  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:38:46 d2.utils.events]: \u001b[0m eta: 1:56:42  iter: 7879  total_loss: 0.1307  loss_cls: 0.03414  loss_box_reg: 0.09099  loss_rpn_cls: 0.000329  loss_rpn_loc: 0.004256  time: 1.1287  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:39:08 d2.utils.events]: \u001b[0m eta: 1:56:18  iter: 7899  total_loss: 0.1333  loss_cls: 0.03381  loss_box_reg: 0.09503  loss_rpn_cls: 0.0008717  loss_rpn_loc: 0.004642  time: 1.1286  data_time: 0.0947  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:39:31 d2.utils.events]: \u001b[0m eta: 1:55:55  iter: 7919  total_loss: 0.1266  loss_cls: 0.03627  loss_box_reg: 0.08766  loss_rpn_cls: 0.0003547  loss_rpn_loc: 0.003992  time: 1.1286  data_time: 0.0873  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:39:53 d2.utils.events]: \u001b[0m eta: 1:55:32  iter: 7939  total_loss: 0.1433  loss_cls: 0.03624  loss_box_reg: 0.1023  loss_rpn_cls: 0.0005961  loss_rpn_loc: 0.005149  time: 1.1286  data_time: 0.0915  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:40:16 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 7959  total_loss: 0.1498  loss_cls: 0.03958  loss_box_reg: 0.101  loss_rpn_cls: 0.0004909  loss_rpn_loc: 0.004169  time: 1.1286  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:40:38 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:40:38 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:40:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:40:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:40:38 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:40:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:40:38 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:40:38 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:40:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0028 s/iter. Inference: 0.0729 s/iter. Eval: 0.0003 s/iter. Total: 0.0759 s/iter. ETA=0:00:20\n\u001b[32m[12/06 17:40:45 d2.evaluation.evaluator]: \u001b[0mInference done 81/279. Dataloading: 0.0026 s/iter. Inference: 0.0690 s/iter. Eval: 0.0002 s/iter. Total: 0.0719 s/iter. ETA=0:00:14\n\u001b[32m[12/06 17:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0020 s/iter. Inference: 0.0661 s/iter. Eval: 0.0002 s/iter. Total: 0.0684 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0020 s/iter. Inference: 0.0658 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:03\n\u001b[32m[12/06 17:40:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.595487 (0.067867 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:40:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065448 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:40:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:40:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:40:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.455\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.439\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n\u001b[32m[12/06 17:40:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.794 | 75.707 | 45.489 | 12.000 | 31.542 | 50.482 |\n\u001b[32m[12/06 17:40:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.747 | 1          | 70.728 |\n| 2          | 40.574 | 3          | 26.607 | 4          | 61.573 |\n| 5          | 30.538 |            |        |            |        |\n\u001b[32m[12/06 17:40:58 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:40:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:40:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:40:58 d2.evaluation.testing]: \u001b[0mcopypaste: 45.7944,75.7075,45.4894,12.0000,31.5416,50.4820\n\u001b[32m[12/06 17:40:58 d2.utils.events]: \u001b[0m eta: 1:54:46  iter: 7979  total_loss: 0.1345  loss_cls: 0.03304  loss_box_reg: 0.09693  loss_rpn_cls: 0.000175  loss_rpn_loc: 0.004237  time: 1.1286  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:41:21 d2.utils.events]: \u001b[0m eta: 1:54:23  iter: 7999  total_loss: 0.1361  loss_cls: 0.03622  loss_box_reg: 0.09208  loss_rpn_cls: 0.0004828  loss_rpn_loc: 0.004419  time: 1.1286  data_time: 0.0959  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:41:43 d2.utils.events]: \u001b[0m eta: 1:54:00  iter: 8019  total_loss: 0.1353  loss_cls: 0.03493  loss_box_reg: 0.09674  loss_rpn_cls: 0.0003198  loss_rpn_loc: 0.004417  time: 1.1286  data_time: 0.0855  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:42:05 d2.utils.events]: \u001b[0m eta: 1:53:36  iter: 8039  total_loss: 0.1361  loss_cls: 0.03216  loss_box_reg: 0.09396  loss_rpn_cls: 0.0004524  loss_rpn_loc: 0.003581  time: 1.1286  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:42:27 d2.utils.events]: \u001b[0m eta: 1:53:14  iter: 8059  total_loss: 0.1264  loss_cls: 0.03365  loss_box_reg: 0.08677  loss_rpn_cls: 0.0003117  loss_rpn_loc: 0.003589  time: 1.1285  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:42:49 d2.utils.events]: \u001b[0m eta: 1:52:51  iter: 8079  total_loss: 0.1473  loss_cls: 0.03682  loss_box_reg: 0.1024  loss_rpn_cls: 0.0002535  loss_rpn_loc: 0.004248  time: 1.1285  data_time: 0.0884  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:43:12 d2.utils.events]: \u001b[0m eta: 1:52:27  iter: 8099  total_loss: 0.1277  loss_cls: 0.034  loss_box_reg: 0.0896  loss_rpn_cls: 0.000254  loss_rpn_loc: 0.003682  time: 1.1285  data_time: 0.0883  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:43:34 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:43:34 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:43:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:43:35 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:43:35 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:43:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:43:35 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:43:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:43:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0049 s/iter. Inference: 0.0751 s/iter. Eval: 0.0003 s/iter. Total: 0.0803 s/iter. ETA=0:00:21\n\u001b[32m[12/06 17:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0019 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:43:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.492077 (0.067489 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:43:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065153 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:43:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:43:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:43:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.443\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n\u001b[32m[12/06 17:43:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.677 | 76.083 | 44.161 | 24.000 | 31.587 | 48.888 |\n\u001b[32m[12/06 17:43:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.211 | 1          | 69.296 |\n| 2          | 40.579 | 3          | 27.882 | 4          | 59.590 |\n| 5          | 26.501 |            |        |            |        |\n\u001b[32m[12/06 17:43:54 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:43:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:43:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:43:54 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6766,76.0828,44.1614,24.0000,31.5872,48.8882\n\u001b[32m[12/06 17:43:54 d2.utils.events]: \u001b[0m eta: 1:52:05  iter: 8119  total_loss: 0.1468  loss_cls: 0.04205  loss_box_reg: 0.1038  loss_rpn_cls: 0.0005525  loss_rpn_loc: 0.004749  time: 1.1284  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:44:16 d2.utils.events]: \u001b[0m eta: 1:51:41  iter: 8139  total_loss: 0.1401  loss_cls: 0.03364  loss_box_reg: 0.09499  loss_rpn_cls: 0.0002407  loss_rpn_loc: 0.004086  time: 1.1284  data_time: 0.0885  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:44:39 d2.utils.events]: \u001b[0m eta: 1:51:18  iter: 8159  total_loss: 0.1237  loss_cls: 0.02989  loss_box_reg: 0.08602  loss_rpn_cls: 0.0003573  loss_rpn_loc: 0.004473  time: 1.1284  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:45:01 d2.utils.events]: \u001b[0m eta: 1:50:56  iter: 8179  total_loss: 0.1306  loss_cls: 0.03132  loss_box_reg: 0.09461  loss_rpn_cls: 0.0002893  loss_rpn_loc: 0.004517  time: 1.1284  data_time: 0.0963  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:45:24 d2.utils.events]: \u001b[0m eta: 1:50:33  iter: 8199  total_loss: 0.1272  loss_cls: 0.03544  loss_box_reg: 0.08506  loss_rpn_cls: 0.0003537  loss_rpn_loc: 0.004401  time: 1.1284  data_time: 0.0902  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:45:46 d2.utils.events]: \u001b[0m eta: 1:50:10  iter: 8219  total_loss: 0.1348  loss_cls: 0.03411  loss_box_reg: 0.09592  loss_rpn_cls: 0.0004075  loss_rpn_loc: 0.004265  time: 1.1284  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:46:09 d2.utils.events]: \u001b[0m eta: 1:49:46  iter: 8239  total_loss: 0.1195  loss_cls: 0.02928  loss_box_reg: 0.08347  loss_rpn_cls: 0.0001918  loss_rpn_loc: 0.003569  time: 1.1284  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:46:31 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:46:31 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:46:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:46:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:46:31 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:46:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:46:31 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:46:31 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:46:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:46:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0690 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:00:18\n\u001b[32m[12/06 17:46:37 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0014 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0654 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0016 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0656 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0016 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:46:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.073691 (0.065962 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:46:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063929 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:46:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:46:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:46:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.441\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.449\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624\n\u001b[32m[12/06 17:46:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.316 | 76.072 | 44.074 | 14.000 | 31.756 | 50.007 |\n\u001b[32m[12/06 17:46:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.949 | 1          | 69.129 |\n| 2          | 40.722 | 3          | 27.052 | 4          | 59.603 |\n| 5          | 30.439 |            |        |            |        |\n\u001b[32m[12/06 17:46:50 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:46:50 d2.evaluation.testing]: \u001b[0mcopypaste: 45.3158,76.0721,44.0735,14.0000,31.7560,50.0065\n\u001b[32m[12/06 17:46:50 d2.utils.events]: \u001b[0m eta: 1:49:23  iter: 8259  total_loss: 0.1344  loss_cls: 0.034  loss_box_reg: 0.09086  loss_rpn_cls: 0.0006563  loss_rpn_loc: 0.004944  time: 1.1283  data_time: 0.0877  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:47:13 d2.utils.events]: \u001b[0m eta: 1:49:01  iter: 8279  total_loss: 0.1321  loss_cls: 0.02978  loss_box_reg: 0.09942  loss_rpn_cls: 0.000419  loss_rpn_loc: 0.004083  time: 1.1283  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:47:35 d2.utils.events]: \u001b[0m eta: 1:48:38  iter: 8299  total_loss: 0.1099  loss_cls: 0.02987  loss_box_reg: 0.07799  loss_rpn_cls: 0.0001799  loss_rpn_loc: 0.003434  time: 1.1283  data_time: 0.0886  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:47:58 d2.utils.events]: \u001b[0m eta: 1:48:15  iter: 8319  total_loss: 0.1281  loss_cls: 0.03062  loss_box_reg: 0.09042  loss_rpn_cls: 0.000329  loss_rpn_loc: 0.004528  time: 1.1283  data_time: 0.0897  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:48:20 d2.utils.events]: \u001b[0m eta: 1:47:52  iter: 8339  total_loss: 0.1372  loss_cls: 0.03393  loss_box_reg: 0.09868  loss_rpn_cls: 0.0003685  loss_rpn_loc: 0.00444  time: 1.1283  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:48:43 d2.utils.events]: \u001b[0m eta: 1:47:29  iter: 8359  total_loss: 0.1301  loss_cls: 0.0321  loss_box_reg: 0.0933  loss_rpn_cls: 0.000159  loss_rpn_loc: 0.003908  time: 1.1283  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:49:06 d2.utils.events]: \u001b[0m eta: 1:47:06  iter: 8379  total_loss: 0.1402  loss_cls: 0.03568  loss_box_reg: 0.09068  loss_rpn_cls: 0.0003036  loss_rpn_loc: 0.004415  time: 1.1283  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:49:28 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:49:28 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:49:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:49:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:49:28 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:49:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:49:28 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:49:28 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:49:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:49:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0016 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0666 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0020 s/iter. Inference: 0.0663 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0018 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0675 s/iter. ETA=0:00:03\n\u001b[32m[12/06 17:49:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.429524 (0.067261 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:49:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065035 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:49:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:49:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:49:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.460\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625\n\u001b[32m[12/06 17:49:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 46.243 | 75.982 | 45.977 | 12.000 | 31.240 | 50.867 |\n\u001b[32m[12/06 17:49:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 46.190 | 1          | 70.894 |\n| 2          | 41.401 | 3          | 27.605 | 4          | 59.507 |\n| 5          | 31.861 |            |        |            |        |\n\u001b[32m[12/06 17:49:47 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:49:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:49:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:49:47 d2.evaluation.testing]: \u001b[0mcopypaste: 46.2429,75.9821,45.9766,12.0000,31.2396,50.8673\n\u001b[32m[12/06 17:49:47 d2.utils.events]: \u001b[0m eta: 1:46:43  iter: 8399  total_loss: 0.1081  loss_cls: 0.03034  loss_box_reg: 0.07776  loss_rpn_cls: 0.0001584  loss_rpn_loc: 0.004053  time: 1.1283  data_time: 0.0935  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:50:10 d2.utils.events]: \u001b[0m eta: 1:46:20  iter: 8419  total_loss: 0.1254  loss_cls: 0.0332  loss_box_reg: 0.0846  loss_rpn_cls: 0.0002063  loss_rpn_loc: 0.004645  time: 1.1284  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:50:33 d2.utils.events]: \u001b[0m eta: 1:45:58  iter: 8439  total_loss: 0.1409  loss_cls: 0.03503  loss_box_reg: 0.1053  loss_rpn_cls: 0.0004563  loss_rpn_loc: 0.004312  time: 1.1284  data_time: 0.0895  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:50:56 d2.utils.events]: \u001b[0m eta: 1:45:35  iter: 8459  total_loss: 0.1324  loss_cls: 0.0358  loss_box_reg: 0.09076  loss_rpn_cls: 0.0006357  loss_rpn_loc: 0.004357  time: 1.1284  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:51:18 d2.utils.events]: \u001b[0m eta: 1:45:12  iter: 8479  total_loss: 0.117  loss_cls: 0.02958  loss_box_reg: 0.08034  loss_rpn_cls: 0.0003009  loss_rpn_loc: 0.003564  time: 1.1284  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:51:41 d2.utils.events]: \u001b[0m eta: 1:44:49  iter: 8499  total_loss: 0.139  loss_cls: 0.03336  loss_box_reg: 0.09439  loss_rpn_cls: 0.0009244  loss_rpn_loc: 0.004416  time: 1.1284  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:52:03 d2.utils.events]: \u001b[0m eta: 1:44:26  iter: 8519  total_loss: 0.1242  loss_cls: 0.02816  loss_box_reg: 0.08748  loss_rpn_cls: 0.0002051  loss_rpn_loc: 0.003539  time: 1.1284  data_time: 0.0877  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:52:26 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:52:26 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:52:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:52:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:52:26 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:52:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:52:26 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:52:26 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:52:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:52:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0017 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0016 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0660 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:52:42 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0017 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0666 s/iter. ETA=0:00:02\n\u001b[32m[12/06 17:52:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.350028 (0.066971 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:52:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064799 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:52:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:52:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:52:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.453\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n\u001b[32m[12/06 17:52:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.239 | 77.483 | 43.617 | 17.000 | 31.110 | 49.971 |\n\u001b[32m[12/06 17:52:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.523 | 1          | 68.067 |\n| 2          | 40.556 | 3          | 28.229 | 4          | 58.892 |\n| 5          | 32.167 |            |        |            |        |\n\u001b[32m[12/06 17:52:45 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:52:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:52:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:52:45 d2.evaluation.testing]: \u001b[0mcopypaste: 45.2392,77.4833,43.6166,17.0000,31.1105,49.9712\n\u001b[32m[12/06 17:52:45 d2.utils.events]: \u001b[0m eta: 1:44:03  iter: 8539  total_loss: 0.1315  loss_cls: 0.03285  loss_box_reg: 0.1004  loss_rpn_cls: 0.000191  loss_rpn_loc: 0.004925  time: 1.1284  data_time: 0.0905  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:53:07 d2.utils.events]: \u001b[0m eta: 1:43:40  iter: 8559  total_loss: 0.1261  loss_cls: 0.03118  loss_box_reg: 0.08911  loss_rpn_cls: 0.0003758  loss_rpn_loc: 0.004349  time: 1.1283  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:53:29 d2.utils.events]: \u001b[0m eta: 1:43:17  iter: 8579  total_loss: 0.1173  loss_cls: 0.02774  loss_box_reg: 0.08696  loss_rpn_cls: 0.0003468  loss_rpn_loc: 0.004323  time: 1.1283  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:53:52 d2.utils.events]: \u001b[0m eta: 1:42:54  iter: 8599  total_loss: 0.1229  loss_cls: 0.03177  loss_box_reg: 0.08763  loss_rpn_cls: 0.0004568  loss_rpn_loc: 0.003862  time: 1.1283  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:54:15 d2.utils.events]: \u001b[0m eta: 1:42:31  iter: 8619  total_loss: 0.1387  loss_cls: 0.03302  loss_box_reg: 0.1031  loss_rpn_cls: 0.0006564  loss_rpn_loc: 0.003971  time: 1.1283  data_time: 0.0892  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:54:38 d2.utils.events]: \u001b[0m eta: 1:42:09  iter: 8639  total_loss: 0.1325  loss_cls: 0.03049  loss_box_reg: 0.09247  loss_rpn_cls: 0.0004714  loss_rpn_loc: 0.00376  time: 1.1284  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:55:00 d2.utils.events]: \u001b[0m eta: 1:41:45  iter: 8659  total_loss: 0.1362  loss_cls: 0.03181  loss_box_reg: 0.09809  loss_rpn_cls: 0.0004701  loss_rpn_loc: 0.00453  time: 1.1283  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:55:22 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:55:22 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:55:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:55:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:55:22 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:55:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:55:22 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:55:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:55:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0044 s/iter. Inference: 0.0808 s/iter. Eval: 0.0003 s/iter. Total: 0.0854 s/iter. ETA=0:00:22\n\u001b[32m[12/06 17:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 82/279. Dataloading: 0.0024 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0719 s/iter. ETA=0:00:14\n\u001b[32m[12/06 17:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0020 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0687 s/iter. ETA=0:00:08\n\u001b[32m[12/06 17:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0020 s/iter. Inference: 0.0659 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:03\n\u001b[32m[12/06 17:55:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.652514 (0.068075 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:55:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065632 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:55:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:55:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:55:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.39s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n\u001b[32m[12/06 17:55:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.722 | 75.247 | 44.428 | 12.000 | 30.677 | 49.266 |\n\u001b[32m[12/06 17:55:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.257 | 1          | 69.680 |\n| 2          | 39.465 | 3          | 25.685 | 4          | 60.082 |\n| 5          | 30.162 |            |        |            |        |\n\u001b[32m[12/06 17:55:42 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:55:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:55:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:55:42 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7219,75.2469,44.4276,12.0000,30.6771,49.2657\n\u001b[32m[12/06 17:55:42 d2.utils.events]: \u001b[0m eta: 1:41:23  iter: 8679  total_loss: 0.1269  loss_cls: 0.03264  loss_box_reg: 0.0896  loss_rpn_cls: 0.0004501  loss_rpn_loc: 0.004391  time: 1.1283  data_time: 0.0918  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:56:04 d2.utils.events]: \u001b[0m eta: 1:41:00  iter: 8699  total_loss: 0.1064  loss_cls: 0.02648  loss_box_reg: 0.07433  loss_rpn_cls: 0.0005637  loss_rpn_loc: 0.003569  time: 1.1283  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:56:27 d2.utils.events]: \u001b[0m eta: 1:40:38  iter: 8719  total_loss: 0.1463  loss_cls: 0.03446  loss_box_reg: 0.1066  loss_rpn_cls: 0.0005257  loss_rpn_loc: 0.004498  time: 1.1283  data_time: 0.0956  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:56:50 d2.utils.events]: \u001b[0m eta: 1:40:15  iter: 8739  total_loss: 0.1281  loss_cls: 0.03171  loss_box_reg: 0.09186  loss_rpn_cls: 0.0002339  loss_rpn_loc: 0.00422  time: 1.1283  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:57:12 d2.utils.events]: \u001b[0m eta: 1:39:53  iter: 8759  total_loss: 0.1362  loss_cls: 0.0313  loss_box_reg: 0.1025  loss_rpn_cls: 0.0003157  loss_rpn_loc: 0.004016  time: 1.1283  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:57:35 d2.utils.events]: \u001b[0m eta: 1:39:31  iter: 8779  total_loss: 0.1277  loss_cls: 0.02995  loss_box_reg: 0.08947  loss_rpn_cls: 0.0001921  loss_rpn_loc: 0.003646  time: 1.1283  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:57:57 d2.utils.events]: \u001b[0m eta: 1:39:07  iter: 8799  total_loss: 0.1129  loss_cls: 0.02807  loss_box_reg: 0.08006  loss_rpn_cls: 0.0002529  loss_rpn_loc: 0.003533  time: 1.1283  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:58:20 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 17:58:20 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 17:58:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 17:58:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 17:58:20 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 17:58:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 17:58:20 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 17:58:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 17:58:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 17:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0011 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 17:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0016 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:12\n\u001b[32m[12/06 17:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0017 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:07\n\u001b[32m[12/06 17:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 232/279. Dataloading: 0.0020 s/iter. Inference: 0.0659 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:03\n\u001b[32m[12/06 17:58:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.587905 (0.067839 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:58:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065432 s / iter per device, on 1 devices)\n\u001b[32m[12/06 17:58:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 17:58:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 17:58:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.447\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n\u001b[32m[12/06 17:58:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.341 | 75.719 | 43.716 | 14.667 | 30.883 | 49.012 |\n\u001b[32m[12/06 17:58:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.814 | 1          | 68.541 |\n| 2          | 38.040 | 3          | 28.069 | 4          | 59.028 |\n| 5          | 27.555 |            |        |            |        |\n\u001b[32m[12/06 17:58:39 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 17:58:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 17:58:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 17:58:39 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3412,75.7195,43.7157,14.6667,30.8832,49.0121\n\u001b[32m[12/06 17:58:39 d2.utils.events]: \u001b[0m eta: 1:38:45  iter: 8819  total_loss: 0.1145  loss_cls: 0.02816  loss_box_reg: 0.08065  loss_rpn_cls: 0.0001913  loss_rpn_loc: 0.003824  time: 1.1283  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:59:01 d2.utils.events]: \u001b[0m eta: 1:38:22  iter: 8839  total_loss: 0.1101  loss_cls: 0.02953  loss_box_reg: 0.07401  loss_rpn_cls: 0.0002718  loss_rpn_loc: 0.003707  time: 1.1282  data_time: 0.0871  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:59:24 d2.utils.events]: \u001b[0m eta: 1:38:00  iter: 8859  total_loss: 0.1293  loss_cls: 0.03278  loss_box_reg: 0.09548  loss_rpn_cls: 0.0001661  loss_rpn_loc: 0.004459  time: 1.1282  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 17:59:47 d2.utils.events]: \u001b[0m eta: 1:37:38  iter: 8879  total_loss: 0.132  loss_cls: 0.03229  loss_box_reg: 0.0875  loss_rpn_cls: 0.0004881  loss_rpn_loc: 0.004158  time: 1.1283  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:00:10 d2.utils.events]: \u001b[0m eta: 1:37:15  iter: 8899  total_loss: 0.1294  loss_cls: 0.03352  loss_box_reg: 0.09112  loss_rpn_cls: 0.0003601  loss_rpn_loc: 0.004542  time: 1.1283  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:00:32 d2.utils.events]: \u001b[0m eta: 1:36:53  iter: 8919  total_loss: 0.1322  loss_cls: 0.03343  loss_box_reg: 0.09768  loss_rpn_cls: 0.0001679  loss_rpn_loc: 0.003902  time: 1.1283  data_time: 0.0946  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:00:55 d2.utils.events]: \u001b[0m eta: 1:36:29  iter: 8939  total_loss: 0.1225  loss_cls: 0.03152  loss_box_reg: 0.08767  loss_rpn_cls: 0.0003405  loss_rpn_loc: 0.004369  time: 1.1283  data_time: 0.0920  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:01:18 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:01:18 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:01:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:01:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:01:18 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:01:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:01:18 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:01:18 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:01:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0054 s/iter. Inference: 0.0707 s/iter. Eval: 0.0003 s/iter. Total: 0.0764 s/iter. ETA=0:00:20\n\u001b[32m[12/06 18:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0018 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:01:29 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0017 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0017 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0666 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:01:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.233856 (0.066547 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:01:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064400 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:01:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:01:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:01:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612\n\u001b[32m[12/06 18:01:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.998 | 75.955 | 45.224 | 12.000 | 31.523 | 49.238 |\n\u001b[32m[12/06 18:01:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.875 | 1          | 70.652 |\n| 2          | 39.087 | 3          | 27.228 | 4          | 59.774 |\n| 5          | 28.373 |            |        |            |        |\n\u001b[32m[12/06 18:01:37 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:01:37 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9982,75.9550,45.2243,12.0000,31.5226,49.2381\n\u001b[32m[12/06 18:01:37 d2.utils.events]: \u001b[0m eta: 1:36:07  iter: 8959  total_loss: 0.1219  loss_cls: 0.03082  loss_box_reg: 0.08282  loss_rpn_cls: 0.0002042  loss_rpn_loc: 0.003656  time: 1.1283  data_time: 0.0964  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:01:59 d2.utils.events]: \u001b[0m eta: 1:35:42  iter: 8979  total_loss: 0.1346  loss_cls: 0.0346  loss_box_reg: 0.09548  loss_rpn_cls: 0.0006306  loss_rpn_loc: 0.005347  time: 1.1283  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:02:21 d2.utils.events]: \u001b[0m eta: 1:35:20  iter: 8999  total_loss: 0.1153  loss_cls: 0.0277  loss_box_reg: 0.07797  loss_rpn_cls: 0.0003826  loss_rpn_loc: 0.003826  time: 1.1283  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:02:44 d2.utils.events]: \u001b[0m eta: 1:34:57  iter: 9019  total_loss: 0.122  loss_cls: 0.02882  loss_box_reg: 0.0903  loss_rpn_cls: 0.0001656  loss_rpn_loc: 0.004136  time: 1.1282  data_time: 0.0866  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:03:06 d2.utils.events]: \u001b[0m eta: 1:34:34  iter: 9039  total_loss: 0.1226  loss_cls: 0.02849  loss_box_reg: 0.09063  loss_rpn_cls: 0.0003265  loss_rpn_loc: 0.003474  time: 1.1282  data_time: 0.0884  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:03:29 d2.utils.events]: \u001b[0m eta: 1:34:11  iter: 9059  total_loss: 0.1242  loss_cls: 0.03082  loss_box_reg: 0.08584  loss_rpn_cls: 0.0005031  loss_rpn_loc: 0.003552  time: 1.1282  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:03:52 d2.utils.events]: \u001b[0m eta: 1:33:49  iter: 9079  total_loss: 0.1233  loss_cls: 0.02873  loss_box_reg: 0.08671  loss_rpn_cls: 0.0002495  loss_rpn_loc: 0.003754  time: 1.1283  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:04:14 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:04:14 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:04:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:04:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:04:14 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:04:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:04:14 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:04:14 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:04:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0687 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:18\n\u001b[32m[12/06 18:04:20 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0022 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:13\n\u001b[32m[12/06 18:04:25 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0019 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0679 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:04:30 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0019 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0676 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:04:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.461814 (0.067379 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:04:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065055 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:04:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:04:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:04:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.450\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n\u001b[32m[12/06 18:04:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.930 | 75.573 | 44.305 | 12.000 | 31.673 | 49.650 |\n\u001b[32m[12/06 18:04:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.224 | 1          | 68.215 |\n| 2          | 40.566 | 3          | 25.604 | 4          | 60.609 |\n| 5          | 31.362 |            |        |            |        |\n\u001b[32m[12/06 18:04:33 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:04:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:04:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:04:33 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9300,75.5727,44.3046,12.0000,31.6727,49.6502\n\u001b[32m[12/06 18:04:33 d2.utils.events]: \u001b[0m eta: 1:33:26  iter: 9099  total_loss: 0.1207  loss_cls: 0.03085  loss_box_reg: 0.08505  loss_rpn_cls: 0.0001659  loss_rpn_loc: 0.004295  time: 1.1282  data_time: 0.0849  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:04:56 d2.utils.events]: \u001b[0m eta: 1:33:03  iter: 9119  total_loss: 0.112  loss_cls: 0.02812  loss_box_reg: 0.07763  loss_rpn_cls: 0.0001703  loss_rpn_loc: 0.003612  time: 1.1282  data_time: 0.0960  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:05:18 d2.utils.events]: \u001b[0m eta: 1:32:41  iter: 9139  total_loss: 0.1141  loss_cls: 0.02826  loss_box_reg: 0.08292  loss_rpn_cls: 0.0005969  loss_rpn_loc: 0.004066  time: 1.1282  data_time: 0.0915  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:05:41 d2.utils.events]: \u001b[0m eta: 1:32:18  iter: 9159  total_loss: 0.1355  loss_cls: 0.03429  loss_box_reg: 0.0966  loss_rpn_cls: 0.0003265  loss_rpn_loc: 0.004743  time: 1.1282  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:06:03 d2.utils.events]: \u001b[0m eta: 1:31:55  iter: 9179  total_loss: 0.1168  loss_cls: 0.03131  loss_box_reg: 0.08108  loss_rpn_cls: 0.0003154  loss_rpn_loc: 0.003703  time: 1.1282  data_time: 0.0904  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:06:26 d2.utils.events]: \u001b[0m eta: 1:31:33  iter: 9199  total_loss: 0.1336  loss_cls: 0.03164  loss_box_reg: 0.09406  loss_rpn_cls: 0.0002793  loss_rpn_loc: 0.004322  time: 1.1282  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:06:48 d2.utils.events]: \u001b[0m eta: 1:31:10  iter: 9219  total_loss: 0.09481  loss_cls: 0.02355  loss_box_reg: 0.06839  loss_rpn_cls: 0.0001579  loss_rpn_loc: 0.003488  time: 1.1282  data_time: 0.0905  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:07:11 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:07:11 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:07:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:07:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:07:11 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:07:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:07:11 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:07:11 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:07:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:07:17 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0016 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:07:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.385338 (0.067100 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:07:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064826 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:07:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:07:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:07:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.441\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.437\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n\u001b[32m[12/06 18:07:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.383 | 76.509 | 44.140 | 12.000 | 29.685 | 49.722 |\n\u001b[32m[12/06 18:07:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.329 | 1          | 64.767 |\n| 2          | 40.699 | 3          | 26.176 | 4          | 60.026 |\n| 5          | 31.298 |            |        |            |        |\n\u001b[32m[12/06 18:07:30 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:07:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:07:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:07:30 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3825,76.5091,44.1397,12.0000,29.6851,49.7218\n\u001b[32m[12/06 18:07:30 d2.utils.events]: \u001b[0m eta: 1:30:48  iter: 9239  total_loss: 0.1192  loss_cls: 0.02797  loss_box_reg: 0.08608  loss_rpn_cls: 0.0002516  loss_rpn_loc: 0.003797  time: 1.1282  data_time: 0.0957  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:07:53 d2.utils.events]: \u001b[0m eta: 1:30:25  iter: 9259  total_loss: 0.1342  loss_cls: 0.02967  loss_box_reg: 0.09791  loss_rpn_cls: 0.0001494  loss_rpn_loc: 0.003888  time: 1.1282  data_time: 0.0896  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:08:15 d2.utils.events]: \u001b[0m eta: 1:30:02  iter: 9279  total_loss: 0.1065  loss_cls: 0.02539  loss_box_reg: 0.07655  loss_rpn_cls: 0.0003143  loss_rpn_loc: 0.003343  time: 1.1282  data_time: 0.0946  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:08:38 d2.utils.events]: \u001b[0m eta: 1:29:40  iter: 9299  total_loss: 0.1217  loss_cls: 0.03092  loss_box_reg: 0.09253  loss_rpn_cls: 0.0001721  loss_rpn_loc: 0.004838  time: 1.1282  data_time: 0.0904  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:09:01 d2.utils.events]: \u001b[0m eta: 1:29:16  iter: 9319  total_loss: 0.1245  loss_cls: 0.031  loss_box_reg: 0.08653  loss_rpn_cls: 0.0003158  loss_rpn_loc: 0.004512  time: 1.1282  data_time: 0.0899  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:09:23 d2.utils.events]: \u001b[0m eta: 1:28:54  iter: 9339  total_loss: 0.1149  loss_cls: 0.02754  loss_box_reg: 0.08019  loss_rpn_cls: 0.0001227  loss_rpn_loc: 0.003655  time: 1.1282  data_time: 0.0894  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:09:45 d2.utils.events]: \u001b[0m eta: 1:28:31  iter: 9359  total_loss: 0.1221  loss_cls: 0.02739  loss_box_reg: 0.08815  loss_rpn_cls: 0.0002579  loss_rpn_loc: 0.004459  time: 1.1282  data_time: 0.0938  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:10:08 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:10:08 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:10:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:10:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:10:08 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:10:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:10:08 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:10:08 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:10:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0645 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0017 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0017 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:10:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.058818 (0.065908 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:10:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063767 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:10:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:10:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:10:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.447\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n\u001b[32m[12/06 18:10:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.382 | 75.554 | 44.759 | 18.000 | 30.534 | 50.144 |\n\u001b[32m[12/06 18:10:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.910 | 1          | 68.790 |\n| 2          | 41.378 | 3          | 26.954 | 4          | 60.698 |\n| 5          | 30.562 |            |        |            |        |\n\u001b[32m[12/06 18:10:27 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:10:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:10:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:10:27 d2.evaluation.testing]: \u001b[0mcopypaste: 45.3817,75.5540,44.7591,18.0000,30.5340,50.1442\n\u001b[32m[12/06 18:10:27 d2.utils.events]: \u001b[0m eta: 1:28:08  iter: 9379  total_loss: 0.1062  loss_cls: 0.02595  loss_box_reg: 0.07656  loss_rpn_cls: 0.0002849  loss_rpn_loc: 0.003983  time: 1.1282  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:10:50 d2.utils.events]: \u001b[0m eta: 1:27:46  iter: 9399  total_loss: 0.1269  loss_cls: 0.03279  loss_box_reg: 0.08429  loss_rpn_cls: 0.0002857  loss_rpn_loc: 0.004624  time: 1.1282  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:11:12 d2.utils.events]: \u001b[0m eta: 1:27:23  iter: 9419  total_loss: 0.128  loss_cls: 0.03088  loss_box_reg: 0.09005  loss_rpn_cls: 0.0004044  loss_rpn_loc: 0.004048  time: 1.1282  data_time: 0.0901  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:11:35 d2.utils.events]: \u001b[0m eta: 1:27:00  iter: 9439  total_loss: 0.1192  loss_cls: 0.03014  loss_box_reg: 0.08539  loss_rpn_cls: 0.0001529  loss_rpn_loc: 0.003858  time: 1.1282  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:11:57 d2.utils.events]: \u001b[0m eta: 1:26:37  iter: 9459  total_loss: 0.1035  loss_cls: 0.02557  loss_box_reg: 0.07554  loss_rpn_cls: 0.0002069  loss_rpn_loc: 0.003435  time: 1.1282  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:12:20 d2.utils.events]: \u001b[0m eta: 1:26:14  iter: 9479  total_loss: 0.1161  loss_cls: 0.02628  loss_box_reg: 0.08307  loss_rpn_cls: 0.0003416  loss_rpn_loc: 0.004231  time: 1.1282  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:12:42 d2.utils.events]: \u001b[0m eta: 1:25:52  iter: 9499  total_loss: 0.1221  loss_cls: 0.02917  loss_box_reg: 0.08953  loss_rpn_cls: 0.0002023  loss_rpn_loc: 0.00331  time: 1.1282  data_time: 0.0866  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:13:05 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:13:05 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:13:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:13:05 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:13:05 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:13:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:13:05 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:13:05 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:13:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0650 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0016 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0022 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0680 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0020 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:13:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.386598 (0.067104 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:13:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064699 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:13:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:13:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:13:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.435\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.425\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n\u001b[32m[12/06 18:13:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.023 | 75.983 | 43.486 | 16.000 | 32.220 | 48.580 |\n\u001b[32m[12/06 18:13:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.961 | 1          | 68.282 |\n| 2          | 40.190 | 3          | 24.396 | 4          | 59.966 |\n| 5          | 28.346 |            |        |            |        |\n\u001b[32m[12/06 18:13:24 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:13:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:13:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:13:24 d2.evaluation.testing]: \u001b[0mcopypaste: 44.0233,75.9831,43.4860,16.0000,32.2203,48.5799\n\u001b[32m[12/06 18:13:24 d2.utils.events]: \u001b[0m eta: 1:25:29  iter: 9519  total_loss: 0.1279  loss_cls: 0.02857  loss_box_reg: 0.09234  loss_rpn_cls: 0.0002502  loss_rpn_loc: 0.00368  time: 1.1281  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:13:46 d2.utils.events]: \u001b[0m eta: 1:25:06  iter: 9539  total_loss: 0.1236  loss_cls: 0.03007  loss_box_reg: 0.08653  loss_rpn_cls: 0.0002981  loss_rpn_loc: 0.003824  time: 1.1281  data_time: 0.0847  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:14:09 d2.utils.events]: \u001b[0m eta: 1:24:44  iter: 9559  total_loss: 0.1066  loss_cls: 0.02498  loss_box_reg: 0.07681  loss_rpn_cls: 0.000365  loss_rpn_loc: 0.003806  time: 1.1281  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:14:31 d2.utils.events]: \u001b[0m eta: 1:24:21  iter: 9579  total_loss: 0.1282  loss_cls: 0.03153  loss_box_reg: 0.08876  loss_rpn_cls: 0.0003434  loss_rpn_loc: 0.004233  time: 1.1281  data_time: 0.0895  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:14:54 d2.utils.events]: \u001b[0m eta: 1:23:59  iter: 9599  total_loss: 0.123  loss_cls: 0.03186  loss_box_reg: 0.08771  loss_rpn_cls: 0.000674  loss_rpn_loc: 0.004747  time: 1.1281  data_time: 0.0981  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:15:16 d2.utils.events]: \u001b[0m eta: 1:23:36  iter: 9619  total_loss: 0.1377  loss_cls: 0.03303  loss_box_reg: 0.09727  loss_rpn_cls: 0.0001653  loss_rpn_loc: 0.004006  time: 1.1281  data_time: 0.0871  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:15:39 d2.utils.events]: \u001b[0m eta: 1:23:13  iter: 9639  total_loss: 0.1373  loss_cls: 0.03248  loss_box_reg: 0.09854  loss_rpn_cls: 0.0002867  loss_rpn_loc: 0.004231  time: 1.1281  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:16:02 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:16:02 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:16:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:16:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:16:02 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:16:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:16:02 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:16:02 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:16:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0017 s/iter. Inference: 0.0648 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0016 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.231115 (0.066537 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:16:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064364 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:16:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:16:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:16:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.23s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.443\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n\u001b[32m[12/06 18:16:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.155 | 75.086 | 44.237 | 14.667 | 31.457 | 48.657 |\n\u001b[32m[12/06 18:16:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 40.881 | 1          | 68.066 |\n| 2          | 39.623 | 3          | 25.659 | 4          | 60.049 |\n| 5          | 30.652 |            |        |            |        |\n\u001b[32m[12/06 18:16:21 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:16:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:16:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:16:21 d2.evaluation.testing]: \u001b[0mcopypaste: 44.1550,75.0859,44.2367,14.6667,31.4570,48.6570\n\u001b[32m[12/06 18:16:21 d2.utils.events]: \u001b[0m eta: 1:22:51  iter: 9659  total_loss: 0.1124  loss_cls: 0.02757  loss_box_reg: 0.08038  loss_rpn_cls: 0.0001557  loss_rpn_loc: 0.00385  time: 1.1281  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:16:43 d2.utils.events]: \u001b[0m eta: 1:22:28  iter: 9679  total_loss: 0.1129  loss_cls: 0.02597  loss_box_reg: 0.08112  loss_rpn_cls: 0.0001541  loss_rpn_loc: 0.003738  time: 1.1281  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:17:06 d2.utils.events]: \u001b[0m eta: 1:22:05  iter: 9699  total_loss: 0.1256  loss_cls: 0.0288  loss_box_reg: 0.08994  loss_rpn_cls: 0.0002832  loss_rpn_loc: 0.004474  time: 1.1281  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:17:29 d2.utils.events]: \u001b[0m eta: 1:21:42  iter: 9719  total_loss: 0.1011  loss_cls: 0.02796  loss_box_reg: 0.07009  loss_rpn_cls: 0.0002569  loss_rpn_loc: 0.003711  time: 1.1282  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:17:51 d2.utils.events]: \u001b[0m eta: 1:21:19  iter: 9739  total_loss: 0.1207  loss_cls: 0.02931  loss_box_reg: 0.08651  loss_rpn_cls: 0.0003695  loss_rpn_loc: 0.004278  time: 1.1282  data_time: 0.0862  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:18:14 d2.utils.events]: \u001b[0m eta: 1:20:56  iter: 9759  total_loss: 0.1118  loss_cls: 0.02907  loss_box_reg: 0.07884  loss_rpn_cls: 0.000166  loss_rpn_loc: 0.003703  time: 1.1282  data_time: 0.0940  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:18:36 d2.utils.events]: \u001b[0m eta: 1:20:33  iter: 9779  total_loss: 0.1143  loss_cls: 0.0277  loss_box_reg: 0.07938  loss_rpn_cls: 0.0004733  loss_rpn_loc: 0.003618  time: 1.1281  data_time: 0.0878  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:18:59 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:18:59 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:18:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:18:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:18:59 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:18:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:18:59 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:18:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:18:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0022 s/iter. Inference: 0.0669 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:13\n\u001b[32m[12/06 18:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0021 s/iter. Inference: 0.0661 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0019 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0675 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:19:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.571282 (0.067778 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:19:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065345 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:19:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:19:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:19:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.453\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n\u001b[32m[12/06 18:19:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.191 | 75.403 | 45.292 | 12.000 | 32.120 | 49.824 |\n\u001b[32m[12/06 18:19:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.612 | 1          | 68.535 |\n| 2          | 40.889 | 3          | 26.558 | 4          | 59.580 |\n| 5          | 30.975 |            |        |            |        |\n\u001b[32m[12/06 18:19:18 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:19:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:19:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:19:18 d2.evaluation.testing]: \u001b[0mcopypaste: 45.1915,75.4029,45.2920,12.0000,32.1205,49.8244\n\u001b[32m[12/06 18:19:18 d2.utils.events]: \u001b[0m eta: 1:20:10  iter: 9799  total_loss: 0.1174  loss_cls: 0.02563  loss_box_reg: 0.0866  loss_rpn_cls: 0.000126  loss_rpn_loc: 0.003852  time: 1.1281  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:19:41 d2.utils.events]: \u001b[0m eta: 1:19:47  iter: 9819  total_loss: 0.1147  loss_cls: 0.02673  loss_box_reg: 0.08244  loss_rpn_cls: 0.0005386  loss_rpn_loc: 0.003817  time: 1.1281  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:20:03 d2.utils.events]: \u001b[0m eta: 1:19:24  iter: 9839  total_loss: 0.1178  loss_cls: 0.03127  loss_box_reg: 0.0835  loss_rpn_cls: 0.0003623  loss_rpn_loc: 0.003996  time: 1.1281  data_time: 0.0875  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:20:26 d2.utils.events]: \u001b[0m eta: 1:19:01  iter: 9859  total_loss: 0.1095  loss_cls: 0.02826  loss_box_reg: 0.0736  loss_rpn_cls: 0.0004956  loss_rpn_loc: 0.003434  time: 1.1281  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:20:48 d2.utils.events]: \u001b[0m eta: 1:18:38  iter: 9879  total_loss: 0.109  loss_cls: 0.02843  loss_box_reg: 0.07858  loss_rpn_cls: 0.000201  loss_rpn_loc: 0.003303  time: 1.1281  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:21:11 d2.utils.events]: \u001b[0m eta: 1:18:14  iter: 9899  total_loss: 0.1097  loss_cls: 0.02468  loss_box_reg: 0.07654  loss_rpn_cls: 0.0003759  loss_rpn_loc: 0.003498  time: 1.1281  data_time: 0.0916  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:21:33 d2.utils.events]: \u001b[0m eta: 1:17:52  iter: 9919  total_loss: 0.1258  loss_cls: 0.03192  loss_box_reg: 0.09412  loss_rpn_cls: 0.000509  loss_rpn_loc: 0.004209  time: 1.1281  data_time: 0.0922  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:21:56 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:21:56 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:21:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:21:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:21:56 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:21:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:21:56 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:21:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:21:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0016 s/iter. Inference: 0.0648 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0015 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0017 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:22:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.439766 (0.067298 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:22:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065039 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:22:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:22:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:22:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.426\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n\u001b[32m[12/06 18:22:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.160 | 74.855 | 42.650 | 14.000 | 29.857 | 49.176 |\n\u001b[32m[12/06 18:22:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.618 | 1          | 66.895 |\n| 2          | 39.619 | 3          | 26.150 | 4          | 59.376 |\n| 5          | 29.303 |            |        |            |        |\n\u001b[32m[12/06 18:22:15 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:22:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:22:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:22:16 d2.evaluation.testing]: \u001b[0mcopypaste: 44.1601,74.8549,42.6499,14.0000,29.8570,49.1757\n\u001b[32m[12/06 18:22:16 d2.utils.events]: \u001b[0m eta: 1:17:29  iter: 9939  total_loss: 0.1042  loss_cls: 0.0281  loss_box_reg: 0.07446  loss_rpn_cls: 0.0001831  loss_rpn_loc: 0.003581  time: 1.1281  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:22:38 d2.utils.events]: \u001b[0m eta: 1:17:06  iter: 9959  total_loss: 0.1185  loss_cls: 0.02991  loss_box_reg: 0.08472  loss_rpn_cls: 0.0002282  loss_rpn_loc: 0.003972  time: 1.1281  data_time: 0.0900  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:23:01 d2.utils.events]: \u001b[0m eta: 1:16:44  iter: 9979  total_loss: 0.1306  loss_cls: 0.02841  loss_box_reg: 0.08886  loss_rpn_cls: 0.0002983  loss_rpn_loc: 0.004189  time: 1.1282  data_time: 0.0947  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:23:24 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 9999  total_loss: 0.1164  loss_cls: 0.03243  loss_box_reg: 0.07742  loss_rpn_cls: 0.0003237  loss_rpn_loc: 0.003933  time: 1.1282  data_time: 0.0917  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:23:47 d2.utils.events]: \u001b[0m eta: 1:15:58  iter: 10019  total_loss: 0.1054  loss_cls: 0.02663  loss_box_reg: 0.07605  loss_rpn_cls: 0.0001994  loss_rpn_loc: 0.003017  time: 1.1282  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:24:09 d2.utils.events]: \u001b[0m eta: 1:15:35  iter: 10039  total_loss: 0.1187  loss_cls: 0.02649  loss_box_reg: 0.08671  loss_rpn_cls: 0.0002018  loss_rpn_loc: 0.003521  time: 1.1281  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:24:32 d2.utils.events]: \u001b[0m eta: 1:15:13  iter: 10059  total_loss: 0.1181  loss_cls: 0.02783  loss_box_reg: 0.07933  loss_rpn_cls: 0.00023  loss_rpn_loc: 0.003934  time: 1.1281  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:24:55 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:24:55 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:24:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:24:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:24:55 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:24:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:24:55 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:24:55 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:24:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0019 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0017 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:25:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.204578 (0.066440 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:25:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064294 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:25:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:25:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:25:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.562\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n\u001b[32m[12/06 18:25:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.450 | 75.436 | 44.731 | 12.000 | 32.954 | 48.995 |\n\u001b[32m[12/06 18:25:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.202 | 1          | 66.382 |\n| 2          | 40.653 | 3          | 25.168 | 4          | 61.528 |\n| 5          | 29.767 |            |        |            |        |\n\u001b[32m[12/06 18:25:14 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:25:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:25:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:25:14 d2.evaluation.testing]: \u001b[0mcopypaste: 44.4501,75.4364,44.7311,12.0000,32.9542,48.9955\n\u001b[32m[12/06 18:25:14 d2.utils.events]: \u001b[0m eta: 1:14:50  iter: 10079  total_loss: 0.1132  loss_cls: 0.02817  loss_box_reg: 0.08039  loss_rpn_cls: 0.0005392  loss_rpn_loc: 0.004048  time: 1.1281  data_time: 0.0965  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:25:36 d2.utils.events]: \u001b[0m eta: 1:14:27  iter: 10099  total_loss: 0.1195  loss_cls: 0.0306  loss_box_reg: 0.0844  loss_rpn_cls: 0.0002334  loss_rpn_loc: 0.003685  time: 1.1282  data_time: 0.0987  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:25:59 d2.utils.events]: \u001b[0m eta: 1:14:04  iter: 10119  total_loss: 0.1068  loss_cls: 0.02572  loss_box_reg: 0.07512  loss_rpn_cls: 0.0003357  loss_rpn_loc: 0.003875  time: 1.1281  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:26:22 d2.utils.events]: \u001b[0m eta: 1:13:42  iter: 10139  total_loss: 0.1047  loss_cls: 0.02567  loss_box_reg: 0.0754  loss_rpn_cls: 0.0002274  loss_rpn_loc: 0.003538  time: 1.1282  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:26:45 d2.utils.events]: \u001b[0m eta: 1:13:18  iter: 10159  total_loss: 0.1191  loss_cls: 0.03052  loss_box_reg: 0.08591  loss_rpn_cls: 0.0002035  loss_rpn_loc: 0.004408  time: 1.1282  data_time: 0.0945  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:27:07 d2.utils.events]: \u001b[0m eta: 1:12:56  iter: 10179  total_loss: 0.1194  loss_cls: 0.03014  loss_box_reg: 0.08547  loss_rpn_cls: 0.0001163  loss_rpn_loc: 0.003366  time: 1.1282  data_time: 0.0946  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:27:30 d2.utils.events]: \u001b[0m eta: 1:12:32  iter: 10199  total_loss: 0.1323  loss_cls: 0.03462  loss_box_reg: 0.09143  loss_rpn_cls: 0.0001452  loss_rpn_loc: 0.003564  time: 1.1282  data_time: 0.0971  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:27:52 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:27:52 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:27:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:27:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:27:52 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:27:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:27:52 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:27:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:27:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0024 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0680 s/iter. ETA=0:00:18\n\u001b[32m[12/06 18:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0023 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:13\n\u001b[32m[12/06 18:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 159/279. Dataloading: 0.0020 s/iter. Inference: 0.0658 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0020 s/iter. Inference: 0.0655 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:03\n\u001b[32m[12/06 18:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.506162 (0.067541 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:28:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065128 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:28:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:28:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:28:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.433\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n\u001b[32m[12/06 18:28:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.903 | 75.021 | 45.068 | 12.000 | 31.923 | 48.672 |\n\u001b[32m[12/06 18:28:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 39.899 | 1          | 65.221 |\n| 2          | 39.769 | 3          | 26.489 | 4          | 61.096 |\n| 5          | 30.942 |            |        |            |        |\n\u001b[32m[12/06 18:28:12 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:28:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:28:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:28:12 d2.evaluation.testing]: \u001b[0mcopypaste: 43.9026,75.0214,45.0676,12.0000,31.9231,48.6721\n\u001b[32m[12/06 18:28:12 d2.utils.events]: \u001b[0m eta: 1:12:09  iter: 10219  total_loss: 0.1272  loss_cls: 0.03246  loss_box_reg: 0.08846  loss_rpn_cls: 0.0002847  loss_rpn_loc: 0.004432  time: 1.1282  data_time: 0.0886  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:28:35 d2.utils.events]: \u001b[0m eta: 1:11:47  iter: 10239  total_loss: 0.1068  loss_cls: 0.02585  loss_box_reg: 0.07599  loss_rpn_cls: 0.0002237  loss_rpn_loc: 0.003604  time: 1.1282  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:28:57 d2.utils.events]: \u001b[0m eta: 1:11:24  iter: 10259  total_loss: 0.1229  loss_cls: 0.02894  loss_box_reg: 0.08589  loss_rpn_cls: 0.0003837  loss_rpn_loc: 0.004425  time: 1.1282  data_time: 0.0861  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:29:19 d2.utils.events]: \u001b[0m eta: 1:11:01  iter: 10279  total_loss: 0.1354  loss_cls: 0.03406  loss_box_reg: 0.09336  loss_rpn_cls: 0.0002792  loss_rpn_loc: 0.003806  time: 1.1282  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:29:42 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 10299  total_loss: 0.1121  loss_cls: 0.02616  loss_box_reg: 0.08351  loss_rpn_cls: 0.0001815  loss_rpn_loc: 0.003915  time: 1.1282  data_time: 0.0947  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:30:05 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 10319  total_loss: 0.1039  loss_cls: 0.02676  loss_box_reg: 0.07527  loss_rpn_cls: 0.0002585  loss_rpn_loc: 0.003753  time: 1.1283  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:30:28 d2.utils.events]: \u001b[0m eta: 1:09:52  iter: 10339  total_loss: 0.09943  loss_cls: 0.02445  loss_box_reg: 0.07148  loss_rpn_cls: 0.0001569  loss_rpn_loc: 0.003396  time: 1.1282  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:30:50 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:30:50 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:30:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:30:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:30:50 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:30:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:30:50 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:30:50 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:30:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0650 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0018 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0018 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:31:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.427128 (0.067252 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:31:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064711 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:31:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:31:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:31:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.563\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n\u001b[32m[12/06 18:31:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.790 | 75.522 | 44.940 | 12.000 | 31.898 | 49.558 |\n\u001b[32m[12/06 18:31:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.000 | 1          | 67.272 |\n| 2          | 40.171 | 3          | 26.586 | 4          | 60.329 |\n| 5          | 31.383 |            |        |            |        |\n\u001b[32m[12/06 18:31:09 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:31:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:31:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:31:09 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7899,75.5221,44.9395,12.0000,31.8984,49.5577\n\u001b[32m[12/06 18:31:09 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 10359  total_loss: 0.1084  loss_cls: 0.0271  loss_box_reg: 0.07898  loss_rpn_cls: 0.0001619  loss_rpn_loc: 0.00386  time: 1.1282  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:31:31 d2.utils.events]: \u001b[0m eta: 1:09:06  iter: 10379  total_loss: 0.1086  loss_cls: 0.02758  loss_box_reg: 0.07898  loss_rpn_cls: 0.0001171  loss_rpn_loc: 0.003283  time: 1.1282  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:31:54 d2.utils.events]: \u001b[0m eta: 1:08:43  iter: 10399  total_loss: 0.1064  loss_cls: 0.02934  loss_box_reg: 0.07517  loss_rpn_cls: 0.0003902  loss_rpn_loc: 0.00396  time: 1.1282  data_time: 0.0945  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:32:16 d2.utils.events]: \u001b[0m eta: 1:08:20  iter: 10419  total_loss: 0.1039  loss_cls: 0.02686  loss_box_reg: 0.07731  loss_rpn_cls: 0.0002353  loss_rpn_loc: 0.003755  time: 1.1282  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:32:39 d2.utils.events]: \u001b[0m eta: 1:07:57  iter: 10439  total_loss: 0.1265  loss_cls: 0.03174  loss_box_reg: 0.09103  loss_rpn_cls: 0.0001679  loss_rpn_loc: 0.004403  time: 1.1282  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:33:01 d2.utils.events]: \u001b[0m eta: 1:07:34  iter: 10459  total_loss: 0.1247  loss_cls: 0.03114  loss_box_reg: 0.08402  loss_rpn_cls: 0.0001586  loss_rpn_loc: 0.003685  time: 1.1282  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:33:24 d2.utils.events]: \u001b[0m eta: 1:07:11  iter: 10479  total_loss: 0.108  loss_cls: 0.02589  loss_box_reg: 0.07547  loss_rpn_cls: 0.0001612  loss_rpn_loc: 0.003207  time: 1.1282  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:33:47 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:33:47 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:33:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:33:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:33:47 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:33:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:33:47 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:33:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:33:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0629 s/iter. Eval: 0.0002 s/iter. Total: 0.0643 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0014 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:33:58 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0015 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 241/279. Dataloading: 0.0015 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0656 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:34:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.982618 (0.065630 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:34:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063674 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:34:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:34:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:34:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.436\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n\u001b[32m[12/06 18:34:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.421 | 74.732 | 44.394 | 12.000 | 30.321 | 49.656 |\n\u001b[32m[12/06 18:34:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.652 | 1          | 66.264 |\n| 2          | 40.663 | 3          | 26.161 | 4          | 59.380 |\n| 5          | 29.406 |            |        |            |        |\n\u001b[32m[12/06 18:34:05 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:34:05 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:34:05 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:34:05 d2.evaluation.testing]: \u001b[0mcopypaste: 44.4210,74.7318,44.3936,12.0000,30.3207,49.6562\n\u001b[32m[12/06 18:34:05 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 10499  total_loss: 0.1017  loss_cls: 0.0244  loss_box_reg: 0.07194  loss_rpn_cls: 0.0002241  loss_rpn_loc: 0.003812  time: 1.1282  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:34:28 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 10519  total_loss: 0.1041  loss_cls: 0.02727  loss_box_reg: 0.072  loss_rpn_cls: 0.0002867  loss_rpn_loc: 0.00391  time: 1.1282  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:34:50 d2.utils.events]: \u001b[0m eta: 1:06:03  iter: 10539  total_loss: 0.1163  loss_cls: 0.02701  loss_box_reg: 0.08368  loss_rpn_cls: 0.0005014  loss_rpn_loc: 0.004345  time: 1.1281  data_time: 0.0922  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:35:13 d2.utils.events]: \u001b[0m eta: 1:05:40  iter: 10559  total_loss: 0.1114  loss_cls: 0.02572  loss_box_reg: 0.08032  loss_rpn_cls: 0.000249  loss_rpn_loc: 0.00306  time: 1.1281  data_time: 0.0895  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:35:35 d2.utils.events]: \u001b[0m eta: 1:05:17  iter: 10579  total_loss: 0.1106  loss_cls: 0.02935  loss_box_reg: 0.08137  loss_rpn_cls: 8.131e-05  loss_rpn_loc: 0.003719  time: 1.1281  data_time: 0.0871  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:35:58 d2.utils.events]: \u001b[0m eta: 1:04:53  iter: 10599  total_loss: 0.1158  loss_cls: 0.02812  loss_box_reg: 0.08254  loss_rpn_cls: 0.0001738  loss_rpn_loc: 0.003697  time: 1.1281  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:36:21 d2.utils.events]: \u001b[0m eta: 1:04:31  iter: 10619  total_loss: 0.1176  loss_cls: 0.02556  loss_box_reg: 0.08288  loss_rpn_cls: 0.0001089  loss_rpn_loc: 0.003686  time: 1.1282  data_time: 0.0897  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:36:43 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:36:43 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:36:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:36:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:36:43 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:36:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:36:43 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:36:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:36:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0018 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0657 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0014 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0017 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0674 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0017 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0671 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:37:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.375970 (0.067066 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:37:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064911 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:37:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:37:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:37:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.449\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n\u001b[32m[12/06 18:37:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.560 | 75.471 | 43.747 | 15.000 | 31.703 | 49.373 |\n\u001b[32m[12/06 18:37:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.672 | 1          | 65.875 |\n| 2          | 40.087 | 3          | 25.836 | 4          | 60.916 |\n| 5          | 29.972 |            |        |            |        |\n\u001b[32m[12/06 18:37:02 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: 44.5595,75.4707,43.7469,15.0000,31.7029,49.3731\n\u001b[32m[12/06 18:37:02 d2.utils.events]: \u001b[0m eta: 1:04:08  iter: 10639  total_loss: 0.1147  loss_cls: 0.02756  loss_box_reg: 0.08242  loss_rpn_cls: 0.0001286  loss_rpn_loc: 0.003818  time: 1.1281  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:37:25 d2.utils.events]: \u001b[0m eta: 1:03:44  iter: 10659  total_loss: 0.1033  loss_cls: 0.0235  loss_box_reg: 0.07446  loss_rpn_cls: 0.0002026  loss_rpn_loc: 0.003292  time: 1.1281  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:37:47 d2.utils.events]: \u001b[0m eta: 1:03:21  iter: 10679  total_loss: 0.1075  loss_cls: 0.02581  loss_box_reg: 0.07293  loss_rpn_cls: 0.0001942  loss_rpn_loc: 0.003148  time: 1.1281  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:38:10 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 10699  total_loss: 0.1114  loss_cls: 0.02894  loss_box_reg: 0.07597  loss_rpn_cls: 0.0004654  loss_rpn_loc: 0.003726  time: 1.1281  data_time: 0.0961  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:38:32 d2.utils.events]: \u001b[0m eta: 1:02:35  iter: 10719  total_loss: 0.1066  loss_cls: 0.02703  loss_box_reg: 0.0783  loss_rpn_cls: 0.0002584  loss_rpn_loc: 0.003301  time: 1.1281  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:38:55 d2.utils.events]: \u001b[0m eta: 1:02:12  iter: 10739  total_loss: 0.1076  loss_cls: 0.0286  loss_box_reg: 0.07686  loss_rpn_cls: 0.0001422  loss_rpn_loc: 0.003512  time: 1.1281  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:39:18 d2.utils.events]: \u001b[0m eta: 1:01:49  iter: 10759  total_loss: 0.1047  loss_cls: 0.02692  loss_box_reg: 0.07611  loss_rpn_cls: 0.0001555  loss_rpn_loc: 0.003856  time: 1.1281  data_time: 0.0954  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:39:40 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:39:40 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:39:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:39:40 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:39:40 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:39:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:39:40 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:39:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:39:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0011 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0644 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:39:46 d2.evaluation.evaluator]: \u001b[0mInference done 89/279. Dataloading: 0.0014 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:39:51 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:39:56 d2.evaluation.evaluator]: \u001b[0mInference done 241/279. Dataloading: 0.0016 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:39:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.081021 (0.065989 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:39:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063950 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:39:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:39:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:39:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.441\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n\u001b[32m[12/06 18:39:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.303 | 75.509 | 44.895 | 12.000 | 30.242 | 49.020 |\n\u001b[32m[12/06 18:39:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.375 | 1          | 65.064 |\n| 2          | 39.409 | 3          | 26.517 | 4          | 60.884 |\n| 5          | 29.571 |            |        |            |        |\n\u001b[32m[12/06 18:39:59 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:39:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:39:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:39:59 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3033,75.5086,44.8945,12.0000,30.2425,49.0195\n\u001b[32m[12/06 18:39:59 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 10779  total_loss: 0.1204  loss_cls: 0.03015  loss_box_reg: 0.08674  loss_rpn_cls: 0.000401  loss_rpn_loc: 0.004439  time: 1.1281  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:40:22 d2.utils.events]: \u001b[0m eta: 1:01:04  iter: 10799  total_loss: 0.1118  loss_cls: 0.02695  loss_box_reg: 0.08057  loss_rpn_cls: 0.0001822  loss_rpn_loc: 0.003401  time: 1.1281  data_time: 0.0939  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:40:45 d2.utils.events]: \u001b[0m eta: 1:00:41  iter: 10819  total_loss: 0.1162  loss_cls: 0.02866  loss_box_reg: 0.07961  loss_rpn_cls: 0.0003288  loss_rpn_loc: 0.003271  time: 1.1282  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:41:07 d2.utils.events]: \u001b[0m eta: 1:00:18  iter: 10839  total_loss: 0.1063  loss_cls: 0.0261  loss_box_reg: 0.07438  loss_rpn_cls: 0.0001464  loss_rpn_loc: 0.003387  time: 1.1282  data_time: 0.0875  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:41:30 d2.utils.events]: \u001b[0m eta: 0:59:55  iter: 10859  total_loss: 0.09816  loss_cls: 0.02179  loss_box_reg: 0.06924  loss_rpn_cls: 0.0001505  loss_rpn_loc: 0.003356  time: 1.1282  data_time: 0.0885  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:41:52 d2.utils.events]: \u001b[0m eta: 0:59:32  iter: 10879  total_loss: 0.1031  loss_cls: 0.02595  loss_box_reg: 0.07561  loss_rpn_cls: 0.0001566  loss_rpn_loc: 0.003894  time: 1.1281  data_time: 0.0904  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:42:15 d2.utils.events]: \u001b[0m eta: 0:59:09  iter: 10899  total_loss: 0.107  loss_cls: 0.02735  loss_box_reg: 0.0765  loss_rpn_cls: 0.0002817  loss_rpn_loc: 0.004087  time: 1.1282  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:42:37 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:42:37 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:42:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:42:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:42:37 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:42:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:42:37 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:42:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:42:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0663 s/iter. Eval: 0.0002 s/iter. Total: 0.0679 s/iter. ETA=0:00:18\n\u001b[32m[12/06 18:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0023 s/iter. Inference: 0.0671 s/iter. Eval: 0.0002 s/iter. Total: 0.0697 s/iter. ETA=0:00:13\n\u001b[32m[12/06 18:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0020 s/iter. Inference: 0.0660 s/iter. Eval: 0.0002 s/iter. Total: 0.0683 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0018 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0671 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.501628 (0.067524 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:42:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065233 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:42:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:42:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:42:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.443\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n\u001b[32m[12/06 18:42:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.034 | 76.438 | 44.200 | 11.000 | 32.665 | 49.390 |\n\u001b[32m[12/06 18:42:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.302 | 1          | 68.080 |\n| 2          | 40.692 | 3          | 26.490 | 4          | 61.897 |\n| 5          | 30.741 |            |        |            |        |\n\u001b[32m[12/06 18:42:57 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:42:57 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:42:57 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:42:57 d2.evaluation.testing]: \u001b[0mcopypaste: 45.0335,76.4381,44.1998,11.0000,32.6649,49.3901\n\u001b[32m[12/06 18:42:57 d2.utils.events]: \u001b[0m eta: 0:58:47  iter: 10919  total_loss: 0.1038  loss_cls: 0.02447  loss_box_reg: 0.07489  loss_rpn_cls: 0.0001497  loss_rpn_loc: 0.0038  time: 1.1282  data_time: 0.0882  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:43:20 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 10939  total_loss: 0.1099  loss_cls: 0.02663  loss_box_reg: 0.07621  loss_rpn_cls: 0.0001964  loss_rpn_loc: 0.003356  time: 1.1282  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:43:42 d2.utils.events]: \u001b[0m eta: 0:58:01  iter: 10959  total_loss: 0.1105  loss_cls: 0.02856  loss_box_reg: 0.07679  loss_rpn_cls: 0.0003723  loss_rpn_loc: 0.003762  time: 1.1282  data_time: 0.0901  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:44:05 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 10979  total_loss: 0.1009  loss_cls: 0.02555  loss_box_reg: 0.06887  loss_rpn_cls: 0.0001521  loss_rpn_loc: 0.003393  time: 1.1282  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:44:28 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 10999  total_loss: 0.1057  loss_cls: 0.02708  loss_box_reg: 0.07449  loss_rpn_cls: 0.0001682  loss_rpn_loc: 0.00401  time: 1.1282  data_time: 0.0950  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:44:50 d2.utils.events]: \u001b[0m eta: 0:56:53  iter: 11019  total_loss: 0.1174  loss_cls: 0.03114  loss_box_reg: 0.08343  loss_rpn_cls: 0.0001676  loss_rpn_loc: 0.003458  time: 1.1282  data_time: 0.0951  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:45:12 d2.utils.events]: \u001b[0m eta: 0:56:29  iter: 11039  total_loss: 0.1006  loss_cls: 0.02693  loss_box_reg: 0.06766  loss_rpn_cls: 0.0002113  loss_rpn_loc: 0.003533  time: 1.1282  data_time: 0.0863  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:45:35 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:45:35 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:45:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:45:35 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:45:35 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:45:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:45:35 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:45:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:45:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0645 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0021 s/iter. Inference: 0.0653 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:13\n\u001b[32m[12/06 18:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0018 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0019 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:45:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.467428 (0.067399 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:45:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065041 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:45:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:45:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:45:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n\u001b[32m[12/06 18:45:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.100 | 75.663 | 45.043 | 10.000 | 32.316 | 49.474 |\n\u001b[32m[12/06 18:45:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 44.031 | 1          | 68.915 |\n| 2          | 40.862 | 3          | 26.100 | 4          | 59.986 |\n| 5          | 30.708 |            |        |            |        |\n\u001b[32m[12/06 18:45:54 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:45:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:45:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:45:54 d2.evaluation.testing]: \u001b[0mcopypaste: 45.1003,75.6632,45.0435,10.0000,32.3161,49.4742\n\u001b[32m[12/06 18:45:54 d2.utils.events]: \u001b[0m eta: 0:56:06  iter: 11059  total_loss: 0.1069  loss_cls: 0.02602  loss_box_reg: 0.07874  loss_rpn_cls: 0.0002057  loss_rpn_loc: 0.003372  time: 1.1282  data_time: 0.0912  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:46:16 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 11079  total_loss: 0.09322  loss_cls: 0.02319  loss_box_reg: 0.06788  loss_rpn_cls: 0.0001147  loss_rpn_loc: 0.003373  time: 1.1281  data_time: 0.0888  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:46:39 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 11099  total_loss: 0.1086  loss_cls: 0.02593  loss_box_reg: 0.07803  loss_rpn_cls: 0.0001625  loss_rpn_loc: 0.003937  time: 1.1281  data_time: 0.0944  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:47:01 d2.utils.events]: \u001b[0m eta: 0:54:58  iter: 11119  total_loss: 0.103  loss_cls: 0.02361  loss_box_reg: 0.0742  loss_rpn_cls: 0.0001477  loss_rpn_loc: 0.003418  time: 1.1281  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:47:24 d2.utils.events]: \u001b[0m eta: 0:54:34  iter: 11139  total_loss: 0.1054  loss_cls: 0.02539  loss_box_reg: 0.07455  loss_rpn_cls: 0.0001616  loss_rpn_loc: 0.003529  time: 1.1281  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:47:46 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 11159  total_loss: 0.1062  loss_cls: 0.02594  loss_box_reg: 0.07614  loss_rpn_cls: 0.0001252  loss_rpn_loc: 0.003769  time: 1.1281  data_time: 0.0922  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:48:09 d2.utils.events]: \u001b[0m eta: 0:53:48  iter: 11179  total_loss: 0.1042  loss_cls: 0.02482  loss_box_reg: 0.07776  loss_rpn_cls: 0.0002103  loss_rpn_loc: 0.003441  time: 1.1281  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:48:31 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:48:31 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:48:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:48:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:48:31 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:48:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:48:31 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:48:31 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:48:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0650 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0017 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0021 s/iter. Inference: 0.0661 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0019 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0676 s/iter. ETA=0:00:03\n\u001b[32m[12/06 18:48:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.598134 (0.067876 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:48:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065489 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:48:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:48:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:48:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.39s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.433\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n\u001b[32m[12/06 18:48:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.341 | 75.814 | 43.274 | 12.000 | 29.930 | 49.675 |\n\u001b[32m[12/06 18:48:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 45.302 | 1          | 66.625 |\n| 2          | 39.907 | 3          | 24.942 | 4          | 59.302 |\n| 5          | 29.967 |            |        |            |        |\n\u001b[32m[12/06 18:48:51 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:48:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:48:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:48:51 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3407,75.8135,43.2740,12.0000,29.9303,49.6752\n\u001b[32m[12/06 18:48:51 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 11199  total_loss: 0.1042  loss_cls: 0.02708  loss_box_reg: 0.07438  loss_rpn_cls: 0.0001  loss_rpn_loc: 0.004149  time: 1.1281  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:49:13 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 11219  total_loss: 0.09878  loss_cls: 0.02483  loss_box_reg: 0.06901  loss_rpn_cls: 0.0002499  loss_rpn_loc: 0.003431  time: 1.1281  data_time: 0.0952  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:49:36 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 11239  total_loss: 0.1083  loss_cls: 0.02808  loss_box_reg: 0.0744  loss_rpn_cls: 0.0001645  loss_rpn_loc: 0.003314  time: 1.1281  data_time: 0.0890  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:49:58 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 11259  total_loss: 0.1034  loss_cls: 0.02455  loss_box_reg: 0.07344  loss_rpn_cls: 0.0002402  loss_rpn_loc: 0.003998  time: 1.1280  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:50:21 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 11279  total_loss: 0.1045  loss_cls: 0.02333  loss_box_reg: 0.08177  loss_rpn_cls: 0.0001014  loss_rpn_loc: 0.004185  time: 1.1281  data_time: 0.0955  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:50:43 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 11299  total_loss: 0.09993  loss_cls: 0.02469  loss_box_reg: 0.0691  loss_rpn_cls: 6.165e-05  loss_rpn_loc: 0.003818  time: 1.1281  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:51:06 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 11319  total_loss: 0.08876  loss_cls: 0.02125  loss_box_reg: 0.06454  loss_rpn_cls: 0.0001125  loss_rpn_loc: 0.002912  time: 1.1281  data_time: 0.0958  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:51:29 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:51:29 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:51:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:51:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:51:29 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:51:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:51:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:51:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:51:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0022 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:00:13\n\u001b[32m[12/06 18:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0020 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0675 s/iter. ETA=0:00:08\n\u001b[32m[12/06 18:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0022 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:00:03\n\u001b[32m[12/06 18:51:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.818940 (0.068682 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:51:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065813 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:51:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:51:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:51:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.434\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n\u001b[32m[12/06 18:51:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.369 | 75.309 | 43.375 | 12.000 | 32.397 | 49.528 |\n\u001b[32m[12/06 18:51:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.366 | 1          | 66.789 |\n| 2          | 39.460 | 3          | 24.660 | 4          | 61.908 |\n| 5          | 31.030 |            |        |            |        |\n\u001b[32m[12/06 18:51:48 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:51:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:51:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:51:48 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3687,75.3086,43.3745,12.0000,32.3973,49.5277\n\u001b[32m[12/06 18:51:48 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 11339  total_loss: 0.09009  loss_cls: 0.02299  loss_box_reg: 0.06283  loss_rpn_cls: 0.0001696  loss_rpn_loc: 0.003263  time: 1.1281  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:52:11 d2.utils.events]: \u001b[0m eta: 0:50:23  iter: 11359  total_loss: 0.104  loss_cls: 0.02553  loss_box_reg: 0.07209  loss_rpn_cls: 0.0001224  loss_rpn_loc: 0.003608  time: 1.1281  data_time: 0.0882  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:52:33 d2.utils.events]: \u001b[0m eta: 0:50:00  iter: 11379  total_loss: 0.0904  loss_cls: 0.02354  loss_box_reg: 0.06558  loss_rpn_cls: 0.0002903  loss_rpn_loc: 0.002951  time: 1.1280  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:52:56 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 11399  total_loss: 0.1013  loss_cls: 0.02397  loss_box_reg: 0.07403  loss_rpn_cls: 0.0001969  loss_rpn_loc: 0.003667  time: 1.1280  data_time: 0.0906  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:53:18 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 11419  total_loss: 0.1307  loss_cls: 0.02941  loss_box_reg: 0.09603  loss_rpn_cls: 0.0002644  loss_rpn_loc: 0.004198  time: 1.1280  data_time: 0.0896  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:53:41 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 11439  total_loss: 0.118  loss_cls: 0.02931  loss_box_reg: 0.08156  loss_rpn_cls: 0.0002087  loss_rpn_loc: 0.003842  time: 1.1280  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:54:04 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 11459  total_loss: 0.1056  loss_cls: 0.02526  loss_box_reg: 0.07497  loss_rpn_cls: 0.0003019  loss_rpn_loc: 0.003631  time: 1.1281  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:54:26 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:54:26 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:54:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:54:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:54:26 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:54:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:54:26 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:54:26 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:54:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0011 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0645 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0018 s/iter. Inference: 0.0649 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0016 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[12/06 18:54:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.163814 (0.066291 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:54:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064221 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:54:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:54:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:54:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.439\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n\u001b[32m[12/06 18:54:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.737 | 76.082 | 43.911 | 12.000 | 31.789 | 49.679 |\n\u001b[32m[12/06 18:54:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.350 | 1          | 67.491 |\n| 2          | 38.224 | 3          | 25.804 | 4          | 61.125 |\n| 5          | 32.430 |            |        |            |        |\n\u001b[32m[12/06 18:54:45 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:54:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:54:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:54:45 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7375,76.0816,43.9114,12.0000,31.7891,49.6787\n\u001b[32m[12/06 18:54:45 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 11479  total_loss: 0.0914  loss_cls: 0.02375  loss_box_reg: 0.06663  loss_rpn_cls: 0.0002158  loss_rpn_loc: 0.003022  time: 1.1280  data_time: 0.0898  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:55:07 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 11499  total_loss: 0.09526  loss_cls: 0.0213  loss_box_reg: 0.07018  loss_rpn_cls: 8.1e-05  loss_rpn_loc: 0.003198  time: 1.1280  data_time: 0.0943  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:55:30 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 11519  total_loss: 0.1199  loss_cls: 0.0266  loss_box_reg: 0.08323  loss_rpn_cls: 0.0002871  loss_rpn_loc: 0.004038  time: 1.1280  data_time: 0.0908  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:55:53 d2.utils.events]: \u001b[0m eta: 0:46:56  iter: 11539  total_loss: 0.1083  loss_cls: 0.02555  loss_box_reg: 0.07693  loss_rpn_cls: 0.0002135  loss_rpn_loc: 0.003478  time: 1.1280  data_time: 0.0884  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:56:15 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 11559  total_loss: 0.1093  loss_cls: 0.02644  loss_box_reg: 0.07688  loss_rpn_cls: 0.0001671  loss_rpn_loc: 0.003751  time: 1.1280  data_time: 0.0905  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:56:38 d2.utils.events]: \u001b[0m eta: 0:46:09  iter: 11579  total_loss: 0.09058  loss_cls: 0.02346  loss_box_reg: 0.06592  loss_rpn_cls: 0.0002525  loss_rpn_loc: 0.003037  time: 1.1280  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:57:00 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 11599  total_loss: 0.1066  loss_cls: 0.02567  loss_box_reg: 0.07602  loss_rpn_cls: 0.0001227  loss_rpn_loc: 0.003787  time: 1.1280  data_time: 0.0836  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:57:22 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 18:57:22 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 18:57:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 18:57:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 18:57:22 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 18:57:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 18:57:22 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 18:57:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 18:57:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 18:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0019 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:17\n\u001b[32m[12/06 18:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0017 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:12\n\u001b[32m[12/06 18:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 161/279. Dataloading: 0.0017 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:07\n\u001b[32m[12/06 18:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 234/279. Dataloading: 0.0018 s/iter. Inference: 0.0656 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:03\n\u001b[32m[12/06 18:57:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.491809 (0.067488 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:57:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065249 s / iter per device, on 1 devices)\n\u001b[32m[12/06 18:57:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 18:57:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 18:57:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.440\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n\u001b[32m[12/06 18:57:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.719 | 75.932 | 44.035 | 12.000 | 32.415 | 49.560 |\n\u001b[32m[12/06 18:57:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.288 | 1          | 65.618 |\n| 2          | 40.554 | 3          | 25.585 | 4          | 61.777 |\n| 5          | 31.495 |            |        |            |        |\n\u001b[32m[12/06 18:57:42 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 18:57:42 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7192,75.9317,44.0348,12.0000,32.4147,49.5598\n\u001b[32m[12/06 18:57:42 d2.utils.events]: \u001b[0m eta: 0:45:23  iter: 11619  total_loss: 0.09833  loss_cls: 0.02424  loss_box_reg: 0.06996  loss_rpn_cls: 0.0001215  loss_rpn_loc: 0.00391  time: 1.1280  data_time: 0.0913  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:58:04 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 11639  total_loss: 0.1192  loss_cls: 0.02717  loss_box_reg: 0.08785  loss_rpn_cls: 0.0001393  loss_rpn_loc: 0.003928  time: 1.1280  data_time: 0.0905  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:58:26 d2.utils.events]: \u001b[0m eta: 0:44:37  iter: 11659  total_loss: 0.1021  loss_cls: 0.02721  loss_box_reg: 0.06955  loss_rpn_cls: 0.0002299  loss_rpn_loc: 0.004038  time: 1.1280  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:58:49 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 11679  total_loss: 0.114  loss_cls: 0.02593  loss_box_reg: 0.08276  loss_rpn_cls: 0.0001254  loss_rpn_loc: 0.003249  time: 1.1280  data_time: 0.0888  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:59:11 d2.utils.events]: \u001b[0m eta: 0:43:51  iter: 11699  total_loss: 0.09989  loss_cls: 0.02548  loss_box_reg: 0.07372  loss_rpn_cls: 8.389e-05  loss_rpn_loc: 0.003711  time: 1.1280  data_time: 0.0981  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:59:34 d2.utils.events]: \u001b[0m eta: 0:43:28  iter: 11719  total_loss: 0.09518  loss_cls: 0.02226  loss_box_reg: 0.06548  loss_rpn_cls: 0.0001736  loss_rpn_loc: 0.003243  time: 1.1279  data_time: 0.0845  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 18:59:56 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 11739  total_loss: 0.1086  loss_cls: 0.02583  loss_box_reg: 0.07454  loss_rpn_cls: 0.0001262  loss_rpn_loc: 0.003521  time: 1.1279  data_time: 0.0916  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:00:18 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:00:18 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:00:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:00:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:00:18 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:00:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:00:18 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:00:18 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:00:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:00:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0019 s/iter. Inference: 0.0652 s/iter. Eval: 0.0003 s/iter. Total: 0.0673 s/iter. ETA=0:00:18\n\u001b[32m[12/06 19:00:24 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0018 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:00:29 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:00:34 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0018 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0665 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:00:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.221538 (0.066502 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:00:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064318 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:00:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:00:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:00:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n\u001b[32m[12/06 19:00:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.231 | 75.167 | 45.947 | 12.000 | 30.150 | 49.290 |\n\u001b[32m[12/06 19:00:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.532 | 1          | 65.015 |\n| 2          | 39.716 | 3          | 24.975 | 4          | 60.658 |\n| 5          | 31.488 |            |        |            |        |\n\u001b[32m[12/06 19:00:37 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:00:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:00:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:00:37 d2.evaluation.testing]: \u001b[0mcopypaste: 44.2305,75.1671,45.9470,12.0000,30.1497,49.2900\n\u001b[32m[12/06 19:00:37 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 11759  total_loss: 0.1049  loss_cls: 0.02402  loss_box_reg: 0.07463  loss_rpn_cls: 7.083e-05  loss_rpn_loc: 0.003267  time: 1.1279  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:01:00 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 11779  total_loss: 0.1093  loss_cls: 0.02797  loss_box_reg: 0.07769  loss_rpn_cls: 0.0002094  loss_rpn_loc: 0.004152  time: 1.1279  data_time: 0.0931  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:01:22 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 11799  total_loss: 0.09921  loss_cls: 0.02447  loss_box_reg: 0.07047  loss_rpn_cls: 0.0001414  loss_rpn_loc: 0.003511  time: 1.1279  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:01:45 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 11819  total_loss: 0.1195  loss_cls: 0.02983  loss_box_reg: 0.08463  loss_rpn_cls: 0.0001151  loss_rpn_loc: 0.003588  time: 1.1279  data_time: 0.0878  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:02:08 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 11839  total_loss: 0.09583  loss_cls: 0.02639  loss_box_reg: 0.06853  loss_rpn_cls: 0.0001134  loss_rpn_loc: 0.002996  time: 1.1279  data_time: 0.1018  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:02:30 d2.utils.events]: \u001b[0m eta: 0:40:46  iter: 11859  total_loss: 0.1058  loss_cls: 0.02505  loss_box_reg: 0.0755  loss_rpn_cls: 0.0002521  loss_rpn_loc: 0.00451  time: 1.1279  data_time: 0.0902  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:02:52 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 11879  total_loss: 0.1082  loss_cls: 0.02466  loss_box_reg: 0.07451  loss_rpn_cls: 0.0002533  loss_rpn_loc: 0.00395  time: 1.1278  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:03:14 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:03:14 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:03:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:03:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:03:14 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:03:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:03:14 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:03:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 85/279. Dataloading: 0.0018 s/iter. Inference: 0.0657 s/iter. Eval: 0.0002 s/iter. Total: 0.0679 s/iter. ETA=0:00:13\n\u001b[32m[12/06 19:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 157/279. Dataloading: 0.0020 s/iter. Inference: 0.0663 s/iter. Eval: 0.0002 s/iter. Total: 0.0686 s/iter. ETA=0:00:08\n\u001b[32m[12/06 19:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 231/279. Dataloading: 0.0020 s/iter. Inference: 0.0661 s/iter. Eval: 0.0002 s/iter. Total: 0.0684 s/iter. ETA=0:00:03\n\u001b[32m[12/06 19:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.630346 (0.067994 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065622 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:03:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:03:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:03:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.07s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.454\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.434\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n\u001b[32m[12/06 19:03:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.786 | 75.943 | 45.441 | 12.000 | 30.125 | 48.610 |\n\u001b[32m[12/06 19:03:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 39.614 | 1          | 66.906 |\n| 2          | 39.044 | 3          | 25.513 | 4          | 61.973 |\n| 5          | 29.668 |            |        |            |        |\n\u001b[32m[12/06 19:03:34 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:03:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:03:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:03:34 d2.evaluation.testing]: \u001b[0mcopypaste: 43.7861,75.9430,45.4411,12.0000,30.1254,48.6095\n\u001b[32m[12/06 19:03:34 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 11899  total_loss: 0.1098  loss_cls: 0.02633  loss_box_reg: 0.07922  loss_rpn_cls: 0.0002156  loss_rpn_loc: 0.003761  time: 1.1278  data_time: 0.0883  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:03:56 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 11919  total_loss: 0.1064  loss_cls: 0.02648  loss_box_reg: 0.07192  loss_rpn_cls: 0.0002659  loss_rpn_loc: 0.003595  time: 1.1278  data_time: 0.0948  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:04:19 d2.utils.events]: \u001b[0m eta: 0:39:14  iter: 11939  total_loss: 0.1025  loss_cls: 0.02786  loss_box_reg: 0.07107  loss_rpn_cls: 5.496e-05  loss_rpn_loc: 0.002973  time: 1.1278  data_time: 0.0870  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:04:42 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 11959  total_loss: 0.09828  loss_cls: 0.02367  loss_box_reg: 0.06906  loss_rpn_cls: 0.0001943  loss_rpn_loc: 0.003785  time: 1.1278  data_time: 0.0977  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:05:04 d2.utils.events]: \u001b[0m eta: 0:38:28  iter: 11979  total_loss: 0.1039  loss_cls: 0.02676  loss_box_reg: 0.07431  loss_rpn_cls: 0.0002375  loss_rpn_loc: 0.004071  time: 1.1278  data_time: 0.0895  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:05:27 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 11999  total_loss: 0.09397  loss_cls: 0.02346  loss_box_reg: 0.06787  loss_rpn_cls: 3.962e-05  loss_rpn_loc: 0.002933  time: 1.1278  data_time: 0.0901  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:05:49 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 12019  total_loss: 0.09291  loss_cls: 0.02297  loss_box_reg: 0.06851  loss_rpn_cls: 0.0001098  loss_rpn_loc: 0.003208  time: 1.1278  data_time: 0.0916  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:06:12 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:06:12 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:06:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:06:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:06:12 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:06:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:06:12 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:06:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:06:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0014 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:18\n\u001b[32m[12/06 19:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 89/279. Dataloading: 0.0015 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0651 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 165/279. Dataloading: 0.0016 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0657 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0017 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:06:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.458347 (0.067366 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:06:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065049 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:06:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:06:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:06:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.445\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.563\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612\n\u001b[32m[12/06 19:06:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.812 | 75.429 | 44.463 | 10.000 | 30.482 | 50.058 |\n\u001b[32m[12/06 19:06:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.770 | 1          | 65.229 |\n| 2          | 40.607 | 3          | 28.137 | 4          | 61.222 |\n| 5          | 30.907 |            |        |            |        |\n\u001b[32m[12/06 19:06:31 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:06:31 d2.evaluation.testing]: \u001b[0mcopypaste: 44.8119,75.4285,44.4631,10.0000,30.4816,50.0579\n\u001b[32m[12/06 19:06:31 d2.utils.events]: \u001b[0m eta: 0:37:19  iter: 12039  total_loss: 0.09134  loss_cls: 0.02432  loss_box_reg: 0.06384  loss_rpn_cls: 0.0001179  loss_rpn_loc: 0.003205  time: 1.1278  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:06:53 d2.utils.events]: \u001b[0m eta: 0:36:56  iter: 12059  total_loss: 0.1024  loss_cls: 0.02497  loss_box_reg: 0.0728  loss_rpn_cls: 0.0001713  loss_rpn_loc: 0.003605  time: 1.1278  data_time: 0.0863  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:07:16 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 12079  total_loss: 0.09988  loss_cls: 0.02621  loss_box_reg: 0.07082  loss_rpn_cls: 8.375e-05  loss_rpn_loc: 0.00324  time: 1.1278  data_time: 0.0918  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:07:38 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 12099  total_loss: 0.09262  loss_cls: 0.02287  loss_box_reg: 0.06596  loss_rpn_cls: 8.25e-05  loss_rpn_loc: 0.003263  time: 1.1278  data_time: 0.0910  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:08:01 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 12119  total_loss: 0.1082  loss_cls: 0.02667  loss_box_reg: 0.07677  loss_rpn_cls: 0.0001406  loss_rpn_loc: 0.003527  time: 1.1278  data_time: 0.0907  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:08:23 d2.utils.events]: \u001b[0m eta: 0:35:24  iter: 12139  total_loss: 0.09988  loss_cls: 0.02313  loss_box_reg: 0.07249  loss_rpn_cls: 0.0001387  loss_rpn_loc: 0.002751  time: 1.1278  data_time: 0.0918  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:08:46 d2.utils.events]: \u001b[0m eta: 0:35:01  iter: 12159  total_loss: 0.09527  loss_cls: 0.02286  loss_box_reg: 0.06911  loss_rpn_cls: 0.0001795  loss_rpn_loc: 0.003392  time: 1.1277  data_time: 0.1004  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:09:08 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:09:08 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:09:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:09:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:09:08 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:09:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:09:08 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:09:08 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:09:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 89/279. Dataloading: 0.0014 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0650 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 165/279. Dataloading: 0.0016 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0655 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 241/279. Dataloading: 0.0016 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:09:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.068112 (0.065942 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:09:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.063917 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:09:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:09:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:09:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.425\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.557\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.557\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n\u001b[32m[12/06 19:09:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.952 | 75.363 | 42.459 | 12.000 | 31.039 | 48.379 |\n\u001b[32m[12/06 19:09:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 41.571 | 1          | 66.046 |\n| 2          | 38.309 | 3          | 25.908 | 4          | 61.391 |\n| 5          | 30.485 |            |        |            |        |\n\u001b[32m[12/06 19:09:27 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:09:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:09:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:09:27 d2.evaluation.testing]: \u001b[0mcopypaste: 43.9518,75.3634,42.4595,12.0000,31.0394,48.3787\n\u001b[32m[12/06 19:09:27 d2.utils.events]: \u001b[0m eta: 0:34:38  iter: 12179  total_loss: 0.09932  loss_cls: 0.02434  loss_box_reg: 0.07251  loss_rpn_cls: 0.0002021  loss_rpn_loc: 0.004426  time: 1.1277  data_time: 0.0910  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:09:50 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 12199  total_loss: 0.1047  loss_cls: 0.02604  loss_box_reg: 0.07639  loss_rpn_cls: 0.0001295  loss_rpn_loc: 0.00389  time: 1.1277  data_time: 0.0957  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:10:13 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 12219  total_loss: 0.09463  loss_cls: 0.02526  loss_box_reg: 0.06668  loss_rpn_cls: 0.0001877  loss_rpn_loc: 0.003718  time: 1.1278  data_time: 0.0972  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:10:35 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 12239  total_loss: 0.09174  loss_cls: 0.02222  loss_box_reg: 0.06312  loss_rpn_cls: 0.0001013  loss_rpn_loc: 0.002982  time: 1.1278  data_time: 0.0881  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:10:58 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 12259  total_loss: 0.08149  loss_cls: 0.0213  loss_box_reg: 0.05679  loss_rpn_cls: 0.0001893  loss_rpn_loc: 0.003099  time: 1.1278  data_time: 0.0902  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:11:20 d2.utils.events]: \u001b[0m eta: 0:32:43  iter: 12279  total_loss: 0.113  loss_cls: 0.02781  loss_box_reg: 0.08002  loss_rpn_cls: 0.0001522  loss_rpn_loc: 0.003307  time: 1.1278  data_time: 0.0900  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:11:43 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 12299  total_loss: 0.09325  loss_cls: 0.0218  loss_box_reg: 0.06735  loss_rpn_cls: 0.0001193  loss_rpn_loc: 0.003584  time: 1.1278  data_time: 0.0895  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:12:05 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:12:05 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:12:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:12:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:12:06 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:12:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:12:06 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:12:06 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:12:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0651 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0656 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:12:17 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0019 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0668 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:12:22 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0019 s/iter. Inference: 0.0646 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:12:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.284856 (0.066733 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:12:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064427 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:12:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:12:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:12:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.418\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.485\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.439\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599\n\u001b[32m[12/06 19:12:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.786 | 76.677 | 41.806 | 10.000 | 31.671 | 48.473 |\n\u001b[32m[12/06 19:12:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 40.643 | 1          | 66.248 |\n| 2          | 38.422 | 3          | 26.845 | 4          | 60.664 |\n| 5          | 29.891 |            |        |            |        |\n\u001b[32m[12/06 19:12:25 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:12:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:12:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:12:25 d2.evaluation.testing]: \u001b[0mcopypaste: 43.7856,76.6775,41.8060,10.0000,31.6706,48.4728\n\u001b[32m[12/06 19:12:25 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 12319  total_loss: 0.09873  loss_cls: 0.02336  loss_box_reg: 0.06966  loss_rpn_cls: 0.0002556  loss_rpn_loc: 0.003671  time: 1.1278  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:12:47 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 12339  total_loss: 0.1053  loss_cls: 0.02749  loss_box_reg: 0.07222  loss_rpn_cls: 0.0001055  loss_rpn_loc: 0.004273  time: 1.1277  data_time: 0.0874  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:13:10 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 12359  total_loss: 0.1027  loss_cls: 0.02393  loss_box_reg: 0.07039  loss_rpn_cls: 0.0001067  loss_rpn_loc: 0.003131  time: 1.1278  data_time: 0.0963  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:13:32 d2.utils.events]: \u001b[0m eta: 0:30:49  iter: 12379  total_loss: 0.1019  loss_cls: 0.02254  loss_box_reg: 0.07514  loss_rpn_cls: 0.0001876  loss_rpn_loc: 0.003316  time: 1.1277  data_time: 0.0921  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:13:54 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 12399  total_loss: 0.1019  loss_cls: 0.02694  loss_box_reg: 0.07222  loss_rpn_cls: 8.1e-05  loss_rpn_loc: 0.002743  time: 1.1277  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:14:17 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 12419  total_loss: 0.08748  loss_cls: 0.02393  loss_box_reg: 0.06153  loss_rpn_cls: 0.0002526  loss_rpn_loc: 0.003218  time: 1.1277  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:14:39 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 12439  total_loss: 0.09966  loss_cls: 0.02534  loss_box_reg: 0.07039  loss_rpn_cls: 0.0002284  loss_rpn_loc: 0.00301  time: 1.1277  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:15:02 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:15:02 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:15:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:15:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:15:02 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:15:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:15:02 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:15:02 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:15:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:15:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:15:13 d2.evaluation.evaluator]: \u001b[0mInference done 162/279. Dataloading: 0.0019 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0666 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:15:18 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:15:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.166144 (0.066300 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:15:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064058 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:15:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:15:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:15:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.445\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599\n\u001b[32m[12/06 19:15:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.606 | 75.332 | 44.493 | 10.000 | 32.093 | 49.207 |\n\u001b[32m[12/06 19:15:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.894 | 1          | 65.649 |\n| 2          | 39.152 | 3          | 26.076 | 4          | 60.344 |\n| 5          | 32.521 |            |        |            |        |\n\u001b[32m[12/06 19:15:21 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:15:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:15:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:15:21 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6061,75.3321,44.4932,10.0000,32.0928,49.2065\n\u001b[32m[12/06 19:15:21 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 12459  total_loss: 0.1108  loss_cls: 0.02647  loss_box_reg: 0.0768  loss_rpn_cls: 0.0001931  loss_rpn_loc: 0.003937  time: 1.1277  data_time: 0.0916  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:15:44 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 12479  total_loss: 0.1071  loss_cls: 0.02467  loss_box_reg: 0.07939  loss_rpn_cls: 0.0001367  loss_rpn_loc: 0.005129  time: 1.1277  data_time: 0.0960  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:16:06 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 12499  total_loss: 0.09497  loss_cls: 0.02108  loss_box_reg: 0.07014  loss_rpn_cls: 9.994e-05  loss_rpn_loc: 0.003134  time: 1.1277  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:16:28 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 12519  total_loss: 0.08473  loss_cls: 0.02099  loss_box_reg: 0.06316  loss_rpn_cls: 0.0001576  loss_rpn_loc: 0.002737  time: 1.1277  data_time: 0.0887  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:16:51 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 12539  total_loss: 0.09329  loss_cls: 0.02328  loss_box_reg: 0.06646  loss_rpn_cls: 0.0001444  loss_rpn_loc: 0.003034  time: 1.1277  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:17:14 d2.utils.events]: \u001b[0m eta: 0:27:23  iter: 12559  total_loss: 0.09582  loss_cls: 0.02582  loss_box_reg: 0.06326  loss_rpn_cls: 0.0001135  loss_rpn_loc: 0.003533  time: 1.1277  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:17:37 d2.utils.events]: \u001b[0m eta: 0:27:01  iter: 12579  total_loss: 0.1015  loss_cls: 0.02496  loss_box_reg: 0.07308  loss_rpn_cls: 0.0001148  loss_rpn_loc: 0.003559  time: 1.1277  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:17:59 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:17:59 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:17:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:17:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:17:59 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:17:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:17:59 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:17:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:17:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:18:05 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0024 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:13\n\u001b[32m[12/06 19:18:10 d2.evaluation.evaluator]: \u001b[0mInference done 158/279. Dataloading: 0.0022 s/iter. Inference: 0.0656 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:08\n\u001b[32m[12/06 19:18:15 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0020 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0672 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:18:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.420452 (0.067228 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:18:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064841 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:18:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:18:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:18:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.50s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.560\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n\u001b[32m[12/06 19:18:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.330 | 75.765 | 43.733 | 10.000 | 31.945 | 48.970 |\n\u001b[32m[12/06 19:18:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.130 | 1          | 65.391 |\n| 2          | 40.736 | 3          | 24.774 | 4          | 61.241 |\n| 5          | 31.709 |            |        |            |        |\n\u001b[32m[12/06 19:18:19 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:18:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:18:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:18:19 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3301,75.7647,43.7331,10.0000,31.9454,48.9705\n\u001b[32m[12/06 19:18:19 d2.utils.events]: \u001b[0m eta: 0:26:38  iter: 12599  total_loss: 0.08567  loss_cls: 0.02258  loss_box_reg: 0.06104  loss_rpn_cls: 9.807e-05  loss_rpn_loc: 0.003047  time: 1.1277  data_time: 0.0875  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:18:41 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 12619  total_loss: 0.09364  loss_cls: 0.02089  loss_box_reg: 0.06632  loss_rpn_cls: 0.0002555  loss_rpn_loc: 0.003392  time: 1.1277  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:19:04 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 12639  total_loss: 0.07588  loss_cls: 0.0181  loss_box_reg: 0.05468  loss_rpn_cls: 0.0001126  loss_rpn_loc: 0.002943  time: 1.1277  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:19:26 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 12659  total_loss: 0.1101  loss_cls: 0.02676  loss_box_reg: 0.07755  loss_rpn_cls: 0.0002126  loss_rpn_loc: 0.00363  time: 1.1277  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:19:49 d2.utils.events]: \u001b[0m eta: 0:25:07  iter: 12679  total_loss: 0.1004  loss_cls: 0.02472  loss_box_reg: 0.07484  loss_rpn_cls: 9.792e-05  loss_rpn_loc: 0.003159  time: 1.1277  data_time: 0.0964  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:20:11 d2.utils.events]: \u001b[0m eta: 0:24:44  iter: 12699  total_loss: 0.09746  loss_cls: 0.02238  loss_box_reg: 0.07119  loss_rpn_cls: 0.0001925  loss_rpn_loc: 0.003706  time: 1.1277  data_time: 0.0923  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:20:34 d2.utils.events]: \u001b[0m eta: 0:24:21  iter: 12719  total_loss: 0.1123  loss_cls: 0.0273  loss_box_reg: 0.08166  loss_rpn_cls: 0.0002238  loss_rpn_loc: 0.0045  time: 1.1277  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:20:56 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:20:56 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:20:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:20:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:20:56 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:20:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:20:56 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:20:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:20:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0011 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0016 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 239/279. Dataloading: 0.0016 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:21:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.388930 (0.067113 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:21:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064802 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:21:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:21:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:21:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n\u001b[32m[12/06 19:21:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.822 | 75.828 | 43.808 | 10.000 | 31.219 | 50.383 |\n\u001b[32m[12/06 19:21:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.464 | 1          | 65.492 |\n| 2          | 39.734 | 3          | 24.332 | 4          | 61.783 |\n| 5          | 35.127 |            |        |            |        |\n\u001b[32m[12/06 19:21:15 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:21:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:21:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:21:15 d2.evaluation.testing]: \u001b[0mcopypaste: 44.8221,75.8275,43.8082,10.0000,31.2189,50.3828\n\u001b[32m[12/06 19:21:15 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 12739  total_loss: 0.09315  loss_cls: 0.02341  loss_box_reg: 0.06625  loss_rpn_cls: 0.0001803  loss_rpn_loc: 0.003592  time: 1.1277  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:21:38 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 12759  total_loss: 0.09608  loss_cls: 0.02215  loss_box_reg: 0.06767  loss_rpn_cls: 0.0001136  loss_rpn_loc: 0.002869  time: 1.1277  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:22:00 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 12779  total_loss: 0.09342  loss_cls: 0.02247  loss_box_reg: 0.06416  loss_rpn_cls: 0.0001303  loss_rpn_loc: 0.003118  time: 1.1277  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:22:23 d2.utils.events]: \u001b[0m eta: 0:22:50  iter: 12799  total_loss: 0.09579  loss_cls: 0.02224  loss_box_reg: 0.07013  loss_rpn_cls: 0.0001414  loss_rpn_loc: 0.003882  time: 1.1277  data_time: 0.0941  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:22:45 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 12819  total_loss: 0.09728  loss_cls: 0.02335  loss_box_reg: 0.07238  loss_rpn_cls: 0.0003004  loss_rpn_loc: 0.003461  time: 1.1276  data_time: 0.0903  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:23:07 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 12839  total_loss: 0.08951  loss_cls: 0.02267  loss_box_reg: 0.06043  loss_rpn_cls: 0.0001526  loss_rpn_loc: 0.003189  time: 1.1276  data_time: 0.0891  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:23:29 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 12859  total_loss: 0.08429  loss_cls: 0.01846  loss_box_reg: 0.05923  loss_rpn_cls: 0.0001909  loss_rpn_loc: 0.003439  time: 1.1276  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:23:52 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:23:52 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:23:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:23:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:23:52 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:23:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:23:52 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:23:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:23:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0016 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0655 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0655 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0662 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:24:08 d2.evaluation.evaluator]: \u001b[0mInference done 240/279. Dataloading: 0.0016 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:24:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.160922 (0.066281 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:24:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064195 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:24:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:24:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:24:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.435\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.437\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604\n\u001b[32m[12/06 19:24:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.399 | 75.689 | 43.488 | 12.000 | 31.754 | 49.138 |\n\u001b[32m[12/06 19:24:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 41.337 | 1          | 67.391 |\n| 2          | 41.149 | 3          | 24.071 | 4          | 61.088 |\n| 5          | 31.356 |            |        |            |        |\n\u001b[32m[12/06 19:24:11 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:24:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:24:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:24:11 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3988,75.6886,43.4875,12.0000,31.7536,49.1385\n\u001b[32m[12/06 19:24:11 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 12879  total_loss: 0.09387  loss_cls: 0.02329  loss_box_reg: 0.06895  loss_rpn_cls: 9.178e-05  loss_rpn_loc: 0.003396  time: 1.1276  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:24:33 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 12899  total_loss: 0.1046  loss_cls: 0.02443  loss_box_reg: 0.0733  loss_rpn_cls: 0.0003526  loss_rpn_loc: 0.003271  time: 1.1276  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:24:56 d2.utils.events]: \u001b[0m eta: 0:20:33  iter: 12919  total_loss: 0.09801  loss_cls: 0.02412  loss_box_reg: 0.07006  loss_rpn_cls: 0.0001491  loss_rpn_loc: 0.003696  time: 1.1276  data_time: 0.0929  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:25:18 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 12939  total_loss: 0.08628  loss_cls: 0.02116  loss_box_reg: 0.06285  loss_rpn_cls: 0.0002401  loss_rpn_loc: 0.003045  time: 1.1275  data_time: 0.0846  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:25:40 d2.utils.events]: \u001b[0m eta: 0:19:47  iter: 12959  total_loss: 0.09878  loss_cls: 0.02342  loss_box_reg: 0.06998  loss_rpn_cls: 0.0001474  loss_rpn_loc: 0.002705  time: 1.1275  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:26:03 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 12979  total_loss: 0.09352  loss_cls: 0.02482  loss_box_reg: 0.06624  loss_rpn_cls: 0.0001192  loss_rpn_loc: 0.003114  time: 1.1275  data_time: 0.0949  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:26:25 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 12999  total_loss: 0.09248  loss_cls: 0.02238  loss_box_reg: 0.06619  loss_rpn_cls: 0.0002315  loss_rpn_loc: 0.003588  time: 1.1275  data_time: 0.0879  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:26:48 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:26:48 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:26:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:26:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:26:48 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:26:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:26:48 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:26:48 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:26:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0647 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0015 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0019 s/iter. Inference: 0.0651 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:08\n\u001b[32m[12/06 19:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 236/279. Dataloading: 0.0018 s/iter. Inference: 0.0650 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:27:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.475645 (0.067429 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:27:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.065108 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:27:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:27:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:27:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.441\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n\u001b[32m[12/06 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.595 | 75.719 | 44.948 | 12.000 | 30.073 | 50.038 |\n\u001b[32m[12/06 19:27:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.724 | 1          | 66.223 |\n| 2          | 39.091 | 3          | 25.590 | 4          | 61.526 |\n| 5          | 32.413 |            |        |            |        |\n\u001b[32m[12/06 19:27:08 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:27:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:27:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:27:08 d2.evaluation.testing]: \u001b[0mcopypaste: 44.5945,75.7191,44.9482,12.0000,30.0727,50.0382\n\u001b[32m[12/06 19:27:08 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 13019  total_loss: 0.08606  loss_cls: 0.01987  loss_box_reg: 0.05963  loss_rpn_cls: 0.0002009  loss_rpn_loc: 0.003342  time: 1.1276  data_time: 0.0933  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:27:30 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 13039  total_loss: 0.09483  loss_cls: 0.02305  loss_box_reg: 0.06892  loss_rpn_cls: 0.0001133  loss_rpn_loc: 0.00317  time: 1.1275  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:27:52 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 13059  total_loss: 0.1005  loss_cls: 0.02417  loss_box_reg: 0.06902  loss_rpn_cls: 0.0001395  loss_rpn_loc: 0.003522  time: 1.1275  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:28:15 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 13079  total_loss: 0.08261  loss_cls: 0.01963  loss_box_reg: 0.05975  loss_rpn_cls: 6.965e-05  loss_rpn_loc: 0.003233  time: 1.1275  data_time: 0.0927  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:28:37 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 13099  total_loss: 0.09638  loss_cls: 0.02349  loss_box_reg: 0.06791  loss_rpn_cls: 0.0002075  loss_rpn_loc: 0.003285  time: 1.1275  data_time: 0.0919  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:29:00 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 13119  total_loss: 0.09768  loss_cls: 0.02389  loss_box_reg: 0.07025  loss_rpn_cls: 0.0002052  loss_rpn_loc: 0.003821  time: 1.1275  data_time: 0.0881  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:29:22 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 13139  total_loss: 0.1025  loss_cls: 0.0245  loss_box_reg: 0.0724  loss_rpn_cls: 0.0001425  loss_rpn_loc: 0.003851  time: 1.1275  data_time: 0.0889  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:29:45 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:29:45 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:29:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:29:45 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:29:45 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:29:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:29:45 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:29:45 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:29:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:29:51 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0016 s/iter. Inference: 0.0637 s/iter. Eval: 0.0002 s/iter. Total: 0.0656 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0017 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:30:01 d2.evaluation.evaluator]: \u001b[0mInference done 241/279. Dataloading: 0.0016 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0657 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:30:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.137116 (0.066194 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:30:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064083 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:30:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:30:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:30:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n\u001b[32m[12/06 19:30:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.664 | 75.319 | 44.290 | 12.000 | 31.891 | 49.783 |\n\u001b[32m[12/06 19:30:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.648 | 1          | 65.326 |\n| 2          | 40.005 | 3          | 25.511 | 4          | 61.952 |\n| 5          | 32.547 |            |        |            |        |\n\u001b[32m[12/06 19:30:04 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:30:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:30:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:30:04 d2.evaluation.testing]: \u001b[0mcopypaste: 44.6645,75.3195,44.2897,12.0000,31.8910,49.7826\n\u001b[32m[12/06 19:30:04 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 13159  total_loss: 0.08601  loss_cls: 0.02254  loss_box_reg: 0.06163  loss_rpn_cls: 0.0001794  loss_rpn_loc: 0.003798  time: 1.1275  data_time: 0.0969  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:30:26 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 13179  total_loss: 0.1093  loss_cls: 0.02708  loss_box_reg: 0.07701  loss_rpn_cls: 0.0001386  loss_rpn_loc: 0.003837  time: 1.1275  data_time: 0.0934  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:30:49 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 13199  total_loss: 0.08803  loss_cls: 0.0227  loss_box_reg: 0.0636  loss_rpn_cls: 0.0002024  loss_rpn_loc: 0.004171  time: 1.1275  data_time: 0.0936  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:31:12 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 13219  total_loss: 0.08763  loss_cls: 0.02177  loss_box_reg: 0.06317  loss_rpn_cls: 0.0001023  loss_rpn_loc: 0.002773  time: 1.1276  data_time: 0.0970  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:31:34 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 13239  total_loss: 0.08188  loss_cls: 0.02058  loss_box_reg: 0.05992  loss_rpn_cls: 9.774e-05  loss_rpn_loc: 0.003089  time: 1.1275  data_time: 0.0865  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:31:57 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 13259  total_loss: 0.08887  loss_cls: 0.02132  loss_box_reg: 0.06231  loss_rpn_cls: 9.775e-05  loss_rpn_loc: 0.002753  time: 1.1275  data_time: 0.0971  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:32:20 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 13279  total_loss: 0.09151  loss_cls: 0.02193  loss_box_reg: 0.0676  loss_rpn_cls: 9.443e-05  loss_rpn_loc: 0.003394  time: 1.1275  data_time: 0.0890  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:32:42 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:32:42 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:32:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:32:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:32:42 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:32:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:32:42 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:32:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:32:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0002 s/iter. Total: 0.0646 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 83/279. Dataloading: 0.0026 s/iter. Inference: 0.0670 s/iter. Eval: 0.0002 s/iter. Total: 0.0698 s/iter. ETA=0:00:13\n\u001b[32m[12/06 19:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0021 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:08\n\u001b[32m[12/06 19:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 237/279. Dataloading: 0.0019 s/iter. Inference: 0.0648 s/iter. Eval: 0.0002 s/iter. Total: 0.0670 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:33:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.451224 (0.067340 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:33:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064883 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:33:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:33:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:33:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605\n\u001b[32m[12/06 19:33:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.405 | 75.611 | 43.628 | 12.000 | 32.032 | 49.296 |\n\u001b[32m[12/06 19:33:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 41.465 | 1          | 67.852 |\n| 2          | 38.902 | 3          | 25.031 | 4          | 61.830 |\n| 5          | 31.349 |            |        |            |        |\n\u001b[32m[12/06 19:33:01 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:33:01 d2.evaluation.testing]: \u001b[0mcopypaste: 44.4047,75.6108,43.6276,12.0000,32.0316,49.2962\n\u001b[32m[12/06 19:33:01 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 13299  total_loss: 0.08933  loss_cls: 0.02133  loss_box_reg: 0.06613  loss_rpn_cls: 0.0001782  loss_rpn_loc: 0.003182  time: 1.1275  data_time: 0.0883  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:33:23 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 13319  total_loss: 0.1  loss_cls: 0.0237  loss_box_reg: 0.06972  loss_rpn_cls: 8.12e-05  loss_rpn_loc: 0.002781  time: 1.1275  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:33:46 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 13339  total_loss: 0.09045  loss_cls: 0.02256  loss_box_reg: 0.06254  loss_rpn_cls: 6.261e-05  loss_rpn_loc: 0.003297  time: 1.1275  data_time: 0.0882  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:34:09 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 13359  total_loss: 0.108  loss_cls: 0.02557  loss_box_reg: 0.07697  loss_rpn_cls: 0.0001505  loss_rpn_loc: 0.003301  time: 1.1275  data_time: 0.0925  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:34:31 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 13379  total_loss: 0.09143  loss_cls: 0.02276  loss_box_reg: 0.06365  loss_rpn_cls: 7.335e-05  loss_rpn_loc: 0.003501  time: 1.1275  data_time: 0.0932  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:34:54 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 13399  total_loss: 0.08435  loss_cls: 0.02155  loss_box_reg: 0.05808  loss_rpn_cls: 6.527e-05  loss_rpn_loc: 0.002898  time: 1.1275  data_time: 0.0900  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:35:16 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 13419  total_loss: 0.08743  loss_cls: 0.02107  loss_box_reg: 0.06048  loss_rpn_cls: 7.095e-05  loss_rpn_loc: 0.00322  time: 1.1275  data_time: 0.0903  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:35:39 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:35:39 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:35:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:35:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:35:39 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:35:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:35:39 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:35:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:35:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0017 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0653 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0016 s/iter. Inference: 0.0645 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0016 s/iter. Inference: 0.0640 s/iter. Eval: 0.0002 s/iter. Total: 0.0658 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 233/279. Dataloading: 0.0018 s/iter. Inference: 0.0660 s/iter. Eval: 0.0002 s/iter. Total: 0.0681 s/iter. ETA=0:00:03\n\u001b[32m[12/06 19:35:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.640064 (0.068029 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:35:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.065727 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:35:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:35:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:35:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606\n\u001b[32m[12/06 19:35:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.924 | 77.045 | 44.768 | 12.000 | 32.409 | 49.829 |\n\u001b[32m[12/06 19:35:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 41.737 | 1          | 66.151 |\n| 2          | 39.889 | 3          | 26.312 | 4          | 60.731 |\n| 5          | 34.726 |            |        |            |        |\n\u001b[32m[12/06 19:35:58 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:35:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:35:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:35:59 d2.evaluation.testing]: \u001b[0mcopypaste: 44.9244,77.0451,44.7683,12.0000,32.4091,49.8286\n\u001b[32m[12/06 19:35:59 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 13439  total_loss: 0.08519  loss_cls: 0.02262  loss_box_reg: 0.05944  loss_rpn_cls: 9.709e-05  loss_rpn_loc: 0.00291  time: 1.1275  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:36:21 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 13459  total_loss: 0.0838  loss_cls: 0.01944  loss_box_reg: 0.05981  loss_rpn_cls: 0.0001542  loss_rpn_loc: 0.003108  time: 1.1275  data_time: 0.0917  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:36:43 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 13479  total_loss: 0.08287  loss_cls: 0.02037  loss_box_reg: 0.05848  loss_rpn_cls: 0.0002627  loss_rpn_loc: 0.003269  time: 1.1275  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:37:06 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 13499  total_loss: 0.1038  loss_cls: 0.02488  loss_box_reg: 0.07462  loss_rpn_cls: 0.000255  loss_rpn_loc: 0.00378  time: 1.1275  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:37:28 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 13519  total_loss: 0.09639  loss_cls: 0.02408  loss_box_reg: 0.06743  loss_rpn_cls: 0.0001068  loss_rpn_loc: 0.003448  time: 1.1275  data_time: 0.0880  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:37:51 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 13539  total_loss: 0.09712  loss_cls: 0.02368  loss_box_reg: 0.06947  loss_rpn_cls: 0.0001818  loss_rpn_loc: 0.00346  time: 1.1275  data_time: 0.0921  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:38:13 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 13559  total_loss: 0.09356  loss_cls: 0.02376  loss_box_reg: 0.06486  loss_rpn_cls: 0.0001369  loss_rpn_loc: 0.003141  time: 1.1275  data_time: 0.0928  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:38:36 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:38:36 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:38:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:38:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:38:36 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:38:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:38:36 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:38:36 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:38:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0012 s/iter. Inference: 0.0634 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 86/279. Dataloading: 0.0017 s/iter. Inference: 0.0647 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 163/279. Dataloading: 0.0016 s/iter. Inference: 0.0641 s/iter. Eval: 0.0002 s/iter. Total: 0.0659 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0016 s/iter. Inference: 0.0644 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:38:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.166994 (0.066303 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:38:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064233 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:38:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:38:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:38:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.14s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.445\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.444\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.555\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n\u001b[32m[12/06 19:38:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.107 | 73.575 | 44.484 | 12.000 | 30.776 | 49.181 |\n\u001b[32m[12/06 19:38:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 41.778 | 1          | 66.764 |\n| 2          | 39.570 | 3          | 22.953 | 4          | 61.885 |\n| 5          | 31.691 |            |        |            |        |\n\u001b[32m[12/06 19:38:55 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: 44.1069,73.5747,44.4837,12.0000,30.7760,49.1805\n\u001b[32m[12/06 19:38:55 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 13579  total_loss: 0.09452  loss_cls: 0.01964  loss_box_reg: 0.06952  loss_rpn_cls: 0.0002328  loss_rpn_loc: 0.003155  time: 1.1275  data_time: 0.0963  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:39:18 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 13599  total_loss: 0.09699  loss_cls: 0.02236  loss_box_reg: 0.06689  loss_rpn_cls: 0.0001147  loss_rpn_loc: 0.003271  time: 1.1275  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:39:41 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 13619  total_loss: 0.08968  loss_cls: 0.02193  loss_box_reg: 0.06499  loss_rpn_cls: 6.187e-05  loss_rpn_loc: 0.003276  time: 1.1275  data_time: 0.0942  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:40:03 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 13639  total_loss: 0.09024  loss_cls: 0.02125  loss_box_reg: 0.06235  loss_rpn_cls: 0.0002072  loss_rpn_loc: 0.002937  time: 1.1275  data_time: 0.0893  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:40:26 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 13659  total_loss: 0.09799  loss_cls: 0.02119  loss_box_reg: 0.06952  loss_rpn_cls: 0.0001799  loss_rpn_loc: 0.00279  time: 1.1275  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:40:48 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 13679  total_loss: 0.08187  loss_cls: 0.01736  loss_box_reg: 0.06055  loss_rpn_cls: 0.0001453  loss_rpn_loc: 0.003016  time: 1.1275  data_time: 0.0935  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:41:11 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 13699  total_loss: 0.09496  loss_cls: 0.02267  loss_box_reg: 0.0634  loss_rpn_cls: 6.67e-05  loss_rpn_loc: 0.00312  time: 1.1275  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:41:34 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:41:34 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:41:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:41:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:41:34 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:41:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:41:34 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:41:34 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:41:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0002 s/iter. Total: 0.0648 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0018 s/iter. Inference: 0.0642 s/iter. Eval: 0.0002 s/iter. Total: 0.0663 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0019 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0674 s/iter. ETA=0:00:08\n\u001b[32m[12/06 19:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 235/279. Dataloading: 0.0019 s/iter. Inference: 0.0652 s/iter. Eval: 0.0002 s/iter. Total: 0.0673 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:41:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.408536 (0.067184 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:41:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064870 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:41:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:41:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:41:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.443\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599\n\u001b[32m[12/06 19:41:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 43.762 | 74.204 | 44.192 | 12.000 | 31.302 | 48.849 |\n\u001b[32m[12/06 19:41:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 41.121 | 1          | 65.062 |\n| 2          | 40.289 | 3          | 24.120 | 4          | 61.663 |\n| 5          | 30.319 |            |        |            |        |\n\u001b[32m[12/06 19:41:53 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:41:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:41:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:41:53 d2.evaluation.testing]: \u001b[0mcopypaste: 43.7624,74.2040,44.1924,12.0000,31.3018,48.8487\n\u001b[32m[12/06 19:41:53 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 13719  total_loss: 0.0813  loss_cls: 0.0221  loss_box_reg: 0.05729  loss_rpn_cls: 7.379e-05  loss_rpn_loc: 0.003167  time: 1.1275  data_time: 0.0930  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:42:15 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 13739  total_loss: 0.09399  loss_cls: 0.02403  loss_box_reg: 0.06324  loss_rpn_cls: 0.0001546  loss_rpn_loc: 0.003508  time: 1.1276  data_time: 0.0953  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:42:38 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 13759  total_loss: 0.09405  loss_cls: 0.02214  loss_box_reg: 0.06596  loss_rpn_cls: 0.0002814  loss_rpn_loc: 0.003859  time: 1.1275  data_time: 0.0853  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:43:00 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 13779  total_loss: 0.09581  loss_cls: 0.02224  loss_box_reg: 0.06758  loss_rpn_cls: 9.082e-05  loss_rpn_loc: 0.003596  time: 1.1275  data_time: 0.0926  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:43:23 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 13799  total_loss: 0.08805  loss_cls: 0.02177  loss_box_reg: 0.06065  loss_rpn_cls: 0.0002025  loss_rpn_loc: 0.002759  time: 1.1275  data_time: 0.0916  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:43:45 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 13819  total_loss: 0.09197  loss_cls: 0.02529  loss_box_reg: 0.06525  loss_rpn_cls: 0.0001678  loss_rpn_loc: 0.003012  time: 1.1275  data_time: 0.0909  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:44:08 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 13839  total_loss: 0.09106  loss_cls: 0.02317  loss_box_reg: 0.0631  loss_rpn_cls: 0.000145  loss_rpn_loc: 0.003466  time: 1.1275  data_time: 0.0966  lr: 0.00025  max_mem: 8018M\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:44:30 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:44:30 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:44:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:44:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:44:30 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:44:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:44:30 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:44:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:44:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0027 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:18\n\u001b[32m[12/06 19:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 87/279. Dataloading: 0.0018 s/iter. Inference: 0.0639 s/iter. Eval: 0.0002 s/iter. Total: 0.0661 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 164/279. Dataloading: 0.0017 s/iter. Inference: 0.0638 s/iter. Eval: 0.0002 s/iter. Total: 0.0657 s/iter. ETA=0:00:07\n\u001b[32m[12/06 19:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 238/279. Dataloading: 0.0018 s/iter. Inference: 0.0643 s/iter. Eval: 0.0002 s/iter. Total: 0.0664 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:44:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.181451 (0.066356 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:44:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064141 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:44:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:44:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:44:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.38s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.437\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n\u001b[32m[12/06 19:44:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 44.049 | 75.292 | 44.757 | 12.000 | 30.963 | 49.227 |\n\u001b[32m[12/06 19:44:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 43.896 | 1          | 65.634 |\n| 2          | 39.479 | 3          | 23.791 | 4          | 61.062 |\n| 5          | 30.432 |            |        |            |        |\n\u001b[32m[12/06 19:44:50 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:44:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:44:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:44:50 d2.evaluation.testing]: \u001b[0mcopypaste: 44.0489,75.2920,44.7573,12.0000,30.9633,49.2269\n\u001b[32m[12/06 19:44:50 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 13859  total_loss: 0.09355  loss_cls: 0.02508  loss_box_reg: 0.06363  loss_rpn_cls: 0.0002118  loss_rpn_loc: 0.003098  time: 1.1275  data_time: 0.0936  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:45:12 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 13879  total_loss: 0.08889  loss_cls: 0.02114  loss_box_reg: 0.06482  loss_rpn_cls: 0.0004593  loss_rpn_loc: 0.003488  time: 1.1275  data_time: 0.0938  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:45:35 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 13899  total_loss: 0.08729  loss_cls: 0.02063  loss_box_reg: 0.06424  loss_rpn_cls: 6.626e-05  loss_rpn_loc: 0.00298  time: 1.1276  data_time: 0.0914  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:45:58 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 13919  total_loss: 0.09081  loss_cls: 0.02071  loss_box_reg: 0.06632  loss_rpn_cls: 0.0001262  loss_rpn_loc: 0.003487  time: 1.1276  data_time: 0.0937  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:46:20 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 13939  total_loss: 0.09249  loss_cls: 0.0245  loss_box_reg: 0.06308  loss_rpn_cls: 0.0001007  loss_rpn_loc: 0.003142  time: 1.1275  data_time: 0.0842  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:46:43 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 13959  total_loss: 0.08642  loss_cls: 0.02067  loss_box_reg: 0.06287  loss_rpn_cls: 0.0002075  loss_rpn_loc: 0.00315  time: 1.1276  data_time: 0.0958  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:47:06 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 13979  total_loss: 0.09443  loss_cls: 0.02204  loss_box_reg: 0.0665  loss_rpn_cls: 0.0002193  loss_rpn_loc: 0.003798  time: 1.1276  data_time: 0.0945  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:47:29 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 13999  total_loss: 0.09429  loss_cls: 0.02157  loss_box_reg: 0.06852  loss_rpn_cls: 5.732e-05  loss_rpn_loc: 0.002841  time: 1.1276  data_time: 0.0924  lr: 0.00025  max_mem: 8018M\n\u001b[32m[12/06 19:47:29 d2.engine.hooks]: \u001b[0mOverall training speed: 13998 iterations in 4:23:04 (1.1276 s / it)\n\u001b[32m[12/06 19:47:29 d2.engine.hooks]: \u001b[0mTotal training time: 4:55:15 (0:32:11 on hooks)\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:47:29 d2.data.datasets.coco]: \u001b[0m\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\n\u001b[32m[12/06 19:47:29 d2.data.datasets.coco]: \u001b[0mLoaded 279 images in COCO format from /kaggle/input/vispol/dhaka-streets-coco/valid/_annotations.coco.json\n\u001b[32m[12/06 19:47:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[12/06 19:47:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n\u001b[32m[12/06 19:47:29 d2.data.common]: \u001b[0mSerializing 279 elements to byte tensors and concatenating them all ...\n\u001b[32m[12/06 19:47:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n\u001b[32m[12/06 19:47:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 19:47:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[12/06 19:47:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 279 batches\n\u001b[32m[12/06 19:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/279. Dataloading: 0.0015 s/iter. Inference: 0.0632 s/iter. Eval: 0.0002 s/iter. Total: 0.0649 s/iter. ETA=0:00:17\n\u001b[32m[12/06 19:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 88/279. Dataloading: 0.0014 s/iter. Inference: 0.0635 s/iter. Eval: 0.0002 s/iter. Total: 0.0652 s/iter. ETA=0:00:12\n\u001b[32m[12/06 19:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 160/279. Dataloading: 0.0017 s/iter. Inference: 0.0654 s/iter. Eval: 0.0002 s/iter. Total: 0.0674 s/iter. ETA=0:00:08\n\u001b[32m[12/06 19:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 237/279. Dataloading: 0.0017 s/iter. Inference: 0.0648 s/iter. Eval: 0.0002 s/iter. Total: 0.0667 s/iter. ETA=0:00:02\n\u001b[32m[12/06 19:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.282216 (0.066723 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:47:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:17 (0.064594 s / iter per device, on 1 devices)\n\u001b[32m[12/06 19:47:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[12/06 19:47:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n\u001b[32m[12/06 19:47:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.13s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n\u001b[32m[12/06 19:47:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n|:------:|:------:|:------:|:------:|:------:|:------:|\n| 45.060 | 75.700 | 45.890 | 12.000 | 30.985 | 50.032 |\n\u001b[32m[12/06 19:47:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category   | AP     | category   | AP     | category   | AP     |\n|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n| pollutants | nan    | 0          | 42.847 | 1          | 65.775 |\n| 2          | 40.134 | 3          | 25.708 | 4          | 62.579 |\n| 5          | 33.315 |            |        |            |        |\n\u001b[32m[12/06 19:47:48 d2.engine.defaults]: \u001b[0mEvaluation results for my_dataset_val in csv format:\n\u001b[32m[12/06 19:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[12/06 19:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[12/06 19:47:48 d2.evaluation.testing]: \u001b[0mcopypaste: 45.0597,75.7002,45.8900,12.0000,30.9846,50.0325\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}